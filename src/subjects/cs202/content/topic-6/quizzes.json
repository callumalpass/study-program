[
  {
    "id": "cs202-topic6-quiz1",
    "subjectId": "cs202",
    "topicId": "cs202-topic6",
    "title": "Memory Technologies",
    "questions": [
      {
        "id": "cs202-t6-q1-1",
        "type": "multiple_choice",
        "prompt": "Why is SRAM faster than DRAM?",
        "options": [
          "SRAM uses larger transistors",
          "SRAM uses flip-flops, no refresh needed",
          "SRAM is closer to the CPU",
          "SRAM has more bandwidth"
        ],
        "correctAnswer": 1,
        "explanation": "SRAM uses 6 transistors in a flip-flop configuration that holds state without refresh, allowing faster access than DRAM's capacitor-based cells."
      },
      {
        "id": "cs202-t6-q1-2",
        "type": "multiple_choice",
        "prompt": "DRAM requires periodic refresh because:",
        "options": [
          "Capacitors leak charge",
          "Transistors wear out",
          "Memory controllers require it",
          "The bus needs to be cleared"
        ],
        "correctAnswer": 0,
        "explanation": "DRAM stores data as charge in tiny capacitors that leak over time; refresh reads and rewrites each row periodically."
      },
      {
        "id": "cs202-t6-q1-3",
        "type": "multiple_choice",
        "prompt": "The term DDR (Double Data Rate) means:",
        "options": [
          "Twice the memory capacity",
          "Data transfers on both clock edges",
          "Two memory channels",
          "Double the voltage"
        ],
        "correctAnswer": 1,
        "explanation": "DDR transfers data on both rising and falling clock edges, doubling the data rate compared to SDR."
      },
      {
        "id": "cs202-t6-q1-4",
        "type": "multiple_choice",
        "prompt": "Which memory technology is non-volatile?",
        "options": [
          "SRAM",
          "DRAM",
          "Flash/SSD",
          "All of the above"
        ],
        "correctAnswer": 2,
        "explanation": "Flash memory retains data without power (non-volatile), while SRAM and DRAM lose data when power is removed."
      },
      {
        "id": "cs202-t6-q1-5",
        "type": "multiple_choice",
        "prompt": "Why are there multiple cache levels (L1, L2, L3)?",
        "options": [
          "For redundancy",
          "To balance speed vs. capacity trade-offs",
          "For power management",
          "Required by x86 architecture"
        ],
        "correctAnswer": 1,
        "explanation": "Multiple levels allow small fast L1 caches for low latency and larger slower L2/L3 caches for capacity."
      }
    ]
  },
  {
    "id": "cs202-topic6-quiz2",
    "subjectId": "cs202",
    "topicId": "cs202-topic6",
    "title": "DRAM and Storage",
    "questions": [
      {
        "id": "cs202-t6-q2-1",
        "type": "multiple_choice",
        "prompt": "In DRAM, a row buffer hit means:",
        "options": [
          "The data is in the cache",
          "The requested row is already open",
          "The memory controller found the data",
          "The refresh is complete"
        ],
        "correctAnswer": 1,
        "explanation": "A row buffer hit occurs when the requested data's row is already in the sense amplifiers, requiring only a column access."
      },
      {
        "id": "cs202-t6-q2-2",
        "type": "multiple_choice",
        "prompt": "The three main components of HDD access time are:",
        "options": [
          "Read, write, verify",
          "Seek, rotation, transfer",
          "Cache, buffer, disk",
          "Connect, access, disconnect"
        ],
        "correctAnswer": 1,
        "explanation": "HDD access time = seek time (move head) + rotational latency (wait for sector) + transfer time (read data)."
      },
      {
        "id": "cs202-t6-q2-3",
        "type": "multiple_choice",
        "prompt": "SSDs are faster than HDDs for random access primarily because:",
        "options": [
          "They have larger caches",
          "They have no mechanical seek time",
          "They use faster memory chips",
          "They have more bandwidth"
        ],
        "correctAnswer": 1,
        "explanation": "SSDs eliminate mechanical seek and rotation time, making random access nearly as fast as sequential."
      },
      {
        "id": "cs202-t6-q2-4",
        "type": "multiple_choice",
        "prompt": "Flash memory write limitation (erase-before-write) is handled by:",
        "options": [
          "Larger blocks",
          "Flash Translation Layer (FTL)",
          "More power",
          "Faster controllers"
        ],
        "correctAnswer": 1,
        "explanation": "The FTL manages address mapping, wear leveling, and garbage collection to handle flash's erase-before-write constraint."
      },
      {
        "id": "cs202-t6-q2-5",
        "type": "multiple_choice",
        "prompt": "Wear leveling in SSDs ensures:",
        "options": [
          "Even distribution of writes across all cells",
          "Data is never lost",
          "Faster read speeds",
          "Lower power consumption"
        ],
        "correctAnswer": 0,
        "explanation": "Wear leveling distributes writes evenly so no cells wear out prematurely, extending SSD lifespan."
      }
    ]
  },
  {
    "id": "cs202-topic6-quiz3",
    "subjectId": "cs202",
    "topicId": "cs202-topic6",
    "title": "Memory Controllers and Performance",
    "questions": [
      {
        "id": "cs202-t6-q3-1",
        "type": "multiple_choice",
        "prompt": "A memory controller's primary function is to:",
        "options": [
          "Store data",
          "Manage CPU cache",
          "Interface between CPU and DRAM",
          "Compress memory data"
        ],
        "correctAnswer": 2,
        "explanation": "The memory controller handles all communication between the CPU and DRAM, including scheduling, timing, and refresh."
      },
      {
        "id": "cs202-t6-q3-2",
        "type": "multiple_choice",
        "prompt": "Memory bandwidth is typically measured in:",
        "options": [
          "MHz",
          "GB/s",
          "Latency",
          "Instructions per second"
        ],
        "correctAnswer": 1,
        "explanation": "Memory bandwidth is the data transfer rate, measured in GB/s (gigabytes per second)."
      },
      {
        "id": "cs202-t6-q3-3",
        "type": "multiple_choice",
        "prompt": "According to Little's Law, to achieve high memory bandwidth you need:",
        "options": [
          "Faster memory chips",
          "Many outstanding memory requests",
          "Larger cache",
          "Lower latency only"
        ],
        "correctAnswer": 1,
        "explanation": "Little's Law: Bandwidth = Outstanding requests / Latency. More outstanding requests enable higher bandwidth despite latency."
      },
      {
        "id": "cs202-t6-q3-4",
        "type": "multiple_choice",
        "prompt": "FR-FCFS memory scheduling prioritizes:",
        "options": [
          "Oldest requests first",
          "Row buffer hits, then oldest",
          "Smallest requests first",
          "Random ordering"
        ],
        "correctAnswer": 1,
        "explanation": "FR-FCFS (First Ready, First Come First Served) prioritizes requests that hit the open row buffer, then by age."
      },
      {
        "id": "cs202-t6-q3-5",
        "type": "multiple_choice",
        "prompt": "High Bandwidth Memory (HBM) achieves high bandwidth through:",
        "options": [
          "Faster clock speeds",
          "3D stacking with wide interfaces",
          "Larger capacitors",
          "More refresh cycles"
        ],
        "correctAnswer": 1,
        "explanation": "HBM stacks DRAM dies with through-silicon vias (TSVs) and uses a very wide (1024-bit) interface."
      }
    ]
  }
]
