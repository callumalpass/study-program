[
  {
    "id": "cs304-t2-ex01",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Simple Recursive Descent Parser",
    "difficulty": 2,
    "description": "Implement a recursive descent parser for arithmetic expressions with addition and multiplication following the grammar: E → T + E | T, T → num.",
    "starterCode": "class Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n\n    def peek(self):\n        return self.tokens[self.pos] if self.pos < len(self.tokens) else None\n\n    def consume(self, expected_type):\n        \"\"\"Consume and return token if it matches expected type\"\"\"\n        # Your code here\n        pass\n\n    def parse_expression(self):\n        \"\"\"E → T + E | T\"\"\"\n        # Your code here\n        pass\n\n    def parse_term(self):\n        \"\"\"T → num\"\"\"\n        # Your code here\n        pass\n\n# Test\ntokens = [('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\nresult = parser.parse_expression()\nprint(result)",
    "solution": "class Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n\n    def peek(self):\n        return self.tokens[self.pos] if self.pos < len(self.tokens) else None\n\n    def consume(self, expected_type):\n        \"\"\"Consume and return token if it matches expected type\"\"\"\n        token = self.peek()\n        if not token or token[0] != expected_type:\n            raise SyntaxError(f\"Expected {expected_type}, got {token}\")\n        self.pos += 1\n        return token\n\n    def parse_expression(self):\n        \"\"\"E → T + E | T\"\"\"\n        left = self.parse_term()\n\n        if self.peek() and self.peek()[0] == 'PLUS':\n            self.consume('PLUS')\n            right = self.parse_expression()\n            return ('ADD', left, right)\n\n        return left\n\n    def parse_term(self):\n        \"\"\"T → num\"\"\"\n        token = self.consume('NUMBER')\n        return ('NUM', token[1])\n\n# Test\ntokens = [('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\nresult = parser.parse_expression()\nprint(result)",
    "testCases": [
      {
        "input": "[('NUMBER', 5)]",
        "expectedOutput": "('NUM', 5)",
        "isHidden": false,
        "description": "Single number"
      },
      {
        "input": "[('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]",
        "expectedOutput": "('ADD', ('NUM', 5), ('NUM', 3))",
        "isHidden": false,
        "description": "Simple addition"
      },
      {
        "input": "[('NUMBER', 1), ('PLUS', '+'), ('NUMBER', 2), ('PLUS', '+'), ('NUMBER', 3)]",
        "expectedOutput": "nested ADD",
        "isHidden": true,
        "description": "Right-associative addition chain"
      }
    ],
    "hints": [
      "Each grammar rule becomes a parsing method",
      "Use peek() to look ahead without consuming",
      "Consume tokens that match the expected type",
      "Return parse tree nodes as tuples"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex02",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Grammar Ambiguity Detection",
    "difficulty": 3,
    "description": "Implement a function that detects if a grammar is ambiguous by checking for conflicts in a simple case (multiple derivations for the same string).",
    "starterCode": "def is_ambiguous_grammar(grammar, test_strings):\n    \"\"\"\n    Check if grammar produces multiple parse trees for any test string.\n    grammar: dict of production rules\n    test_strings: list of strings to test\n    Return True if any string has multiple derivations.\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'E'], ['E', '*', 'E'], ['num']]\n}\nprint(is_ambiguous_grammar(grammar, ['num+num*num']))",
    "solution": "def is_ambiguous_grammar(grammar, test_strings):\n    \"\"\"\n    Check if grammar produces multiple parse trees for any test string.\n    This is a simplified version that checks for the classic ambiguity pattern.\n    \"\"\"\n    # Check for ambiguous patterns in the grammar itself\n    def has_ambiguous_operators(productions):\n        \"\"\"Check if grammar has operators at same precedence level\"\"\"\n        operators = []\n        for prod in productions:\n            if len(prod) == 3 and prod[0] == prod[2]:  # E → E op E\n                operators.append(prod[1])\n        # If multiple operators exist with same recursive pattern, likely ambiguous\n        return len(operators) > 1\n\n    # Simple heuristic: if we have E → E + E | E * E, it's ambiguous\n    for nonterminal, productions in grammar.items():\n        if has_ambiguous_operators(productions):\n            return True\n\n    return False\n\n# More sophisticated version using CYK-style parsing\ndef is_ambiguous_grammar_advanced(grammar, test_strings):\n    \"\"\"\n    Actually parse test strings and count derivations.\n    This is computationally expensive but more accurate.\n    \"\"\"\n    def count_parse_trees(string, symbol, memo=None):\n        if memo is None:\n            memo = {}\n\n        if (string, symbol) in memo:\n            return memo[(string, symbol)]\n\n        if symbol not in grammar:\n            # Terminal\n            count = 1 if string == symbol else 0\n            memo[(string, symbol)] = count\n            return count\n\n        total = 0\n        for production in grammar[symbol]:\n            if len(production) == 1:\n                # E → num\n                total += count_parse_trees(string, production[0], memo)\n            elif len(production) == 3:\n                # E → E + E - try all splits\n                for i in range(len(string)):\n                    left = string[:i]\n                    right = string[i+1:]\n                    if i < len(string) and string[i] == production[1]:\n                        left_count = count_parse_trees(left, production[0], memo)\n                        right_count = count_parse_trees(right, production[2], memo)\n                        total += left_count * right_count\n\n        memo[(string, symbol)] = total\n        return total\n\n    for test_str in test_strings:\n        if count_parse_trees(test_str, 'E') > 1:\n            return True\n\n    return False\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'E'], ['E', '*', 'E'], ['num']]\n}\nprint(is_ambiguous_grammar(grammar, ['num+num*num']))",
    "testCases": [
      {
        "input": "grammar1",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Ambiguous arithmetic grammar"
      },
      {
        "input": "grammar2",
        "expectedOutput": "False",
        "isHidden": true,
        "description": "Unambiguous grammar with precedence"
      }
    ],
    "hints": [
      "A grammar is ambiguous if one string has multiple parse trees",
      "Look for patterns like E → E + E | E * E (same precedence)",
      "You can check heuristically or actually parse test strings",
      "This is undecidable in general, so use approximations"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex03",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "First and Follow Sets",
    "difficulty": 3,
    "description": "Compute FIRST and FOLLOW sets for a context-free grammar, used in LL parsing.",
    "starterCode": "def compute_first_sets(grammar):\n    \"\"\"\n    Compute FIRST sets for each nonterminal.\n    grammar: dict {nonterminal: [[production], ...]}\n    Return: dict {symbol: set of terminals}\n    \"\"\"\n    # Your code here\n    pass\n\ndef compute_follow_sets(grammar, start_symbol):\n    \"\"\"\n    Compute FOLLOW sets for each nonterminal.\n    Return: dict {nonterminal: set of terminals}\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'S': [['A', 'B']],\n    'A': [['a'], ['ε']],\n    'B': [['b']]\n}\nprint(compute_first_sets(grammar))\nprint(compute_follow_sets(grammar, 'S'))",
    "solution": "def compute_first_sets(grammar):\n    \"\"\"\n    Compute FIRST sets for each nonterminal.\n    grammar: dict {nonterminal: [[production], ...]}\n    Return: dict {symbol: set of terminals}\n    \"\"\"\n    first = {nt: set() for nt in grammar}\n\n    # Terminals have themselves in FIRST\n    all_symbols = set()\n    for productions in grammar.values():\n        for prod in productions:\n            all_symbols.update(prod)\n\n    terminals = all_symbols - set(grammar.keys())\n\n    changed = True\n    while changed:\n        changed = False\n        for nonterminal in grammar:\n            for production in grammar[nonterminal]:\n                # Empty production\n                if production == ['ε']:\n                    if 'ε' not in first[nonterminal]:\n                        first[nonterminal].add('ε')\n                        changed = True\n                    continue\n\n                # Process symbols in production\n                for symbol in production:\n                    if symbol in terminals:\n                        if symbol not in first[nonterminal]:\n                            first[nonterminal].add(symbol)\n                            changed = True\n                        break\n                    else:\n                        # Nonterminal\n                        before = len(first[nonterminal])\n                        first[nonterminal].update(first[symbol] - {'ε'})\n                        if len(first[nonterminal]) > before:\n                            changed = True\n\n                        if 'ε' not in first[symbol]:\n                            break\n                else:\n                    # All symbols can derive epsilon\n                    if 'ε' not in first[nonterminal]:\n                        first[nonterminal].add('ε')\n                        changed = True\n\n    return first\n\ndef compute_follow_sets(grammar, start_symbol):\n    \"\"\"\n    Compute FOLLOW sets for each nonterminal.\n    Return: dict {nonterminal: set of terminals}\n    \"\"\"\n    first = compute_first_sets(grammar)\n    follow = {nt: set() for nt in grammar}\n    follow[start_symbol].add('$')  # End marker\n\n    changed = True\n    while changed:\n        changed = False\n        for nonterminal in grammar:\n            for production in grammar[nonterminal]:\n                for i, symbol in enumerate(production):\n                    if symbol not in grammar:\n                        continue  # Terminal\n\n                    # Everything after symbol\n                    rest = production[i+1:]\n\n                    if not rest:\n                        # Symbol is last - add FOLLOW(nonterminal)\n                        before = len(follow[symbol])\n                        follow[symbol].update(follow[nonterminal])\n                        if len(follow[symbol]) > before:\n                            changed = True\n                    else:\n                        # Add FIRST(rest) to FOLLOW(symbol)\n                        for next_symbol in rest:\n                            if next_symbol in grammar:\n                                before = len(follow[symbol])\n                                follow[symbol].update(first[next_symbol] - {'ε'})\n                                if len(follow[symbol]) > before:\n                                    changed = True\n                                if 'ε' not in first[next_symbol]:\n                                    break\n                            else:\n                                # Terminal\n                                if next_symbol not in follow[symbol]:\n                                    follow[symbol].add(next_symbol)\n                                    changed = True\n                                break\n                        else:\n                            # All symbols in rest can derive epsilon\n                            before = len(follow[symbol])\n                            follow[symbol].update(follow[nonterminal])\n                            if len(follow[symbol]) > before:\n                                changed = True\n\n    return follow\n\n# Test\ngrammar = {\n    'S': [['A', 'B']],\n    'A': [['a'], ['ε']],\n    'B': [['b']]\n}\nprint(compute_first_sets(grammar))\nprint(compute_follow_sets(grammar, 'S'))",
    "testCases": [
      {
        "input": "grammar1",
        "expectedOutput": "FIRST(A) = {a, ε}, FIRST(B) = {b}",
        "isHidden": false,
        "description": "Simple grammar"
      },
      {
        "input": "grammar2",
        "expectedOutput": "FOLLOW(A) = {b}",
        "isHidden": true,
        "description": "Follow set computation"
      }
    ],
    "hints": [
      "FIRST(X) is the set of terminals that can start strings derived from X",
      "If X → ε, then ε ∈ FIRST(X)",
      "FOLLOW(X) is the set of terminals that can appear after X",
      "Use fixed-point iteration until sets stop growing"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex04",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "LL(1) Parse Table Construction",
    "difficulty": 4,
    "description": "Build an LL(1) parse table from a grammar using FIRST and FOLLOW sets.",
    "starterCode": "def build_ll1_table(grammar, start_symbol):\n    \"\"\"\n    Build LL(1) parsing table.\n    Return: dict {(nonterminal, terminal): production}\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'E': [['T', 'E_prime']],\n    'E_prime': [['PLUS', 'T', 'E_prime'], ['ε']],\n    'T': [['num']]\n}\ntable = build_ll1_table(grammar, 'E')\nprint(table[('E', 'num')])  # Should be ['T', 'E_prime']",
    "solution": "def compute_first_sets(grammar):\n    \"\"\"Compute FIRST sets\"\"\"\n    first = {nt: set() for nt in grammar}\n    all_symbols = set()\n    for productions in grammar.values():\n        for prod in productions:\n            all_symbols.update(prod)\n    terminals = all_symbols - set(grammar.keys())\n\n    changed = True\n    while changed:\n        changed = False\n        for nonterminal in grammar:\n            for production in grammar[nonterminal]:\n                if production == ['ε']:\n                    if 'ε' not in first[nonterminal]:\n                        first[nonterminal].add('ε')\n                        changed = True\n                    continue\n\n                for symbol in production:\n                    if symbol in terminals:\n                        if symbol not in first[nonterminal]:\n                            first[nonterminal].add(symbol)\n                            changed = True\n                        break\n                    else:\n                        before = len(first[nonterminal])\n                        first[nonterminal].update(first[symbol] - {'ε'})\n                        if len(first[nonterminal]) > before:\n                            changed = True\n                        if 'ε' not in first[symbol]:\n                            break\n                else:\n                    if 'ε' not in first[nonterminal]:\n                        first[nonterminal].add('ε')\n                        changed = True\n    return first\n\ndef compute_follow_sets(grammar, start_symbol):\n    \"\"\"Compute FOLLOW sets\"\"\"\n    first = compute_first_sets(grammar)\n    follow = {nt: set() for nt in grammar}\n    follow[start_symbol].add('$')\n\n    changed = True\n    while changed:\n        changed = False\n        for nonterminal in grammar:\n            for production in grammar[nonterminal]:\n                for i, symbol in enumerate(production):\n                    if symbol not in grammar:\n                        continue\n                    rest = production[i+1:]\n                    if not rest:\n                        before = len(follow[symbol])\n                        follow[symbol].update(follow[nonterminal])\n                        if len(follow[symbol]) > before:\n                            changed = True\n                    else:\n                        for next_symbol in rest:\n                            if next_symbol in grammar:\n                                before = len(follow[symbol])\n                                follow[symbol].update(first[next_symbol] - {'ε'})\n                                if len(follow[symbol]) > before:\n                                    changed = True\n                                if 'ε' not in first[next_symbol]:\n                                    break\n                            else:\n                                if next_symbol not in follow[symbol]:\n                                    follow[symbol].add(next_symbol)\n                                    changed = True\n                                break\n                        else:\n                            before = len(follow[symbol])\n                            follow[symbol].update(follow[nonterminal])\n                            if len(follow[symbol]) > before:\n                                changed = True\n    return follow\n\ndef build_ll1_table(grammar, start_symbol):\n    \"\"\"\n    Build LL(1) parsing table.\n    Return: dict {(nonterminal, terminal): production}\n    \"\"\"\n    first = compute_first_sets(grammar)\n    follow = compute_follow_sets(grammar, start_symbol)\n    table = {}\n\n    for nonterminal in grammar:\n        for production in grammar[nonterminal]:\n            # Compute FIRST of production\n            prod_first = set()\n\n            if production == ['ε']:\n                prod_first.add('ε')\n            else:\n                for symbol in production:\n                    if symbol not in grammar:\n                        prod_first.add(symbol)\n                        break\n                    else:\n                        prod_first.update(first[symbol] - {'ε'})\n                        if 'ε' not in first[symbol]:\n                            break\n                else:\n                    prod_first.add('ε')\n\n            # For each terminal in FIRST(production)\n            for terminal in prod_first - {'ε'}:\n                if (nonterminal, terminal) in table:\n                    raise ValueError(f\"Grammar is not LL(1): conflict at ({nonterminal}, {terminal})\")\n                table[(nonterminal, terminal)] = production\n\n            # If epsilon in FIRST(production), add for FOLLOW terminals\n            if 'ε' in prod_first:\n                for terminal in follow[nonterminal]:\n                    if (nonterminal, terminal) in table:\n                        raise ValueError(f\"Grammar is not LL(1): conflict at ({nonterminal}, {terminal})\")\n                    table[(nonterminal, terminal)] = production\n\n    return table\n\n# Test\ngrammar = {\n    'E': [['T', 'E_prime']],\n    'E_prime': [['PLUS', 'T', 'E_prime'], ['ε']],\n    'T': [['num']]\n}\ntable = build_ll1_table(grammar, 'E')\nprint(table[('E', 'num')])  # Should be ['T', 'E_prime']",
    "testCases": [
      {
        "input": "grammar1",
        "expectedOutput": "['T', 'E_prime']",
        "isHidden": false,
        "description": "LL(1) table entry for E"
      },
      {
        "input": "grammar2",
        "expectedOutput": "['ε']",
        "isHidden": true,
        "description": "Epsilon production in table"
      }
    ],
    "hints": [
      "For production A → α, add it to table[A, t] for each t in FIRST(α)",
      "If ε ∈ FIRST(α), also add it for each t in FOLLOW(A)",
      "If any table entry has multiple productions, grammar is not LL(1)",
      "Use FIRST and FOLLOW sets computed earlier"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex05",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Table-Driven LL(1) Parser",
    "difficulty": 3,
    "description": "Implement a table-driven LL(1) parser using a parse table and stack.",
    "starterCode": "def ll1_parse(grammar, parse_table, start_symbol, tokens):\n    \"\"\"\n    Parse tokens using LL(1) parse table.\n    Return parse tree or raise SyntaxError.\n    tokens: list ending with '$'\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'E': [['T', 'E_prime']],\n    'E_prime': [['PLUS', 'T', 'E_prime'], ['ε']],\n    'T': [['num']]\n}\ntable = {\n    ('E', 'num'): ['T', 'E_prime'],\n    ('E_prime', 'PLUS'): ['PLUS', 'T', 'E_prime'],\n    ('E_prime', '$'): ['ε'],\n    ('T', 'num'): ['num']\n}\ntokens = ['num', 'PLUS', 'num', '$']\ntree = ll1_parse(grammar, table, 'E', tokens)\nprint(tree)",
    "solution": "def ll1_parse(grammar, parse_table, start_symbol, tokens):\n    \"\"\"\n    Parse tokens using LL(1) parse table.\n    Return parse tree or raise SyntaxError.\n    \"\"\"\n    stack = ['$', start_symbol]\n    token_idx = 0\n    parse_tree = {start_symbol: []}\n\n    while stack:\n        top = stack.pop()\n        current_token = tokens[token_idx] if token_idx < len(tokens) else '$'\n\n        if top == '$':\n            if current_token == '$':\n                return parse_tree\n            else:\n                raise SyntaxError(\"Unexpected tokens at end\")\n\n        elif top == 'ε':\n            # Epsilon, skip\n            continue\n\n        elif top not in grammar:\n            # Terminal\n            if top == current_token:\n                token_idx += 1\n            else:\n                raise SyntaxError(f\"Expected {top}, got {current_token}\")\n\n        else:\n            # Nonterminal - use parse table\n            if (top, current_token) not in parse_table:\n                raise SyntaxError(f\"No parse table entry for ({top}, {current_token})\")\n\n            production = parse_table[(top, current_token)]\n\n            # Push production in reverse order\n            for symbol in reversed(production):\n                if symbol != 'ε':\n                    stack.append(symbol)\n\n    if token_idx < len(tokens) - 1:\n        raise SyntaxError(\"Not all tokens consumed\")\n\n    return \"Accepted\"\n\n# More sophisticated version with tree building\ndef ll1_parse_with_tree(grammar, parse_table, start_symbol, tokens):\n    \"\"\"Parse and build explicit tree structure\"\"\"\n    stack = [('$', None), (start_symbol, None)]\n    token_idx = 0\n    nodes = {}\n    node_id = 0\n\n    def make_node(symbol):\n        nonlocal node_id\n        nid = node_id\n        node_id += 1\n        nodes[nid] = {'symbol': symbol, 'children': []}\n        return nid\n\n    root_id = make_node(start_symbol)\n    stack = [('$', None), (start_symbol, root_id)]\n\n    while stack:\n        top, parent_id = stack.pop()\n        current_token = tokens[token_idx] if token_idx < len(tokens) else '$'\n\n        if top == '$':\n            if current_token == '$':\n                return nodes[root_id]\n            else:\n                raise SyntaxError(\"Unexpected tokens at end\")\n\n        elif top == 'ε':\n            continue\n\n        elif top not in grammar:\n            # Terminal\n            if top == current_token:\n                child_id = make_node(top)\n                nodes[parent_id]['children'].append(child_id)\n                token_idx += 1\n            else:\n                raise SyntaxError(f\"Expected {top}, got {current_token}\")\n\n        else:\n            # Nonterminal\n            if (top, current_token) not in parse_table:\n                raise SyntaxError(f\"No parse table entry for ({top}, {current_token})\")\n\n            production = parse_table[(top, current_token)]\n\n            # Create children and push onto stack\n            child_ids = []\n            for symbol in production:\n                if symbol != 'ε':\n                    child_id = make_node(symbol)\n                    child_ids.append(child_id)\n\n            nodes[parent_id]['children'] = child_ids\n\n            for symbol, cid in zip(reversed(production), reversed(child_ids)):\n                if symbol != 'ε':\n                    stack.append((symbol, cid))\n\n    return nodes[root_id]\n\n# Test\ngrammar = {\n    'E': [['T', 'E_prime']],\n    'E_prime': [['PLUS', 'T', 'E_prime'], ['ε']],\n    'T': [['num']]\n}\ntable = {\n    ('E', 'num'): ['T', 'E_prime'],\n    ('E_prime', 'PLUS'): ['PLUS', 'T', 'E_prime'],\n    ('E_prime', '$'): ['ε'],\n    ('T', 'num'): ['num']\n}\ntokens = ['num', 'PLUS', 'num', '$']\ntree = ll1_parse(grammar, table, 'E', tokens)\nprint(tree)",
    "testCases": [
      {
        "input": "['num', '$']",
        "expectedOutput": "Accepted",
        "isHidden": false,
        "description": "Single number"
      },
      {
        "input": "['num', 'PLUS', 'num', '$']",
        "expectedOutput": "Accepted",
        "isHidden": false,
        "description": "Addition expression"
      },
      {
        "input": "['num', 'num', '$']",
        "expectedOutput": "SyntaxError",
        "isHidden": true,
        "description": "Invalid syntax"
      }
    ],
    "hints": [
      "Use a stack initialized with [$, start_symbol]",
      "Match terminals, expand nonterminals using table",
      "Pop from stack and compare with current input token",
      "Accept when stack is $ and input is $"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex06",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "LR(0) Items and Closures",
    "difficulty": 4,
    "description": "Compute the closure of LR(0) items, used in LR parser construction.",
    "starterCode": "def lr0_closure(items, grammar):\n    \"\"\"\n    Compute closure of LR(0) items.\n    items: set of (production, dot_position) tuples\n    grammar: dict {nonterminal: [[production], ...]}\n    Return: set of items in closure\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    \"S'\": [['E']],\n    'E': [['E', '+', 'T'], ['T']],\n    'T': [['num']]\n}\nitems = {(\"S'\", ('E',), 0)}  # S' → •E\nclosure = lr0_closure(items, grammar)\nprint(closure)",
    "solution": "def lr0_closure(items, grammar):\n    \"\"\"\n    Compute closure of LR(0) items.\n    items: set of (nonterminal, production, dot_position) tuples\n    grammar: dict {nonterminal: [[production], ...]}\n    Return: set of items in closure\n    \"\"\"\n    closure = set(items)\n    changed = True\n\n    while changed:\n        changed = False\n        new_items = set()\n\n        for nonterminal, production, dot in closure:\n            # If dot is before a nonterminal\n            if dot < len(production):\n                next_symbol = production[dot]\n\n                if next_symbol in grammar:\n                    # Add all productions of next_symbol with dot at start\n                    for prod in grammar[next_symbol]:\n                        item = (next_symbol, tuple(prod), 0)\n                        if item not in closure:\n                            new_items.add(item)\n                            changed = True\n\n        closure.update(new_items)\n\n    return closure\n\n# Test\ngrammar = {\n    \"S'\": [['E']],\n    'E': [['E', '+', 'T'], ['T']],\n    'T': [['num']]\n}\nitems = {(\"S'\", ('E',), 0)}  # S' → •E\nclosure = lr0_closure(items, grammar)\nprint(closure)",
    "testCases": [
      {
        "input": "items1",
        "expectedOutput": "Contains E → •E + T, E → •T, T → •num",
        "isHidden": false,
        "description": "Closure of start item"
      },
      {
        "input": "items2",
        "expectedOutput": "Only original items",
        "isHidden": true,
        "description": "Closure with no additions"
      }
    ],
    "hints": [
      "An LR(0) item is a production with a dot marking position",
      "Closure adds items for nonterminals after the dot",
      "If A → α•Bβ is in closure, add B → •γ for all B productions",
      "Iterate until no new items are added"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex07",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "LR(0) GOTO Function",
    "difficulty": 4,
    "description": "Implement the GOTO function that computes the next state in LR parsing.",
    "starterCode": "def lr0_goto(items, symbol, grammar):\n    \"\"\"\n    Compute GOTO(items, symbol) for LR(0) parsing.\n    Move dot over symbol and compute closure.\n    items: set of (nonterminal, production, dot) items\n    symbol: grammar symbol to process\n    Return: set of items\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'T'], ['T']],\n    'T': [['num']]\n}\nitems = {('E', ('E', '+', 'T'), 0), ('E', ('T',), 0)}\ngoto_result = lr0_goto(items, 'T', grammar)\nprint(goto_result)",
    "solution": "def lr0_closure(items, grammar):\n    \"\"\"Compute closure of LR(0) items\"\"\"\n    closure = set(items)\n    changed = True\n\n    while changed:\n        changed = False\n        new_items = set()\n\n        for nonterminal, production, dot in closure:\n            if dot < len(production):\n                next_symbol = production[dot]\n                if next_symbol in grammar:\n                    for prod in grammar[next_symbol]:\n                        item = (next_symbol, tuple(prod), 0)\n                        if item not in closure:\n                            new_items.add(item)\n                            changed = True\n\n        closure.update(new_items)\n\n    return closure\n\ndef lr0_goto(items, symbol, grammar):\n    \"\"\"\n    Compute GOTO(items, symbol) for LR(0) parsing.\n    Move dot over symbol and compute closure.\n    \"\"\"\n    # Find items with dot before symbol\n    moved_items = set()\n\n    for nonterminal, production, dot in items:\n        if dot < len(production) and production[dot] == symbol:\n            # Move dot one position\n            moved_items.add((nonterminal, production, dot + 1))\n\n    # Compute closure of moved items\n    if moved_items:\n        return lr0_closure(moved_items, grammar)\n    else:\n        return set()\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'T'], ['T']],\n    'T': [['num']]\n}\nitems = {('E', ('E', '+', 'T'), 0), ('E', ('T',), 0)}\ngoto_result = lr0_goto(items, 'T', grammar)\nprint(goto_result)",
    "testCases": [
      {
        "input": "(items, 'T')",
        "expectedOutput": "{('E', ('T',), 1)}",
        "isHidden": false,
        "description": "GOTO on T"
      },
      {
        "input": "(items, 'E')",
        "expectedOutput": "{('E', ('E', '+', 'T'), 1)}",
        "isHidden": true,
        "description": "GOTO on E"
      }
    ],
    "hints": [
      "GOTO(I, X) moves the dot over symbol X",
      "For each item A → α•Xβ, create A → αX•β",
      "Then compute closure of the resulting items",
      "Return empty set if no items have X after the dot"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex08",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "SLR Parse Table Construction",
    "difficulty": 5,
    "description": "Build an SLR(1) parse table with shift, reduce, and accept actions.",
    "starterCode": "def build_slr_table(grammar, start_symbol):\n    \"\"\"\n    Build SLR(1) parsing table.\n    Return: (action_table, goto_table, states)\n    action_table: {(state, terminal): ('shift', next_state) | ('reduce', production) | 'accept'}\n    goto_table: {(state, nonterminal): next_state}\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    \"S'\": [['E']],\n    'E': [['E', '+', 'n'], ['n']]\n}\naction, goto, states = build_slr_table(grammar, \"S'\")\nprint(f\"Number of states: {len(states)}\")",
    "solution": "def compute_follow_sets(grammar, start_symbol):\n    \"\"\"Compute FOLLOW sets for SLR\"\"\"\n    # Simplified version\n    follow = {nt: set() for nt in grammar}\n    follow[start_symbol].add('$')\n\n    changed = True\n    while changed:\n        changed = False\n        for nt in grammar:\n            for prod in grammar[nt]:\n                for i, symbol in enumerate(prod):\n                    if symbol not in grammar:\n                        continue\n                    # Add what follows symbol\n                    if i + 1 < len(prod):\n                        next_sym = prod[i + 1]\n                        if next_sym not in grammar:\n                            if next_sym not in follow[symbol]:\n                                follow[symbol].add(next_sym)\n                                changed = True\n                    else:\n                        # Symbol is last\n                        before = len(follow[symbol])\n                        follow[symbol].update(follow[nt])\n                        if len(follow[symbol]) > before:\n                            changed = True\n    return follow\n\ndef lr0_closure(items, grammar):\n    \"\"\"Compute closure\"\"\"\n    closure = set(items)\n    changed = True\n    while changed:\n        changed = False\n        new_items = set()\n        for nonterminal, production, dot in closure:\n            if dot < len(production):\n                next_symbol = production[dot]\n                if next_symbol in grammar:\n                    for prod in grammar[next_symbol]:\n                        item = (next_symbol, tuple(prod), 0)\n                        if item not in closure:\n                            new_items.add(item)\n                            changed = True\n        closure.update(new_items)\n    return closure\n\ndef lr0_goto(items, symbol, grammar):\n    \"\"\"Compute GOTO\"\"\"\n    moved_items = set()\n    for nonterminal, production, dot in items:\n        if dot < len(production) and production[dot] == symbol:\n            moved_items.add((nonterminal, production, dot + 1))\n    if moved_items:\n        return lr0_closure(moved_items, grammar)\n    return set()\n\ndef build_slr_table(grammar, start_symbol):\n    \"\"\"Build SLR(1) parsing table\"\"\"\n    # Get all symbols\n    all_symbols = set()\n    for prods in grammar.values():\n        for prod in prods:\n            all_symbols.update(prod)\n\n    terminals = (all_symbols - set(grammar.keys())) | {'$'}\n    nonterminals = set(grammar.keys())\n\n    # Build canonical collection of LR(0) items\n    start_items = lr0_closure({(start_symbol, tuple(grammar[start_symbol][0]), 0)}, grammar)\n    states = [start_items]\n    state_map = {frozenset(start_items): 0}\n    unmarked = [0]\n\n    while unmarked:\n        state_id = unmarked.pop()\n        items = states[state_id]\n\n        for symbol in all_symbols | nonterminals:\n            goto_items = lr0_goto(items, symbol, grammar)\n            if goto_items:\n                goto_frozen = frozenset(goto_items)\n                if goto_frozen not in state_map:\n                    state_map[goto_frozen] = len(states)\n                    states.append(goto_items)\n                    unmarked.append(len(states) - 1)\n\n    # Build ACTION and GOTO tables\n    action = {}\n    goto = {}\n    follow = compute_follow_sets(grammar, start_symbol)\n\n    for state_id, items in enumerate(states):\n        for nt, prod, dot in items:\n            if dot < len(prod):\n                next_symbol = prod[dot]\n                goto_items = lr0_goto(items, next_symbol, grammar)\n                if goto_items:\n                    goto_frozen = frozenset(goto_items)\n                    next_state = state_map[goto_frozen]\n\n                    if next_symbol in terminals:\n                        # Shift\n                        action[(state_id, next_symbol)] = ('shift', next_state)\n                    elif next_symbol in nonterminals:\n                        # GOTO\n                        goto[(state_id, next_symbol)] = next_state\n            else:\n                # Reduce item\n                if nt == start_symbol:\n                    # Accept\n                    action[(state_id, '$')] = 'accept'\n                else:\n                    # Reduce by production\n                    for terminal in follow[nt]:\n                        action[(state_id, terminal)] = ('reduce', (nt, prod))\n\n    return action, goto, states\n\n# Test\ngrammar = {\n    \"S'\": [['E']],\n    'E': [['E', '+', 'n'], ['n']]\n}\naction, goto, states = build_slr_table(grammar, \"S'\")\nprint(f\"Number of states: {len(states)}\")",
    "testCases": [
      {
        "input": "grammar1",
        "expectedOutput": "5 states",
        "isHidden": false,
        "description": "Simple expression grammar"
      },
      {
        "input": "grammar2",
        "expectedOutput": "Valid SLR table",
        "isHidden": true,
        "description": "More complex grammar"
      }
    ],
    "hints": [
      "Build canonical collection of LR(0) item sets",
      "For items with dot before terminal, add shift actions",
      "For complete items A → α•, add reduce for terminals in FOLLOW(A)",
      "GOTO table handles nonterminal transitions",
      "Detect conflicts: multiple actions for same (state, symbol)"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex09",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Shift-Reduce Parser",
    "difficulty": 4,
    "description": "Implement a shift-reduce parser using an SLR parse table.",
    "starterCode": "def shift_reduce_parse(action_table, goto_table, tokens):\n    \"\"\"\n    Parse tokens using shift-reduce parsing.\n    tokens: list ending with '$'\n    Return: list of parse actions taken\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\naction = {\n    (0, 'n'): ('shift', 2),\n    (0, '$'): ('reduce', ('E', ('n',))),\n    (2, '$'): ('reduce', ('E', ('n',))),\n    (1, '$'): 'accept'\n}\ngoto = {(0, 'E'): 1}\ntokens = ['n', '$']\nactions = shift_reduce_parse(action, goto, tokens)\nprint(actions)",
    "solution": "def shift_reduce_parse(action_table, goto_table, tokens):\n    \"\"\"\n    Parse tokens using shift-reduce parsing.\n    tokens: list ending with '$'\n    Return: list of parse actions taken\n    \"\"\"\n    stack = [0]  # State stack\n    symbol_stack = []  # Symbol stack\n    token_idx = 0\n    actions_taken = []\n\n    while True:\n        state = stack[-1]\n        token = tokens[token_idx]\n\n        if (state, token) not in action_table:\n            raise SyntaxError(f\"No action for state {state}, token {token}\")\n\n        action = action_table[(state, token)]\n\n        if action == 'accept':\n            actions_taken.append('accept')\n            return actions_taken\n\n        elif action[0] == 'shift':\n            next_state = action[1]\n            actions_taken.append(f\"shift {token} to state {next_state}\")\n            stack.append(next_state)\n            symbol_stack.append(token)\n            token_idx += 1\n\n        elif action[0] == 'reduce':\n            nonterminal, production = action[1]\n            actions_taken.append(f\"reduce by {nonterminal} → {' '.join(production)}\")\n\n            # Pop production length from stacks\n            prod_len = len(production)\n            for _ in range(prod_len):\n                stack.pop()\n                if symbol_stack:\n                    symbol_stack.pop()\n\n            # Push nonterminal\n            symbol_stack.append(nonterminal)\n\n            # GOTO\n            state = stack[-1]\n            if (state, nonterminal) not in goto_table:\n                raise SyntaxError(f\"No GOTO for state {state}, nonterminal {nonterminal}\")\n\n            next_state = goto_table[(state, nonterminal)]\n            stack.append(next_state)\n\n        else:\n            raise SyntaxError(f\"Unknown action: {action}\")\n\n# Test\naction = {\n    (0, 'n'): ('shift', 2),\n    (2, '$'): ('reduce', ('E', ('n',))),\n    (1, '$'): 'accept',\n    (0, 'E'): None  # This would be in goto table\n}\ngoto = {(0, 'E'): 1}\ntokens = ['n', '$']\nactions = shift_reduce_parse(action, goto, tokens)\nprint(actions)",
    "testCases": [
      {
        "input": "['n', '$']",
        "expectedOutput": "['shift', 'reduce', 'accept']",
        "isHidden": false,
        "description": "Parse single number"
      },
      {
        "input": "['n', '+', 'n', '$']",
        "expectedOutput": "shift/reduce sequence",
        "isHidden": true,
        "description": "Parse addition"
      }
    ],
    "hints": [
      "Maintain two stacks: state stack and symbol stack",
      "Shift: push token and next state",
      "Reduce: pop production length, push nonterminal, use GOTO",
      "Accept: when reaching accept action",
      "Handle errors when no action exists"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex10",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Parse Tree Construction",
    "difficulty": 3,
    "description": "Build an explicit parse tree data structure during recursive descent parsing.",
    "starterCode": "class ParseNode:\n    def __init__(self, symbol, children=None):\n        self.symbol = symbol\n        self.children = children or []\n\n    def __repr__(self):\n        return f\"ParseNode({self.symbol}, {self.children})\"\n\nclass Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n\n    def parse(self):\n        \"\"\"Parse and return parse tree\"\"\"\n        # Your code here\n        pass\n\n# Test\ntokens = [('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\ntree = parser.parse()\nprint(tree)",
    "solution": "class ParseNode:\n    def __init__(self, symbol, children=None, value=None):\n        self.symbol = symbol\n        self.children = children or []\n        self.value = value\n\n    def __repr__(self, level=0):\n        indent = \"  \" * level\n        if self.children:\n            children_repr = \"\\n\".join(c.__repr__(level + 1) for c in self.children)\n            return f\"{indent}{self.symbol}\\n{children_repr}\"\n        else:\n            val = f\"={self.value}\" if self.value is not None else \"\"\n            return f\"{indent}{self.symbol}{val}\"\n\nclass Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n\n    def peek(self):\n        return self.tokens[self.pos] if self.pos < len(self.tokens) else None\n\n    def consume(self, expected_type):\n        token = self.peek()\n        if not token or token[0] != expected_type:\n            raise SyntaxError(f\"Expected {expected_type}, got {token}\")\n        self.pos += 1\n        return token\n\n    def parse(self):\n        \"\"\"Parse and return parse tree for expression\"\"\"\n        return self.parse_expression()\n\n    def parse_expression(self):\n        \"\"\"E → T + E | T\"\"\"\n        node = ParseNode('E')\n        left = self.parse_term()\n        node.children.append(left)\n\n        if self.peek() and self.peek()[0] == 'PLUS':\n            plus_token = self.consume('PLUS')\n            plus_node = ParseNode('PLUS', value=plus_token[1])\n            node.children.append(plus_node)\n\n            right = self.parse_expression()\n            node.children.append(right)\n\n        return node\n\n    def parse_term(self):\n        \"\"\"T → num\"\"\"\n        token = self.consume('NUMBER')\n        return ParseNode('NUMBER', value=token[1])\n\n# Test\ntokens = [('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\ntree = parser.parse()\nprint(tree)",
    "testCases": [
      {
        "input": "[('NUMBER', 5)]",
        "expectedOutput": "Tree with single NUMBER node",
        "isHidden": false,
        "description": "Single number tree"
      },
      {
        "input": "[('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]",
        "expectedOutput": "Tree with E → NUMBER PLUS E structure",
        "isHidden": false,
        "description": "Addition tree"
      },
      {
        "input": "[('NUMBER', 1), ('PLUS', '+'), ('NUMBER', 2), ('PLUS', '+'), ('NUMBER', 3)]",
        "expectedOutput": "Right-associative tree",
        "isHidden": true,
        "description": "Chain of additions"
      }
    ],
    "hints": [
      "Create ParseNode objects for each grammar symbol",
      "Attach children when recursively parsing sub-expressions",
      "Store token values in leaf nodes",
      "Return the root node from each parsing method"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex11",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Left Factoring",
    "difficulty": 3,
    "description": "Transform a grammar by left factoring to eliminate common prefixes, making it suitable for LL parsing.",
    "starterCode": "def left_factor(grammar):\n    \"\"\"\n    Transform grammar by left factoring.\n    grammar: dict {nonterminal: [[production], ...]}\n    Return: transformed grammar\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'A': [['a', 'b'], ['a', 'c']]\n}\nfactored = left_factor(grammar)\nprint(factored)  # Should factor out common 'a'",
    "solution": "def left_factor(grammar):\n    \"\"\"\n    Transform grammar by left factoring.\n    Finds common prefixes and factors them out.\n    \"\"\"\n    new_grammar = {}\n    suffix_counter = {}\n\n    for nonterminal in grammar:\n        productions = grammar[nonterminal]\n\n        # Group productions by common prefix\n        prefix_groups = {}\n\n        for prod in productions:\n            if not prod:\n                continue\n\n            # Find longest common prefix with other productions\n            prefix = tuple([prod[0]])  # Start with first symbol\n\n            # Could extend to find longer prefixes\n            if prefix not in prefix_groups:\n                prefix_groups[prefix] = []\n            prefix_groups[prefix].append(prod)\n\n        # Build new productions\n        new_prods = []\n\n        for prefix, group in prefix_groups.items():\n            if len(group) > 1:\n                # Need to factor\n                # Create new nonterminal\n                if nonterminal not in suffix_counter:\n                    suffix_counter[nonterminal] = 0\n                suffix_counter[nonterminal] += 1\n                new_nt = f\"{nonterminal}_prime{suffix_counter[nonterminal]}\"\n\n                # Add: A → prefix A'\n                new_prods.append(list(prefix) + [new_nt])\n\n                # Add: A' → suffix1 | suffix2 | ...\n                new_grammar[new_nt] = []\n                for prod in group:\n                    suffix = prod[len(prefix):]\n                    if not suffix:\n                        suffix = ['ε']\n                    new_grammar[new_nt].append(suffix)\n            else:\n                # No factoring needed\n                new_prods.append(group[0])\n\n        new_grammar[nonterminal] = new_prods\n\n    return new_grammar\n\n# More sophisticated version\ndef left_factor_advanced(grammar):\n    \"\"\"\n    Left factor with longest common prefix detection.\n    \"\"\"\n    def longest_common_prefix(prods):\n        \"\"\"Find longest common prefix among productions\"\"\"\n        if not prods or len(prods) < 2:\n            return []\n\n        prefix = []\n        min_len = min(len(p) for p in prods)\n\n        for i in range(min_len):\n            symbols = [p[i] for p in prods]\n            if all(s == symbols[0] for s in symbols):\n                prefix.append(symbols[0])\n            else:\n                break\n\n        return prefix\n\n    new_grammar = dict(grammar)\n    changed = True\n    counter = 0\n\n    while changed:\n        changed = False\n\n        for nonterminal in list(new_grammar.keys()):\n            productions = new_grammar[nonterminal]\n\n            # Try to find productions with common prefix\n            for i in range(len(productions)):\n                for j in range(i + 1, len(productions)):\n                    prefix = longest_common_prefix([productions[i], productions[j]])\n\n                    if prefix:\n                        # Found common prefix - factor it out\n                        changed = True\n                        counter += 1\n                        new_nt = f\"{nonterminal}_prime{counter}\"\n\n                        # Collect all productions with this prefix\n                        with_prefix = []\n                        without_prefix = []\n\n                        for prod in productions:\n                            if prod[:len(prefix)] == prefix:\n                                with_prefix.append(prod)\n                            else:\n                                without_prefix.append(prod)\n\n                        # Create new productions\n                        new_grammar[nonterminal] = without_prefix + [prefix + [new_nt]]\n                        new_grammar[new_nt] = []\n\n                        for prod in with_prefix:\n                            suffix = prod[len(prefix):]\n                            if not suffix:\n                                suffix = ['ε']\n                            new_grammar[new_nt].append(suffix)\n\n                        break\n                if changed:\n                    break\n            if changed:\n                break\n\n    return new_grammar\n\n# Test\ngrammar = {\n    'A': [['a', 'b'], ['a', 'c']]\n}\nfactored = left_factor(grammar)\nprint(factored)",
    "testCases": [
      {
        "input": "{'A': [['a', 'b'], ['a', 'c']]}",
        "expectedOutput": "A → a A', A' → b | c",
        "isHidden": false,
        "description": "Simple left factoring"
      },
      {
        "input": "{'S': [['if', 'expr', 'then', 'stmt'], ['if', 'expr', 'then', 'stmt', 'else', 'stmt']]}",
        "expectedOutput": "Factored if-then-else",
        "isHidden": true,
        "description": "Dangling else factoring"
      }
    ],
    "hints": [
      "Find productions with common prefixes",
      "Create a new nonterminal for the suffixes",
      "Replace A → αβ | αγ with A → αA', A' → β | γ",
      "May need to iterate until no more factoring is possible"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex12",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Left Recursion Elimination",
    "difficulty": 4,
    "description": "Eliminate left recursion from a grammar to make it suitable for top-down parsing.",
    "starterCode": "def eliminate_left_recursion(grammar):\n    \"\"\"\n    Eliminate immediate left recursion.\n    Transform A → Aα | β into A → βA', A' → αA' | ε\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'T'], ['T']]\n}\ntransformed = eliminate_left_recursion(grammar)\nprint(transformed)",
    "solution": "def eliminate_left_recursion(grammar):\n    \"\"\"\n    Eliminate immediate left recursion.\n    Transform A → Aα | β into A → βA', A' → αA' | ε\n    \"\"\"\n    new_grammar = {}\n\n    for nonterminal in grammar:\n        productions = grammar[nonterminal]\n\n        # Separate into left-recursive and non-left-recursive\n        left_recursive = []\n        non_left_recursive = []\n\n        for prod in productions:\n            if prod and prod[0] == nonterminal:\n                # Left recursive: A → Aα\n                left_recursive.append(prod[1:])  # α\n            else:\n                # Not left recursive: A → β\n                non_left_recursive.append(prod)\n\n        if not left_recursive:\n            # No left recursion\n            new_grammar[nonterminal] = productions\n        else:\n            # Eliminate left recursion\n            new_nt = f\"{nonterminal}_prime\"\n\n            # A → βA' for each β\n            new_grammar[nonterminal] = []\n            for beta in non_left_recursive:\n                new_grammar[nonterminal].append(beta + [new_nt])\n\n            # A' → αA' | ε for each α\n            new_grammar[new_nt] = []\n            for alpha in left_recursive:\n                new_grammar[new_nt].append(alpha + [new_nt])\n            new_grammar[new_nt].append(['ε'])\n\n    return new_grammar\n\n# General left recursion elimination (handles indirect)\ndef eliminate_all_left_recursion(grammar):\n    \"\"\"\n    Eliminate all left recursion including indirect.\n    Uses the algorithm that orders nonterminals.\n    \"\"\"\n    nonterminals = list(grammar.keys())\n    new_grammar = dict(grammar)\n\n    # Order nonterminals A1, A2, ..., An\n    for i in range(len(nonterminals)):\n        Ai = nonterminals[i]\n\n        # Eliminate Ai → Aj γ where j < i\n        for j in range(i):\n            Aj = nonterminals[j]\n            new_productions = []\n\n            for prod in new_grammar[Ai]:\n                if prod and prod[0] == Aj:\n                    # Replace Ai → Aj γ with Ai → δ1 γ | δ2 γ | ...\n                    # where Aj → δ1 | δ2 | ...\n                    gamma = prod[1:]\n                    for aj_prod in new_grammar[Aj]:\n                        new_productions.append(aj_prod + gamma)\n                else:\n                    new_productions.append(prod)\n\n            new_grammar[Ai] = new_productions\n\n        # Eliminate immediate left recursion for Ai\n        new_grammar = {**new_grammar, **eliminate_left_recursion({Ai: new_grammar[Ai]})}\n\n    return new_grammar\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'T'], ['T']]\n}\ntransformed = eliminate_left_recursion(grammar)\nprint(transformed)",
    "testCases": [
      {
        "input": "{'E': [['E', '+', 'T'], ['T']]}",
        "expectedOutput": "E → T E', E' → + T E' | ε",
        "isHidden": false,
        "description": "Immediate left recursion"
      },
      {
        "input": "{'S': [['S', 'a'], ['b']]}",
        "expectedOutput": "S → b S', S' → a S' | ε",
        "isHidden": true,
        "description": "Simple left recursion"
      }
    ],
    "hints": [
      "Separate productions into left-recursive (A → Aα) and others (A → β)",
      "Create new nonterminal A'",
      "Replace with A → βA' and A' → αA' | ε",
      "For indirect recursion, use substitution algorithm"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex13",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Operator Precedence Parser",
    "difficulty": 4,
    "description": "Implement an operator precedence parser using precedence relations between operators.",
    "starterCode": "def precedence_parse(tokens, precedence):\n    \"\"\"\n    Parse using operator precedence.\n    precedence: dict {operator: level}, higher = higher precedence\n    tokens: list of numbers and operators\n    Return: parse tree\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nprecedence = {'+': 1, '*': 2}\ntokens = [5, '+', 3, '*', 2]\ntree = precedence_parse(tokens, precedence)\nprint(tree)",
    "solution": "def precedence_parse(tokens, precedence):\n    \"\"\"\n    Parse using operator precedence.\n    Uses a simple precedence climbing algorithm.\n    \"\"\"\n    def parse_expression(min_precedence):\n        nonlocal pos\n\n        # Parse left operand (number)\n        if pos >= len(tokens) or not isinstance(tokens[pos], int):\n            raise SyntaxError(f\"Expected number at position {pos}\")\n\n        left = tokens[pos]\n        pos += 1\n\n        # Process operators\n        while pos < len(tokens) and tokens[pos] in precedence:\n            op = tokens[pos]\n            op_precedence = precedence[op]\n\n            if op_precedence < min_precedence:\n                break\n\n            pos += 1\n\n            # Parse right operand with higher precedence\n            right = parse_expression(op_precedence + 1)\n\n            # Build tree node\n            left = (op, left, right)\n\n        return left\n\n    pos = 0\n    result = parse_expression(0)\n    return result\n\n# Alternative: Using stack-based operator precedence\ndef precedence_parse_stack(tokens, precedence):\n    \"\"\"\n    Parse using stack-based operator precedence.\n    \"\"\"\n    operand_stack = []\n    operator_stack = []\n\n    def apply_operator():\n        if len(operand_stack) < 2:\n            raise SyntaxError(\"Not enough operands\")\n        right = operand_stack.pop()\n        left = operand_stack.pop()\n        op = operator_stack.pop()\n        operand_stack.append((op, left, right))\n\n    i = 0\n    while i < len(tokens):\n        token = tokens[i]\n\n        if isinstance(token, int):\n            # Operand\n            operand_stack.append(token)\n        elif token in precedence:\n            # Operator\n            while (operator_stack and\n                   operator_stack[-1] in precedence and\n                   precedence[operator_stack[-1]] >= precedence[token]):\n                apply_operator()\n\n            operator_stack.append(token)\n        else:\n            raise SyntaxError(f\"Unknown token: {token}\")\n\n        i += 1\n\n    # Apply remaining operators\n    while operator_stack:\n        apply_operator()\n\n    if len(operand_stack) != 1:\n        raise SyntaxError(\"Invalid expression\")\n\n    return operand_stack[0]\n\n# Test\nprecedence = {'+': 1, '*': 2}\ntokens = [5, '+', 3, '*', 2]\ntree = precedence_parse(tokens, precedence)\nprint(tree)",
    "testCases": [
      {
        "input": "[5, \"+\", 3]",
        "expectedOutput": "(\"+\", 5, 3)",
        "isHidden": false,
        "description": "Simple addition"
      },
      {
        "input": "[5, \"+\", 3, \"*\", 2]",
        "expectedOutput": "(\"+\", 5, (\"*\", 3, 2))",
        "isHidden": false,
        "description": "Precedence: multiplication before addition"
      },
      {
        "input": "[2, \"*\", 3, \"+\", 4, \"*\", 5]",
        "expectedOutput": "(\"+\", (\"*\", 2, 3), (\"*\", 4, 5))",
        "isHidden": true,
        "description": "Mixed precedence"
      }
    ],
    "hints": [
      "Use precedence levels to decide when to reduce",
      "Higher precedence binds tighter",
      "Can use precedence climbing or stack-based approach",
      "Build tree nodes as you reduce operators"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex14",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Abstract Syntax Tree (AST)",
    "difficulty": 3,
    "description": "Convert a parse tree into an Abstract Syntax Tree by removing unnecessary nodes.",
    "starterCode": "def parse_tree_to_ast(parse_tree):\n    \"\"\"\n    Convert parse tree to AST.\n    Remove intermediate nonterminals, keep only essential structure.\n    parse_tree: nested tuple structure\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nparse_tree = ('E', ('T', ('num', 5)), ('+', '+'), ('E', ('T', ('num', 3))))\nast = parse_tree_to_ast(parse_tree)\nprint(ast)  # Should be simpler: ('+', 5, 3)",
    "solution": "def parse_tree_to_ast(parse_tree):\n    \"\"\"\n    Convert parse tree to AST.\n    Remove intermediate nonterminals, keep only essential structure.\n    \"\"\"\n    if not isinstance(parse_tree, tuple):\n        return parse_tree\n\n    symbol = parse_tree[0]\n\n    # If this is a leaf node with a value\n    if len(parse_tree) == 2 and not isinstance(parse_tree[1], tuple):\n        # Leaf node like ('num', 5)\n        return parse_tree[1]\n\n    # Process children\n    children = [parse_tree_to_ast(child) for child in parse_tree[1:]]\n\n    # Filter out None and non-essential nodes\n    children = [c for c in children if c is not None]\n\n    # Simplification rules\n    if symbol in ['E', 'T', 'F', 'E_prime', 'T_prime']:\n        # Intermediate nonterminals\n        if len(children) == 1:\n            # Single child - return it directly\n            return children[0]\n        elif len(children) == 3 and children[1] in ['+', '-', '*', '/']:\n            # Binary operation: left op right\n            return (children[1], children[0], children[2])\n        elif len(children) == 2:\n            # Could be unary or other structure\n            if children[0] in ['+', '-', '*', '/']:\n                # Operator followed by operand\n                return (children[0], children[1])\n            else:\n                return children[1]\n\n    # Operator nodes\n    if symbol in ['+', '-', '*', '/', 'PLUS', 'MINUS', 'MULTIPLY', 'DIVIDE']:\n        return symbol\n\n    # Default: return simplified structure\n    if len(children) == 1:\n        return children[0]\n    else:\n        return (symbol, *children)\n\n# More sophisticated version\nclass ASTNode:\n    def __init__(self, type, value=None, children=None):\n        self.type = type\n        self.value = value\n        self.children = children or []\n\n    def __repr__(self):\n        if self.value is not None:\n            return f\"AST({self.type}={self.value})\"\n        elif self.children:\n            children_str = \", \".join(repr(c) for c in self.children)\n            return f\"AST({self.type}: {children_str})\"\n        else:\n            return f\"AST({self.type})\"\n\ndef parse_tree_to_ast_nodes(parse_tree):\n    \"\"\"\n    Convert to AST using ASTNode objects.\n    \"\"\"\n    if not isinstance(parse_tree, tuple):\n        return ASTNode('literal', value=parse_tree)\n\n    symbol = parse_tree[0]\n\n    # Terminal with value\n    if len(parse_tree) == 2 and not isinstance(parse_tree[1], tuple):\n        if symbol in ['num', 'NUMBER']:\n            return ASTNode('number', value=parse_tree[1])\n        elif symbol in ['id', 'IDENTIFIER']:\n            return ASTNode('identifier', value=parse_tree[1])\n        else:\n            return ASTNode(symbol, value=parse_tree[1])\n\n    # Process children\n    children = [parse_tree_to_ast_nodes(child) for child in parse_tree[1:]]\n\n    # Simplification\n    if symbol in ['E', 'T', 'F', 'E_prime', 'T_prime']:\n        # Look for binary operation pattern\n        if len(children) == 3:\n            # Assume: left op right\n            op = children[1]\n            if hasattr(op, 'value') and op.value in ['+', '-', '*', '/']:\n                return ASTNode('binop', value=op.value, children=[children[0], children[2]])\n\n        # Single child passthrough\n        if len(children) == 1:\n            return children[0]\n\n    return ASTNode(symbol, children=children)\n\n# Test\nparse_tree = ('E', ('T', ('num', 5)), ('+', '+'), ('E', ('T', ('num', 3))))\nast = parse_tree_to_ast(parse_tree)\nprint(ast)",
    "testCases": [
      {
        "input": "('num', 5)",
        "expectedOutput": "5",
        "isHidden": false,
        "description": "Leaf node"
      },
      {
        "input": "('E', ('T', ('num', 5)), ('+', '+'), ('E', ('T', ('num', 3))))",
        "expectedOutput": "('+', 5, 3)",
        "isHidden": false,
        "description": "Binary operation"
      },
      {
        "input": "complex_parse_tree",
        "expectedOutput": "Simplified AST",
        "isHidden": true,
        "description": "Nested expression"
      }
    ],
    "hints": [
      "AST omits syntactic details like intermediate nonterminals",
      "Keep only semantically significant nodes",
      "Operators become parent nodes with operand children",
      "Literals become leaf nodes with values",
      "Remove chain productions (A → B where B is the only child)"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex15",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Error Recovery in Parsing",
    "difficulty": 4,
    "description": "Implement panic mode error recovery in a recursive descent parser.",
    "starterCode": "class Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n        self.errors = []\n\n    def parse_with_recovery(self, sync_tokens):\n        \"\"\"\n        Parse with error recovery.\n        sync_tokens: tokens to synchronize on after error\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\ntokens = [('NUMBER', 5), ('ERROR', '!'), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\nresult = parser.parse_with_recovery(['PLUS', 'SEMICOLON'])\nprint(f\"Errors: {parser.errors}\")",
    "solution": "class Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n        self.errors = []\n\n    def peek(self):\n        return self.tokens[self.pos] if self.pos < len(self.tokens) else None\n\n    def consume(self, expected_type):\n        token = self.peek()\n        if not token:\n            self.errors.append(f\"Unexpected end of input, expected {expected_type}\")\n            raise SyntaxError(\"EOF\")\n\n        if token[0] != expected_type:\n            self.errors.append(f\"Expected {expected_type}, got {token[0]} at position {self.pos}\")\n            raise SyntaxError(f\"Token mismatch\")\n\n        self.pos += 1\n        return token\n\n    def sync(self, sync_tokens):\n        \"\"\"Skip tokens until we find a synchronization token\"\"\"\n        while self.peek():\n            if self.peek()[0] in sync_tokens:\n                break\n            self.pos += 1\n\n    def parse_with_recovery(self, sync_tokens):\n        \"\"\"\n        Parse with error recovery.\n        sync_tokens: tokens to synchronize on after error\n        \"\"\"\n        result = []\n\n        while self.pos < len(self.tokens):\n            try:\n                node = self.parse_expression()\n                result.append(node)\n\n                # Check for statement terminator\n                if self.peek() and self.peek()[0] == 'SEMICOLON':\n                    self.consume('SEMICOLON')\n\n            except SyntaxError as e:\n                # Error recovery: sync to next safe point\n                self.sync(sync_tokens)\n\n                # Skip the sync token\n                if self.peek() and self.peek()[0] in sync_tokens:\n                    self.pos += 1\n\n        return result\n\n    def parse_expression(self):\n        \"\"\"E → T + E | T\"\"\"\n        left = self.parse_term()\n\n        if self.peek() and self.peek()[0] == 'PLUS':\n            self.consume('PLUS')\n            right = self.parse_expression()\n            return ('ADD', left, right)\n\n        return left\n\n    def parse_term(self):\n        \"\"\"T → num\"\"\"\n        token = self.consume('NUMBER')\n        return ('NUM', token[1])\n\n# More sophisticated error recovery\nclass RobustParser(Parser):\n    def parse_expression_robust(self):\n        \"\"\"Parse with local error recovery\"\"\"\n        try:\n            return self.parse_expression()\n        except SyntaxError:\n            # Try to recover by assuming a number\n            self.errors.append(f\"Recovering by inserting default value at {self.pos}\")\n            return ('NUM', 0)\n\n    def parse_term_robust(self):\n        \"\"\"Parse term with error recovery\"\"\"\n        token = self.peek()\n\n        if not token:\n            raise SyntaxError(\"EOF\")\n\n        if token[0] == 'NUMBER':\n            self.consume('NUMBER')\n            return ('NUM', token[1])\n        else:\n            # Error: expected number\n            self.errors.append(f\"Expected NUMBER, got {token[0]} at {self.pos}\")\n\n            # Skip this token and try to continue\n            self.pos += 1\n\n            # Try next token\n            if self.peek() and self.peek()[0] == 'NUMBER':\n                return self.parse_term_robust()\n            else:\n                # Give up and return error node\n                return ('ERROR', None)\n\n# Test\ntokens = [('NUMBER', 5), ('ERROR', '!'), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\nresult = parser.parse_with_recovery(['PLUS', 'SEMICOLON'])\nprint(f\"Errors: {parser.errors}\")\nprint(f\"Result: {result}\")",
    "testCases": [
      {
        "input": "valid_tokens",
        "expectedOutput": "No errors",
        "isHidden": false,
        "description": "Valid input"
      },
      {
        "input": "tokens_with_error",
        "expectedOutput": "Errors reported, parsing continues",
        "isHidden": false,
        "description": "Error recovery"
      },
      {
        "input": "multiple_errors",
        "expectedOutput": "Multiple errors detected",
        "isHidden": true,
        "description": "Multiple error recovery"
      }
    ],
    "hints": [
      "Catch syntax errors instead of aborting",
      "Skip tokens until you find a synchronization point",
      "Common sync tokens: semicolon, closing brace, keywords",
      "Report errors but continue parsing",
      "May insert/delete tokens to recover"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex16",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Earley Parser Implementation",
    "difficulty": 5,
    "description": "Implement a simplified Earley parser that can handle any context-free grammar.",
    "starterCode": "def earley_parse(grammar, start_symbol, tokens):\n    \"\"\"\n    Parse using Earley algorithm.\n    grammar: dict {nonterminal: [[production], ...]}\n    Returns: True if tokens are accepted, False otherwise\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'S': [['A', 'B']],\n    'A': [['a'], []],  # A can be epsilon\n    'B': [['b']]\n}\nprint(earley_parse(grammar, 'S', ['a', 'b']))  # True\nprint(earley_parse(grammar, 'S', ['b']))       # True",
    "solution": "def earley_parse(grammar, start_symbol, tokens):\n    \"\"\"\n    Parse using Earley algorithm.\n    Handles any CFG including ambiguous and left-recursive grammars.\n    \"\"\"\n    class EarleyItem:\n        def __init__(self, nonterminal, production, dot, start_pos):\n            self.nonterminal = nonterminal\n            self.production = production\n            self.dot = dot\n            self.start_pos = start_pos\n\n        def __eq__(self, other):\n            return (self.nonterminal == other.nonterminal and\n                    self.production == other.production and\n                    self.dot == other.dot and\n                    self.start_pos == other.start_pos)\n\n        def __hash__(self):\n            return hash((self.nonterminal, self.production, self.dot, self.start_pos))\n\n        def __repr__(self):\n            prod_str = list(self.production)\n            prod_str.insert(self.dot, '•')\n            return f\"{self.nonterminal} → {' '.join(prod_str)} ({self.start_pos})\"\n\n        def next_symbol(self):\n            return self.production[self.dot] if self.dot < len(self.production) else None\n\n        def is_complete(self):\n            return self.dot >= len(self.production)\n\n    # Initialize chart\n    chart = [set() for _ in range(len(tokens) + 1)]\n\n    # Add start rule: S' → •S\n    start_item = EarleyItem(start_symbol + \"'\", (start_symbol,), 0, 0)\n    chart[0].add(start_item)\n\n    # Process each position\n    for i in range(len(tokens) + 1):\n        changed = True\n        while changed:\n            changed = False\n            current_items = list(chart[i])\n\n            for item in current_items:\n                if item.is_complete():\n                    # Completer\n                    for earlier_item in chart[item.start_pos]:\n                        if (earlier_item.next_symbol() == item.nonterminal and\n                            not earlier_item.is_complete()):\n                            new_item = EarleyItem(\n                                earlier_item.nonterminal,\n                                earlier_item.production,\n                                earlier_item.dot + 1,\n                                earlier_item.start_pos\n                            )\n                            if new_item not in chart[i]:\n                                chart[i].add(new_item)\n                                changed = True\n\n                else:\n                    next_sym = item.next_symbol()\n\n                    if next_sym in grammar:\n                        # Predictor\n                        for production in grammar[next_sym]:\n                            new_item = EarleyItem(\n                                next_sym,\n                                tuple(production) if production else (),\n                                0,\n                                i\n                            )\n                            if new_item not in chart[i]:\n                                chart[i].add(new_item)\n                                changed = True\n\n                    elif i < len(tokens) and next_sym == tokens[i]:\n                        # Scanner\n                        new_item = EarleyItem(\n                            item.nonterminal,\n                            item.production,\n                            item.dot + 1,\n                            item.start_pos\n                        )\n                        if new_item not in chart[i + 1]:\n                            chart[i + 1].add(new_item)\n\n    # Check if parse succeeded\n    for item in chart[len(tokens)]:\n        if (item.nonterminal == start_symbol + \"'\" and\n            item.is_complete() and\n            item.start_pos == 0):\n            return True\n\n    return False\n\n# Test\ngrammar = {\n    'S': [['A', 'B']],\n    'A': [['a'], []],  # A can be epsilon\n    'B': [['b']]\n}\nprint(earley_parse(grammar, 'S', ['a', 'b']))  # True\nprint(earley_parse(grammar, 'S', ['b']))       # True\nprint(earley_parse(grammar, 'S', ['a']))       # False",
    "testCases": [
      {
        "input": "['a', 'b']",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Valid input with both symbols"
      },
      {
        "input": "['b']",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Valid input with epsilon production"
      },
      {
        "input": "['a']",
        "expectedOutput": "False",
        "isHidden": true,
        "description": "Invalid input"
      }
    ],
    "hints": [
      "Earley parser uses dynamic programming with chart parsing",
      "Three operations: Predictor (add items for nonterminals), Scanner (match terminals), Completer (finish items)",
      "Chart[i] contains all items at position i",
      "Item is (nonterminal, production, dot position, start position)",
      "Accepts if chart[n] contains S' → S• starting at 0"
    ],
    "language": "python"
  }
]
