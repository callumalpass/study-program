[
  {
    "id": "cs402-quiz-4-1",
    "subjectId": "cs402",
    "topicId": "cs402-topic-4",
    "title": "Neural Network Basics",
    "questions": [
      {
        "id": "cs402-q46",
        "type": "multiple_choice",
        "prompt": "What is a perceptron?",
        "options": [
          "A binary linear classifier: output = sign(wᵀx + b)",
          "A multi-layer neural network",
          "A kernel method",
          "A decision tree variant"
        ],
        "correctAnswer": 0,
        "explanation": "The perceptron is the simplest neural unit, computing a weighted sum and applying a threshold/sign function. It can only learn linearly separable functions."
      },
      {
        "id": "cs402-q47",
        "type": "multiple_choice",
        "prompt": "Why do neural networks need non-linear activation functions?",
        "options": [
          "Without them, multiple layers collapse to a single linear transformation",
          "To speed up training",
          "To prevent overfitting",
          "To handle missing data"
        ],
        "correctAnswer": 0,
        "explanation": "Composing linear transformations yields another linear transformation: f(Wx + b) = Wx + b without non-linearity. Activation functions enable learning complex non-linear functions."
      },
      {
        "id": "cs402-q48",
        "type": "multiple_choice",
        "prompt": "What is the most commonly used activation function in modern deep learning?",
        "options": [
          "ReLU (Rectified Linear Unit)",
          "Sigmoid",
          "Tanh",
          "Step function"
        ],
        "correctAnswer": 0,
        "explanation": "ReLU(x) = max(0,x) is popular because it's computationally efficient, doesn't saturate for positive values, and enables sparse activations. It largely replaced sigmoid/tanh in hidden layers."
      },
      {
        "id": "cs402-q49",
        "type": "multiple_choice",
        "prompt": "What algorithm is used to train neural networks?",
        "options": [
          "Backpropagation with gradient descent",
          "Decision tree induction",
          "K-means clustering",
          "Genetic algorithms"
        ],
        "correctAnswer": 0,
        "explanation": "Backpropagation efficiently computes gradients by applying the chain rule backward through the network. These gradients are used with gradient descent (or variants) to update weights."
      },
      {
        "id": "cs402-q50",
        "type": "multiple_choice",
        "prompt": "What problem can occur with sigmoid/tanh activations in deep networks?",
        "options": [
          "Vanishing gradients",
          "Exploding gradients",
          "Too fast convergence",
          "Memory overflow"
        ],
        "correctAnswer": 0,
        "explanation": "Sigmoid and tanh have small derivatives (<0.25) near their saturation regions. When multiplied across many layers during backprop, gradients exponentially decay, preventing learning in early layers."
      }
    ]
  },
  {
    "id": "cs402-quiz-4-2",
    "subjectId": "cs402",
    "topicId": "cs402-topic-4",
    "title": "Training & Regularization",
    "questions": [
      {
        "id": "cs402-q51",
        "type": "multiple_choice",
        "prompt": "Your neural network isn't learning. What should you check first?",
        "options": [
          "Learning rate and weight initialization",
          "Number of layers",
          "Activation functions",
          "Dataset size"
        ],
        "correctAnswer": 0,
        "explanation": "Learning rate too high causes divergence, too low means no progress. Poor initialization can cause dead neurons or gradient issues. These are the most common culprits for failed training."
      },
      {
        "id": "cs402-q52",
        "type": "multiple_choice",
        "prompt": "What is dropout?",
        "options": [
          "Randomly deactivating neurons during training to prevent co-adaptation",
          "Removing layers from the network",
          "Stopping training early",
          "Removing features from input"
        ],
        "correctAnswer": 0,
        "explanation": "Dropout randomly sets neuron outputs to 0 with probability p during training, forcing the network to learn redundant representations. At test time, all neurons are active but scaled by (1-p)."
      },
      {
        "id": "cs402-q53",
        "type": "multiple_choice",
        "prompt": "When should you use batch normalization?",
        "options": [
          "To stabilize training by normalizing layer inputs and enable higher learning rates",
          "To reduce model size",
          "To speed up inference",
          "To handle imbalanced classes"
        ],
        "correctAnswer": 0,
        "explanation": "Batch normalization normalizes layer inputs to have mean 0 and variance 1 per mini-batch, reducing internal covariate shift. This stabilizes training and allows higher learning rates."
      },
      {
        "id": "cs402-q54",
        "type": "multiple_choice",
        "prompt": "How many hidden units should you use?",
        "options": [
          "Start with a reasonable size and tune via validation performance",
          "Always use 100 hidden units",
          "Use exactly as many as input features",
          "Use as many as possible"
        ],
        "correctAnswer": 0,
        "explanation": "There's no universal rule. Start with a moderate size (e.g., similar to input dimension), then increase if underfitting or decrease/regularize if overfitting, guided by validation error."
      },
      {
        "id": "cs402-q55",
        "type": "multiple_choice",
        "prompt": "What is the advantage of using Adam optimizer over SGD?",
        "options": [
          "Adapts learning rate per parameter using momentum and RMSprop",
          "Guaranteed to find global minimum",
          "Requires no hyperparameters",
          "Always faster than SGD"
        ],
        "correctAnswer": 0,
        "explanation": "Adam combines momentum (exponential moving average of gradients) and RMSprop (adaptive learning rates). This often works well out-of-the-box with default hyperparameters β₁=0.9, β₂=0.999, α=0.001."
      }
    ]
  },
  {
    "id": "cs402-quiz-4-3",
    "subjectId": "cs402",
    "topicId": "cs402-topic-4",
    "title": "Backpropagation & Optimization",
    "questions": [
      {
        "id": "cs402-q56",
        "type": "multiple_choice",
        "prompt": "What is the universal approximation theorem?",
        "options": [
          "A neural network with one hidden layer can approximate any continuous function",
          "Neural networks can learn any function",
          "Deep networks are always better than shallow ones",
          "Backpropagation always finds the global minimum"
        ],
        "correctAnswer": 0,
        "explanation": "The UAT states a 2-layer network with enough hidden units can approximate any continuous function on a compact domain arbitrarily well. However, depth can make learning much more efficient."
      },
      {
        "id": "cs402-q57",
        "type": "multiple_choice",
        "prompt": "What is the backpropagation chain rule for a neuron?",
        "options": [
          "∂L/∂wᵢⱼ = ∂L/∂zⱼ · ∂zⱼ/∂wᵢⱼ = δⱼ · aᵢ",
          "∂L/∂wᵢⱼ = zⱼ - yⱼ",
          "∂L/∂wᵢⱼ = Σwᵢⱼ²",
          "∂L/∂wᵢⱼ = log(aⱼ)"
        ],
        "correctAnswer": 0,
        "explanation": "Backprop applies chain rule: gradient w.r.t. weight wᵢⱼ is the error term δⱼ = ∂L/∂zⱼ times the input activation aᵢ. Error terms propagate backward via δⱼ = (Σwⱼₖδₖ)·f'(zⱼ)."
      },
      {
        "id": "cs402-q58",
        "type": "multiple_choice",
        "prompt": "Why is Xavier/Glorot initialization important?",
        "options": [
          "Keeps variance of activations and gradients consistent across layers",
          "Ensures all weights start at zero",
          "Makes all neurons identical",
          "Speeds up convergence to global minimum"
        ],
        "correctAnswer": 0,
        "explanation": "Xavier initialization sets weights from N(0, 1/n_in) or U(-√(6/(n_in+n_out)), √(6/(n_in+n_out))). This maintains activation variance through layers, preventing vanishing/exploding activations."
      },
      {
        "id": "cs402-q59",
        "type": "multiple_choice",
        "prompt": "What is the gradient of ReLU?",
        "options": [
          "∂ReLU(z)/∂z = 1 if z>0, else 0 (undefined at 0)",
          "∂ReLU(z)/∂z = z",
          "∂ReLU(z)/∂z = 1/(1+e^(-z))",
          "∂ReLU(z)/∂z = 1-tanh²(z)"
        ],
        "correctAnswer": 0,
        "explanation": "ReLU gradient is simple: 1 for positive inputs (allows gradient flow) and 0 for negative (blocks gradient). This simplicity and lack of saturation for positive values helps deep networks train."
      },
      {
        "id": "cs402-q60",
        "type": "multiple_choice",
        "prompt": "What is the dying ReLU problem?",
        "options": [
          "Neurons can get stuck outputting 0 for all inputs due to large negative bias",
          "ReLU causes overfitting",
          "ReLU is too slow to compute",
          "ReLU requires too much memory"
        ],
        "correctAnswer": 0,
        "explanation": "A neuron with large negative weighted sum will output 0, receive gradient 0, and never recover. This \"dies\" the neuron. Leaky ReLU (small negative slope) prevents this by allowing small gradient for negative inputs."
      }
    ]
  }
]
