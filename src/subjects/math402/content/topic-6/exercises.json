[
  {
    "id": "math402-ex-6-1",
    "subjectId": "math402",
    "topicId": "topic-6",
    "difficulty": 1,
    "title": "Jacobi Iteration",
    "description": "Implement the Jacobi iterative method for solving linear systems. The Jacobi method splits A = D + R where D is diagonal, and iterates x^(k+1) = D^(-1)(b - Rx^(k)). This is the simplest stationary iterative method.",
    "starterCode": "import numpy as np\n\ndef jacobi_iteration(A, b, x0=None, max_iter=100, tol=1e-6):\n    \"\"\"\n    Solve Ax = b using Jacobi iteration.\n\n    Parameters:\n    - A: n×n coefficient matrix\n    - b: n×1 right-hand side\n    - x0: initial guess (default: zero vector)\n    - max_iter: maximum iterations\n    - tol: convergence tolerance\n\n    Returns:\n    - x: solution\n    - iterations: number of iterations\n    - residuals: list of residual norms\n    \"\"\"\n    # TODO: Implement this function\n    pass\n\n# Test case: diagonally dominant system\nA = np.array([\n    [4.0, 1.0, 0.0],\n    [1.0, 4.0, 1.0],\n    [0.0, 1.0, 4.0]\n], dtype=float)\n\nb = np.array([6.0, 8.0, 6.0])\n\nx, iters, residuals = jacobi_iteration(A, b)\nprint(f\"Solution: {x}\")\nprint(f\"Iterations: {iters}\")\nprint(f\"Final residual: {residuals[-1]:.2e}\")",
    "hints": [
      "Extract diagonal D and off-diagonal R where A = D + R",
      "Update: x^(k+1)[i] = (b[i] - sum(A[i,j]*x^(k)[j] for j≠i)) / A[i,i]",
      "Use all old values x^(k) to compute all new values x^(k+1)",
      "Check convergence: ||b - Ax|| < tol"
    ],
    "solution": "import numpy as np\n\ndef jacobi_iteration(A, b, x0=None, max_iter=100, tol=1e-6):\n    \"\"\"\n    Solve Ax = b using Jacobi iteration.\n\n    Parameters:\n    - A: n×n coefficient matrix\n    - b: n×1 right-hand side\n    - x0: initial guess (default: zero vector)\n    - max_iter: maximum iterations\n    - tol: convergence tolerance\n\n    Returns:\n    - x: solution\n    - iterations: number of iterations\n    - residuals: list of residual norms\n    \"\"\"\n    n = len(b)\n\n    # Initialize\n    if x0 is None:\n        x = np.zeros(n)\n    else:\n        x = x0.copy()\n\n    residuals = []\n\n    for k in range(max_iter):\n        # Compute residual\n        residual = b - A @ x\n        res_norm = np.linalg.norm(residual)\n        residuals.append(res_norm)\n\n        # Check convergence\n        if res_norm < tol:\n            return x, k + 1, residuals\n\n        # Jacobi update: x_new[i] = (b[i] - sum(A[i,j]*x[j] for j≠i)) / A[i,i]\n        x_new = np.zeros(n)\n        for i in range(n):\n            sigma = sum(A[i, j] * x[j] for j in range(n) if j != i)\n            x_new[i] = (b[i] - sigma) / A[i, i]\n\n        x = x_new\n\n    # Max iterations reached\n    residual = b - A @ x\n    residuals.append(np.linalg.norm(residual))\n\n    return x, max_iter, residuals\n\n# Test case: diagonally dominant system\nA = np.array([\n    [4.0, 1.0, 0.0],\n    [1.0, 4.0, 1.0],\n    [0.0, 1.0, 4.0]\n], dtype=float)\n\nb = np.array([6.0, 8.0, 6.0])\n\nx, iters, residuals = jacobi_iteration(A, b)\nprint(f\"Solution: {x}\")\nprint(f\"Iterations: {iters}\")\nprint(f\"Final residual: {residuals[-1]:.2e}\")\n\n# Verify\nprint(f\"\\nVerification Ax: {A @ x}\")\nprint(f\"Original b: {b}\")\n\n# Compare with direct solve\nx_exact = np.linalg.solve(A, b)\nprint(f\"\\nDifference from exact: {np.linalg.norm(x - x_exact):.2e}\")\n\n# Plot convergence\nimport matplotlib.pyplot as plt\nplt.semilogy(residuals)\nplt.xlabel('Iteration')\nplt.ylabel('Residual norm')\nplt.title('Jacobi Convergence')\nplt.grid(True)\nplt.show()\n\nprint(\"\\nAll tests passed!\")",
    "testCases": [
      {
        "input": "Diagonally dominant 3×3 system",
        "expectedOutput": "Converged solution in ~10-20 iterations",
        "isHidden": false,
        "description": "Basic Jacobi iteration convergence"
      }
    ],
    "language": "python"
  },
  {
    "id": "math402-ex-6-2",
    "subjectId": "math402",
    "topicId": "topic-6",
    "difficulty": 2,
    "title": "Gauss-Seidel Method",
    "description": "Implement Gauss-Seidel iteration which uses updated values immediately. Gauss-Seidel often converges faster than Jacobi because it uses the most recent information. Update: x^(k+1)[i] uses already-computed x^(k+1)[j] for j < i.",
    "starterCode": "import numpy as np\n\ndef gauss_seidel(A, b, x0=None, max_iter=100, tol=1e-6):\n    \"\"\"\n    Solve Ax = b using Gauss-Seidel iteration.\n\n    Parameters:\n    - A: n×n coefficient matrix\n    - b: n×1 right-hand side\n    - x0: initial guess\n    - max_iter: maximum iterations\n    - tol: convergence tolerance\n\n    Returns:\n    - x: solution\n    - iterations: number of iterations\n    - residuals: list of residual norms\n    \"\"\"\n    # TODO: Implement this function\n    pass\n\n# Test case\nA = np.array([\n    [4.0, 1.0, 0.0],\n    [1.0, 4.0, 1.0],\n    [0.0, 1.0, 4.0]\n], dtype=float)\n\nb = np.array([6.0, 8.0, 6.0])\n\nx, iters, residuals = gauss_seidel(A, b)\nprint(f\"Solution: {x}\")\nprint(f\"Iterations: {iters}\")",
    "hints": [
      "Use updated values immediately in the same iteration",
      "x[i] = (b[i] - sum(A[i,j]*x[j] for j<i) - sum(A[i,j]*x[j] for j>i)) / A[i,i]",
      "First sum uses new x values, second sum uses old x values",
      "Typically converges faster than Jacobi"
    ],
    "solution": "import numpy as np\n\ndef gauss_seidel(A, b, x0=None, max_iter=100, tol=1e-6):\n    \"\"\"\n    Solve Ax = b using Gauss-Seidel iteration.\n\n    Parameters:\n    - A: n×n coefficient matrix\n    - b: n×1 right-hand side\n    - x0: initial guess\n    - max_iter: maximum iterations\n    - tol: convergence tolerance\n\n    Returns:\n    - x: solution\n    - iterations: number of iterations\n    - residuals: list of residual norms\n    \"\"\"\n    n = len(b)\n\n    if x0 is None:\n        x = np.zeros(n)\n    else:\n        x = x0.copy()\n\n    residuals = []\n\n    for k in range(max_iter):\n        # Compute residual\n        residual = b - A @ x\n        res_norm = np.linalg.norm(residual)\n        residuals.append(res_norm)\n\n        if res_norm < tol:\n            return x, k + 1, residuals\n\n        # Gauss-Seidel update (in-place)\n        for i in range(n):\n            sigma = sum(A[i, j] * x[j] for j in range(n) if j != i)\n            x[i] = (b[i] - sigma) / A[i, i]\n\n    residual = b - A @ x\n    residuals.append(np.linalg.norm(residual))\n\n    return x, max_iter, residuals\n\ndef compare_jacobi_gs(A, b):\n    \"\"\"Compare Jacobi and Gauss-Seidel convergence.\"\"\"\n    from math402_ex_6_1 import jacobi_iteration\n\n    # Run both methods\n    x_j, iters_j, res_j = jacobi_iteration(A, b)\n    x_gs, iters_gs, res_gs = gauss_seidel(A, b)\n\n    print(\"Jacobi:\")\n    print(f\"  Iterations: {iters_j}\")\n    print(f\"  Final residual: {res_j[-1]:.2e}\")\n\n    print(\"\\nGauss-Seidel:\")\n    print(f\"  Iterations: {iters_gs}\")\n    print(f\"  Final residual: {res_gs[-1]:.2e}\")\n\n    print(f\"\\nSpeedup: {iters_j / iters_gs:.2f}x\")\n\n    # Plot comparison\n    import matplotlib.pyplot as plt\n    plt.semilogy(res_j, label='Jacobi', marker='o')\n    plt.semilogy(res_gs, label='Gauss-Seidel', marker='s')\n    plt.xlabel('Iteration')\n    plt.ylabel('Residual norm')\n    plt.title('Convergence Comparison')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n# Test case\nA = np.array([\n    [4.0, 1.0, 0.0],\n    [1.0, 4.0, 1.0],\n    [0.0, 1.0, 4.0]\n], dtype=float)\n\nb = np.array([6.0, 8.0, 6.0])\n\nx, iters, residuals = gauss_seidel(A, b)\nprint(f\"Solution: {x}\")\nprint(f\"Iterations: {iters}\")\nprint(f\"Final residual: {residuals[-1]:.2e}\")\n\n# Verify\nprint(f\"\\nVerification Ax: {A @ x}\")\nprint(f\"Original b: {b}\")\n\nx_exact = np.linalg.solve(A, b)\nprint(f\"Difference from exact: {np.linalg.norm(x - x_exact):.2e}\")\n\nprint(\"\\nAll tests passed!\")",
    "testCases": [
      {
        "input": "Same system as Jacobi",
        "expectedOutput": "Faster convergence than Jacobi",
        "isHidden": false,
        "description": "Gauss-Seidel convergence comparison"
      }
    ],
    "language": "python"
  }
]
