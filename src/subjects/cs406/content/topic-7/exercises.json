[
  {
    "id": "cs406-t7-ex01",
    "subjectId": "cs406",
    "topicId": "cs406-topic-7",
    "title": "Bayesian Network Inference",
    "difficulty": 2,
    "description": "Implement exact inference in a simple Bayesian network.\n\nYour implementation should:\n- Represent conditional probability tables (CPTs)\n- Compute joint probabilities\n- Perform inference using enumeration\n- Calculate P(X|evidence)",
    "starterCode": "class BayesianNetwork:\n    def __init__(self):\n        self.variables = []\n        self.parents = {}  # var -> list of parents\n        self.cpts = {}  # var -> CPT\n\n    def add_variable(self, var, parents, cpt):\n        # Add variable with its CPT\n        pass\n\n    def probability(self, var, value, evidence):\n        # Compute P(var=value | evidence)\n        pass\n\n# Example: Simple alarm network\n# Burglary -> Alarm <- Earthquake\n# Alarm -> Call",
    "solution": "from itertools import product\n\nclass BayesianNetwork:\n    def __init__(self):\n        self.variables = []\n        self.parents = {}\n        self.cpts = {}\n\n    def add_variable(self, var, parents, cpt):\n        \"\"\"Add variable with parents and CPT.\"\"\"\n        self.variables.append(var)\n        self.parents[var] = parents\n        self.cpts[var] = cpt\n\n    def get_probability(self, var, value, parent_values):\n        \"\"\"Get P(var=value | parent_values) from CPT.\"\"\"\n        cpt = self.cpts[var]\n\n        if not self.parents[var]:\n            # No parents, unconditional probability\n            return cpt.get(value, 0.0)\n\n        # Convert parent values to tuple key\n        key = tuple(parent_values[p] for p in self.parents[var])\n\n        return cpt.get((key, value), 0.0)\n\n    def enumerate_all(self, variables, evidence):\n        \"\"\"Enumerate all assignments consistent with evidence.\"\"\"\n        if not variables:\n            return 1.0\n\n        var = variables[0]\n        rest = variables[1:]\n\n        if var in evidence:\n            # Variable is observed\n            parent_vals = evidence\n            prob = self.get_probability(var, evidence[var], parent_vals)\n            return prob * self.enumerate_all(rest, evidence)\n        else:\n            # Sum over all possible values\n            total = 0.0\n\n            for value in [True, False]:\n                extended = evidence.copy()\n                extended[var] = value\n\n                parent_vals = extended\n                prob = self.get_probability(var, value, parent_vals)\n                total += prob * self.enumerate_all(rest, extended)\n\n            return total\n\n    def probability(self, query_var, query_value, evidence):\n        \"\"\"Compute P(query_var=query_value | evidence) using enumeration.\"\"\"\n\n        # P(X|e) = P(X,e) / P(e)\n\n        # Compute P(query_var=query_value, evidence)\n        extended = evidence.copy()\n        extended[query_var] = query_value\n        p_x_e = self.enumerate_all(self.variables, extended)\n\n        # Compute P(evidence)\n        p_e = self.enumerate_all(self.variables, evidence)\n\n        if p_e == 0:\n            return 0.0\n\n        return p_x_e / p_e\n\n# Build alarm network\n# Burglary -> Alarm <- Earthquake\n#              |\n#              v\n#            Call\n\nbn = BayesianNetwork()\n\n# P(Burglary)\nbn.add_variable('Burglary', [], {\n    True: 0.001,\n    False: 0.999\n})\n\n# P(Earthquake)\nbn.add_variable('Earthquake', [], {\n    True: 0.002,\n    False: 0.998\n})\n\n# P(Alarm | Burglary, Earthquake)\nbn.add_variable('Alarm', ['Burglary', 'Earthquake'], {\n    ((True, True), True): 0.95,\n    ((True, True), False): 0.05,\n    ((True, False), True): 0.94,\n    ((True, False), False): 0.06,\n    ((False, True), True): 0.29,\n    ((False, True), False): 0.71,\n    ((False, False), True): 0.001,\n    ((False, False), False): 0.999\n})\n\n# P(Call | Alarm)\nbn.add_variable('Call', ['Alarm'], {\n    ((True,), True): 0.70,\n    ((True,), False): 0.30,\n    ((False,), True): 0.05,\n    ((False,), False): 0.95\n})\n\n# Queries\nprint(\"Alarm Network Inference\")\nprint(\"=\"*50)\n\n# Prior probability of burglary\np_b = bn.probability('Burglary', True, {})\nprint(f\"P(Burglary) = {p_b:.4f}\")\n\n# P(Burglary | Call)\np_b_call = bn.probability('Burglary', True, {'Call': True})\nprint(f\"P(Burglary | Call) = {p_b_call:.4f}\")\n\n# P(Burglary | Call, ¬Earthquake)\np_b_call_no_eq = bn.probability('Burglary', True, {'Call': True, 'Earthquake': False})\nprint(f\"P(Burglary | Call, ¬Earthquake) = {p_b_call_no_eq:.4f}\")\n\n# P(Alarm | Burglary, ¬Earthquake)\np_a_b = bn.probability('Alarm', True, {'Burglary': True, 'Earthquake': False})\nprint(f\"P(Alarm | Burglary, ¬Earthquake) = {p_a_b:.4f}\")\n\nprint(\"\\nNote: Burglary probability increases from prior when we observe Call\")",
    "testCases": [
      {
        "input": "bn.probability(\"Burglary\", True, {})",
        "isHidden": false,
        "description": "Test prior probability calculation"
      },
      {
        "input": "bn.probability(\"Burglary\", True, {\"Call\": True})",
        "isHidden": false,
        "description": "Test posterior probability given evidence"
      },
      {
        "input": "bn.enumerate_all(variables, evidence)",
        "isHidden": false,
        "description": "Test enumeration over all variables"
      }
    ],
    "hints": [
      "Use enumeration: sum over all possible assignments consistent with evidence",
      "P(X|e) = P(X,e) / P(e) where P(X,e) and P(e) are computed by enumeration",
      "For each variable, if observed use its value, otherwise sum over both True and False"
    ],
    "language": "python"
  },
  {
    "id": "cs406-t7-ex02",
    "subjectId": "cs406",
    "topicId": "cs406-topic-7",
    "title": "Hidden Markov Model - Viterbi Algorithm",
    "difficulty": 3,
    "description": "Implement the Viterbi algorithm for HMMs to find the most likely state sequence.\n\nYour implementation should:\n- Represent HMM with transition and emission probabilities\n- Use dynamic programming to find best path\n- Backtrack to recover full state sequence\n- Handle log probabilities to avoid underflow",
    "starterCode": "class HMM:\n    def __init__(self, states, observations):\n        self.states = states\n        self.observations = observations\n        self.start_prob = {}\n        self.trans_prob = {}\n        self.emit_prob = {}\n\n    def viterbi(self, observations):\n        # Find most likely state sequence\n        # Returns: (probability, state_sequence)\n        pass",
    "solution": "import math\n\nclass HMM:\n    def __init__(self, states, observations):\n        self.states = states\n        self.observations = observations\n        self.start_prob = {}  # state -> probability\n        self.trans_prob = {}  # (state, state) -> probability\n        self.emit_prob = {}   # (state, observation) -> probability\n\n    def viterbi(self, observations):\n        \"\"\"\n        Viterbi algorithm to find most likely state sequence.\n        Returns: (log_probability, state_sequence)\n        \"\"\"\n        T = len(observations)\n        N = len(self.states)\n\n        # DP table: viterbi[t][state] = (max_prob, best_prev_state)\n        viterbi = [{} for _ in range(T)]\n        backpointer = [{} for _ in range(T)]\n\n        # Initialize (t=0)\n        for state in self.states:\n            start_p = self.start_prob.get(state, 1e-10)\n            emit_p = self.emit_prob.get((state, observations[0]), 1e-10)\n\n            # Use log probabilities to avoid underflow\n            viterbi[0][state] = math.log(start_p) + math.log(emit_p)\n            backpointer[0][state] = None\n\n        # Forward pass (t=1 to T-1)\n        for t in range(1, T):\n            for curr_state in self.states:\n                max_prob = float('-inf')\n                best_prev = None\n\n                for prev_state in self.states:\n                    trans_p = self.trans_prob.get((prev_state, curr_state), 1e-10)\n                    prob = viterbi[t-1][prev_state] + math.log(trans_p)\n\n                    if prob > max_prob:\n                        max_prob = prob\n                        best_prev = prev_state\n\n                emit_p = self.emit_prob.get((curr_state, observations[t]), 1e-10)\n                viterbi[t][curr_state] = max_prob + math.log(emit_p)\n                backpointer[t][curr_state] = best_prev\n\n        # Find best final state\n        max_prob = float('-inf')\n        best_final = None\n\n        for state in self.states:\n            if viterbi[T-1][state] > max_prob:\n                max_prob = viterbi[T-1][state]\n                best_final = state\n\n        # Backtrack to recover path\n        path = [best_final]\n        for t in range(T-1, 0, -1):\n            path.insert(0, backpointer[t][path[0]])\n\n        return max_prob, path\n\n    def forward(self, observations):\n        \"\"\"\n        Forward algorithm to compute P(observations).\n        Returns: log probability\n        \"\"\"\n        T = len(observations)\n\n        # Forward table: forward[t][state] = P(o_1:t, state_t)\n        forward = [{} for _ in range(T)]\n\n        # Initialize\n        for state in self.states:\n            start_p = self.start_prob.get(state, 1e-10)\n            emit_p = self.emit_prob.get((state, observations[0]), 1e-10)\n            forward[0][state] = math.log(start_p) + math.log(emit_p)\n\n        # Forward pass\n        for t in range(1, T):\n            for curr_state in self.states:\n                log_sum = float('-inf')\n\n                for prev_state in self.states:\n                    trans_p = self.trans_prob.get((prev_state, curr_state), 1e-10)\n                    prob = forward[t-1][prev_state] + math.log(trans_p)\n\n                    # Log-sum-exp trick\n                    if log_sum == float('-inf'):\n                        log_sum = prob\n                    else:\n                        log_sum = max(log_sum, prob) + math.log(1 + math.exp(min(log_sum, prob) - max(log_sum, prob)))\n\n                emit_p = self.emit_prob.get((curr_state, observations[t]), 1e-10)\n                forward[t][curr_state] = log_sum + math.log(emit_p)\n\n        # Sum over final states\n        total = float('-inf')\n        for state in self.states:\n            if total == float('-inf'):\n                total = forward[T-1][state]\n            else:\n                p = forward[T-1][state]\n                total = max(total, p) + math.log(1 + math.exp(min(total, p) - max(total, p)))\n\n        return total\n\n# Example: Weather HMM\n# States: Sunny, Rainy\n# Observations: Walk, Shop, Clean\n\nhmm = HMM(\n    states=['Sunny', 'Rainy'],\n    observations=['Walk', 'Shop', 'Clean']\n)\n\n# Start probabilities\nhmm.start_prob = {\n    'Sunny': 0.6,\n    'Rainy': 0.4\n}\n\n# Transition probabilities\nhmm.trans_prob = {\n    ('Sunny', 'Sunny'): 0.7,\n    ('Sunny', 'Rainy'): 0.3,\n    ('Rainy', 'Sunny'): 0.4,\n    ('Rainy', 'Rainy'): 0.6\n}\n\n# Emission probabilities\nhmm.emit_prob = {\n    ('Sunny', 'Walk'): 0.6,\n    ('Sunny', 'Shop'): 0.3,\n    ('Sunny', 'Clean'): 0.1,\n    ('Rainy', 'Walk'): 0.1,\n    ('Rainy', 'Shop'): 0.4,\n    ('Rainy', 'Clean'): 0.5\n}\n\n# Observations\nobs = ['Walk', 'Shop', 'Clean']\n\nprint(\"Weather HMM\")\nprint(\"=\"*50)\nprint(f\"Observations: {obs}\")\nprint()\n\n# Viterbi - most likely state sequence\nlog_prob, path = hmm.viterbi(obs)\nprint(f\"Most likely state sequence: {path}\")\nprint(f\"Log probability: {log_prob:.4f}\")\nprint(f\"Probability: {math.exp(log_prob):.6e}\")\nprint()\n\n# Forward algorithm - total probability\ntotal_log_prob = hmm.forward(obs)\nprint(f\"Total P(observations) [log]: {total_log_prob:.4f}\")\nprint(f\"Total P(observations): {math.exp(total_log_prob):.6e}\")\n\n# Try different observation sequence\nobs2 = ['Clean', 'Clean', 'Clean']\nlog_prob2, path2 = hmm.viterbi(obs2)\nprint(f\"\\nObservations: {obs2}\")\nprint(f\"Most likely state sequence: {path2}\")\nprint(f\"Probability: {math.exp(log_prob2):.6e}\")",
    "testCases": [
      {
        "input": "hmm.viterbi(observations)",
        "isHidden": false,
        "description": "Test Viterbi finds most likely state sequence"
      },
      {
        "input": "hmm.forward(observations)",
        "isHidden": false,
        "description": "Test forward algorithm computes total probability"
      },
      {
        "input": "viterbi with different observations",
        "isHidden": false,
        "description": "Test Viterbi produces sensible paths"
      }
    ],
    "hints": [
      "Use dynamic programming: viterbi[t][s] = max probability of path ending in state s at time t",
      "Use log probabilities to avoid numerical underflow (multiply becomes add in log space)",
      "Store backpointers to recover the best path after forward pass completes",
      "Backtrack from the best final state to reconstruct the complete path"
    ],
    "language": "python"
  },
  {
    "id": "cs406-t7-ex03",
    "subjectId": "cs406",
    "topicId": "cs406-topic-7",
    "title": "Particle Filter for Robot Localization",
    "difficulty": 4,
    "description": "Implement a particle filter for robot localization.\n\nYour implementation should:\n- Represent belief as a set of weighted particles\n- Implement prediction step (motion model)\n- Implement update step (sensor model)\n- Resample particles based on weights\n- Estimate position from particle cloud",
    "starterCode": "import random\nimport math\n\nclass Particle:\n    def __init__(self, x, y, weight=1.0):\n        self.x = x\n        self.y = y\n        self.weight = weight\n\nclass ParticleFilter:\n    def __init__(self, num_particles, world_size):\n        self.particles = []\n        self.world_size = world_size\n\n    def predict(self, motion):\n        # Move particles according to motion model\n        pass\n\n    def update(self, measurement, landmarks):\n        # Update particle weights based on sensor measurement\n        pass\n\n    def resample(self):\n        # Resample particles based on weights\n        pass\n\n    def estimate(self):\n        # Estimate robot position from particles\n        pass",
    "solution": "import random\nimport math\n\nclass Particle:\n    def __init__(self, x, y, weight=1.0):\n        self.x = x\n        self.y = y\n        self.weight = weight\n\n    def __repr__(self):\n        return f\"Particle({self.x:.2f}, {self.y:.2f}, w={self.weight:.4f})\"\n\nclass ParticleFilter:\n    def __init__(self, num_particles, world_size):\n        self.num_particles = num_particles\n        self.world_size = world_size\n\n        # Initialize particles uniformly\n        self.particles = []\n        for _ in range(num_particles):\n            x = random.uniform(0, world_size[0])\n            y = random.uniform(0, world_size[1])\n            self.particles.append(Particle(x, y, 1.0 / num_particles))\n\n    def predict(self, motion, noise_std=1.0):\n        \"\"\"\n        Move particles according to motion model.\n        motion: (dx, dy) movement\n        noise_std: standard deviation of motion noise\n        \"\"\"\n        dx, dy = motion\n\n        for particle in self.particles:\n            # Add noise to motion\n            noise_x = random.gauss(0, noise_std)\n            noise_y = random.gauss(0, noise_std)\n\n            particle.x += dx + noise_x\n            particle.y += dy + noise_y\n\n            # Keep particles in world bounds (wrap around or clip)\n            particle.x = particle.x % self.world_size[0]\n            particle.y = particle.y % self.world_size[1]\n\n    def update(self, measurement, landmarks, sensor_noise=2.0):\n        \"\"\"\n        Update particle weights based on sensor measurement.\n        measurement: list of distances to landmarks\n        landmarks: list of (x, y) landmark positions\n        sensor_noise: standard deviation of sensor noise\n        \"\"\"\n        weights = []\n\n        for particle in self.particles:\n            # Compute expected measurements for this particle\n            weight = 1.0\n\n            for i, (lx, ly) in enumerate(landmarks):\n                # Expected distance to landmark\n                expected_dist = math.sqrt((particle.x - lx)**2 + (particle.y - ly)**2)\n\n                # Actual measured distance\n                measured_dist = measurement[i]\n\n                # Compute likelihood using Gaussian\n                diff = expected_dist - measured_dist\n                weight *= math.exp(-(diff**2) / (2 * sensor_noise**2))\n\n            particle.weight = weight\n            weights.append(weight)\n\n        # Normalize weights\n        total_weight = sum(weights)\n\n        if total_weight > 0:\n            for particle in self.particles:\n                particle.weight /= total_weight\n\n    def resample(self):\n        \"\"\"Resample particles based on weights (importance sampling).\"\"\"\n        weights = [p.weight for p in self.particles]\n\n        # Systematic resampling\n        new_particles = []\n\n        # Compute cumulative weights\n        cumulative = []\n        cum_sum = 0\n        for w in weights:\n            cum_sum += w\n            cumulative.append(cum_sum)\n\n        # Generate uniform random samples\n        step = 1.0 / self.num_particles\n        start = random.uniform(0, step)\n\n        for i in range(self.num_particles):\n            target = start + i * step\n\n            # Find particle\n            for j, cum_w in enumerate(cumulative):\n                if target <= cum_w:\n                    # Copy particle\n                    p = self.particles[j]\n                    new_particles.append(Particle(p.x, p.y, 1.0 / self.num_particles))\n                    break\n\n        self.particles = new_particles\n\n    def estimate(self):\n        \"\"\"Estimate robot position as weighted mean of particles.\"\"\"\n        x_est = sum(p.x * p.weight for p in self.particles)\n        y_est = sum(p.y * p.weight for p in self.particles)\n\n        return (x_est, y_est)\n\n    def effective_sample_size(self):\n        \"\"\"Compute effective sample size (measure of particle diversity).\"\"\"\n        return 1.0 / sum(p.weight**2 for p in self.particles)\n\n# Simulation\nprint(\"Particle Filter for Robot Localization\")\nprint(\"=\"*50)\n\n# World setup\nworld_size = (100, 100)\nlandmarks = [(20, 20), (80, 20), (20, 80), (80, 80)]\n\n# True robot position\ntrue_x, true_y = 50, 50\n\n# Create particle filter\npf = ParticleFilter(num_particles=1000, world_size=world_size)\n\nprint(f\"World size: {world_size}\")\nprint(f\"Landmarks: {landmarks}\")\nprint(f\"True position: ({true_x}, {true_y})\")\nprint()\n\n# Initial estimate\nest_x, est_y = pf.estimate()\nerror = math.sqrt((est_x - true_x)**2 + (est_y - true_y)**2)\nprint(f\"Initial estimate: ({est_x:.2f}, {est_y:.2f})\")\nprint(f\"Initial error: {error:.2f}\")\nprint(f\"Effective sample size: {pf.effective_sample_size():.1f}\")\nprint()\n\n# Simulate robot motion and sensing\nmotions = [(5, 0), (0, 5), (-5, 0), (0, -5)]\n\nfor step, motion in enumerate(motions):\n    print(f\"Step {step + 1}: Motion {motion}\")\n\n    # Update true position\n    true_x += motion[0]\n    true_y += motion[1]\n\n    # Predict step\n    pf.predict(motion, noise_std=1.0)\n\n    # Generate measurement (with noise)\n    measurement = []\n    for lx, ly in landmarks:\n        true_dist = math.sqrt((true_x - lx)**2 + (true_y - ly)**2)\n        noisy_dist = true_dist + random.gauss(0, 2.0)\n        measurement.append(noisy_dist)\n\n    # Update step\n    pf.update(measurement, landmarks, sensor_noise=2.0)\n\n    # Resample if needed (when particle diversity is low)\n    if pf.effective_sample_size() < pf.num_particles / 2:\n        pf.resample()\n\n    # Estimate\n    est_x, est_y = pf.estimate()\n    error = math.sqrt((est_x - true_x)**2 + (est_y - true_y)**2)\n\n    print(f\"  True position: ({true_x:.2f}, {true_y:.2f})\")\n    print(f\"  Estimated position: ({est_x:.2f}, {est_y:.2f})\")\n    print(f\"  Error: {error:.2f}\")\n    print(f\"  Effective sample size: {pf.effective_sample_size():.1f}\")\n    print()\n\nprint(\"Note: Error decreases as particles converge to true position\")",
    "testCases": [
      {
        "input": "pf.predict(motion, noise_std)",
        "isHidden": false,
        "description": "Test prediction step moves particles according to motion model"
      },
      {
        "input": "pf.update(measurement, landmarks, sensor_noise)",
        "isHidden": false,
        "description": "Test update step weights particles by measurement likelihood"
      },
      {
        "input": "pf.resample()",
        "isHidden": false,
        "description": "Test resampling concentrates particles in high-probability regions"
      }
    ],
    "hints": [
      "Prediction: move each particle according to motion command plus Gaussian noise",
      "Update: weight each particle by how well its expected measurements match actual measurements",
      "Use Gaussian likelihood: exp(-(difference²)/(2*sigma²)) for sensor model",
      "Resample when effective sample size drops below threshold to avoid particle depletion"
    ],
    "language": "python"
  }
]
