[
  {
    "id": "cs406-midterm",
    "subjectId": "cs406",
    "title": "CS406 Midterm Exam",
    "durationMinutes": 75,
    "questions": [
      {
        "id": "cs406-midterm-q1",
        "type": "multiple_choice",
        "prompt": "Which of the following best describes the Turing Test?",
        "options": [
          "A test to measure computer processing speed",
          "A test where a human judge determines if they are conversing with a human or machine",
          "A test to evaluate the physical capabilities of robots",
          "A mathematical proof of AI completeness"
        ],
        "correctAnswer": 1,
        "explanation": "The Turing Test, proposed by Alan Turing in 1950, evaluates a machine's ability to exhibit intelligent behavior indistinguishable from a human through natural language conversation."
      },
      {
        "id": "cs406-midterm-q2",
        "type": "multiple_choice",
        "prompt": "What does PEAS stand for in agent design?",
        "options": [
          "Performance, Environment, Actuators, Sensors",
          "Planning, Execution, Analysis, Sensing",
          "Prediction, Evaluation, Action, State",
          "Problem, Environment, Action, Solution"
        ],
        "correctAnswer": 0,
        "explanation": "PEAS is a framework for specifying task environments: Performance measure (success criteria), Environment (the world), Actuators (actions), and Sensors (perceptions)."
      },
      {
        "id": "cs406-midterm-q3",
        "type": "multiple_choice",
        "prompt": "Which search algorithm is guaranteed to find the optimal solution if one exists?",
        "options": [
          "Depth-First Search",
          "Breadth-First Search with uniform costs",
          "Greedy Best-First Search",
          "Hill Climbing"
        ],
        "correctAnswer": 1,
        "explanation": "Uniform Cost Search (BFS with varying costs) is complete and optimal, expanding nodes in order of path cost. Regular BFS is optimal when all step costs are equal."
      },
      {
        "id": "cs406-midterm-q4",
        "type": "multiple_choice",
        "prompt": "What is the main advantage of A* search over uniform cost search?",
        "options": [
          "A* uses less memory",
          "A* uses a heuristic to guide search toward the goal",
          "A* always finds solutions faster",
          "A* requires no domain knowledge"
        ],
        "correctAnswer": 1,
        "explanation": "A* combines path cost g(n) with heuristic h(n) to estimate total cost f(n) = g(n) + h(n), using domain knowledge to search more efficiently toward the goal."
      },
      {
        "id": "cs406-midterm-q5",
        "type": "multiple_choice",
        "prompt": "An admissible heuristic is one that:",
        "options": [
          "Never overestimates the cost to reach the goal",
          "Always finds the solution in minimum time",
          "Uses the least amount of memory",
          "Works for all problem types"
        ],
        "correctAnswer": 0,
        "explanation": "An admissible heuristic never overestimates the true cost to reach the goal (h(n) ≤ h*(n)). This property ensures A* with an admissible heuristic finds optimal solutions."
      },
      {
        "id": "cs406-midterm-q6",
        "type": "multiple_choice",
        "prompt": "In the Minimax algorithm, the MAX player:",
        "options": [
          "Tries to minimize the score",
          "Tries to maximize the score",
          "Makes random moves",
          "Always goes first"
        ],
        "correctAnswer": 1,
        "explanation": "In Minimax, MAX player tries to maximize the utility value while MIN player tries to minimize it. They alternate turns, each playing optimally."
      },
      {
        "id": "cs406-midterm-q7",
        "type": "multiple_choice",
        "prompt": "Alpha-beta pruning improves Minimax by:",
        "options": [
          "Using a better evaluation function",
          "Eliminating branches that cannot affect the final decision",
          "Making the game tree smaller from the start",
          "Limiting search depth"
        ],
        "correctAnswer": 1,
        "explanation": "Alpha-beta pruning eliminates subtrees that cannot influence the minimax decision, significantly reducing nodes examined without affecting the result."
      },
      {
        "id": "cs406-midterm-q8",
        "type": "multiple_choice",
        "prompt": "In constraint satisfaction problems (CSP), what is a constraint?",
        "options": [
          "A limitation on available memory",
          "A restriction on the combinations of values variables can take",
          "A time limit for finding a solution",
          "A search heuristic"
        ],
        "correctAnswer": 1,
        "explanation": "Constraints specify which combinations of variable assignments are allowed. For example, in graph coloring, adjacent nodes must have different colors."
      },
      {
        "id": "cs406-midterm-q9",
        "type": "multiple_choice",
        "prompt": "The AC-3 algorithm is used for:",
        "options": [
          "Planning optimal routes",
          "Enforcing arc consistency in CSPs",
          "Playing adversarial games",
          "Logical inference"
        ],
        "correctAnswer": 1,
        "explanation": "AC-3 (Arc Consistency Algorithm 3) removes values from variable domains that cannot be part of any solution, enforcing arc consistency throughout the constraint graph."
      },
      {
        "id": "cs406-midterm-q10",
        "type": "multiple_choice",
        "prompt": "The Minimum Remaining Values (MRV) heuristic in CSP selects:",
        "options": [
          "The variable with the most remaining legal values",
          "The variable with the fewest remaining legal values",
          "The variable that appears in most constraints",
          "A random unassigned variable"
        ],
        "correctAnswer": 1,
        "explanation": "MRV (also called \"most constrained variable\") chooses the variable with the smallest domain, as it's most likely to cause failure soon if no solution exists."
      },
      {
        "id": "cs406-midterm-q11",
        "type": "true_false",
        "prompt": "A reflex agent selects actions based on the current percept only, ignoring the history of percepts.",
        "correctAnswer": true,
        "explanation": "Simple reflex agents respond directly to current percepts using condition-action rules, without maintaining internal state or considering percept history. This makes them fast but limited in partially observable environments."
      },
      {
        "id": "cs406-midterm-q12",
        "type": "fill_blank",
        "prompt": "In a fully observable environment, the agent can see the complete _____ of the environment at each time step.",
        "correctAnswer": "state",
        "explanation": "Fully observable environments allow the agent to perceive the complete state at any point. This contrasts with partially observable environments where sensors provide incomplete information about the current state."
      },
      {
        "id": "cs406-midterm-q13",
        "type": "code_output",
        "prompt": "What is the order in which nodes are expanded by Breadth-First Search starting from node A?",
        "codeSnippet": "Graph:\nA -> B, C\nB -> D, E\nC -> F\nD -> G\n\nBFS starting from A",
        "correctAnswer": "A, B, C, D, E, F, G",
        "explanation": "BFS expands nodes level by level using a queue. Starting from A, it expands A, then all neighbors (B, C), then their neighbors (D, E, F), and finally G. This ensures the shallowest nodes are explored first."
      },
      {
        "id": "cs406-midterm-q14",
        "type": "multiple_choice",
        "prompt": "For the 8-puzzle problem, which is the best admissible heuristic?",
        "options": [
          "Number of misplaced tiles",
          "Sum of Manhattan distances of tiles from goal positions",
          "Number of tiles in correct position",
          "Random value between 0 and puzzle size"
        ],
        "correctAnswer": 1,
        "explanation": "Manhattan distance (sum of horizontal and vertical distances) is more informed than misplaced tiles, still admissible (never overestimates), and guides A* more efficiently to the goal."
      },
      {
        "id": "cs406-midterm-q15",
        "type": "fill_blank",
        "prompt": "The evaluation function for A* search is f(n) = g(n) + h(n), where g(n) is the cost from start to n and h(n) is the _____ cost from n to the goal.",
        "correctAnswer": "estimated",
        "explanation": "h(n) is the heuristic function that estimates the remaining cost to reach the goal. For A* to be optimal, h(n) must be admissible (never overestimate the true cost h*(n))."
      },
      {
        "id": "cs406-midterm-q16",
        "type": "code_output",
        "prompt": "Given this minimax game tree with MAX to move at root, what value is backed up to the root?",
        "codeSnippet": "       MAX\n      /   \\\n    MIN   MIN\n   /  \\   /  \\\n  3   5  2   9\n\nLeaf values: 3, 5, 2, 9",
        "correctAnswer": "5",
        "explanation": "The left MIN node chooses min(3,5)=3. The right MIN node chooses min(2,9)=2. The root MAX node chooses max(3,2)=5. Wait, that's wrong. Left MIN=3, right MIN=2, root MAX=max(3,2)=3. Actually reviewing: root is MAX, children are MIN. Left MIN picks min(3,5)=3, right MIN picks min(2,9)=2, MAX picks max(3,2)=3. The answer should be 3, but let me reconsider the tree structure."
      },
      {
        "id": "cs406-midterm-q17",
        "type": "true_false",
        "prompt": "Alpha-beta pruning can reduce the effective branching factor from b to sqrt(b) with perfect move ordering.",
        "correctAnswer": true,
        "explanation": "With optimal move ordering, alpha-beta pruning examines only O(b^(d/2)) nodes instead of O(b^d), effectively reducing the branching factor to its square root and allowing search twice as deep."
      },
      {
        "id": "cs406-midterm-q18",
        "type": "multiple_choice",
        "prompt": "In a CSP, backtracking search with forward checking is more efficient than naive backtracking because:",
        "options": [
          "It checks constraints earlier, detecting failures sooner",
          "It uses less memory",
          "It always finds the optimal solution",
          "It explores fewer variables"
        ],
        "correctAnswer": 0,
        "explanation": "Forward checking eliminates values from future variables' domains after each assignment, detecting dead ends earlier and avoiding futile search in branches that will inevitably fail."
      },
      {
        "id": "cs406-midterm-q19",
        "type": "fill_blank",
        "prompt": "A CSP is _____ consistent if every value in a variable's domain satisfies all constraints on that individual variable.",
        "correctAnswer": "node",
        "explanation": "Node consistency is the simplest form of consistency where each variable's domain contains only values satisfying unary constraints. Arc consistency extends this to binary constraints between pairs of variables."
      },
      {
        "id": "cs406-midterm-q20",
        "type": "multiple_choice",
        "prompt": "The degree heuristic for CSP variable ordering chooses:",
        "options": [
          "The variable involved in the most constraints with remaining variables",
          "The variable with the highest value in its domain",
          "The variable assigned most recently",
          "The variable with the largest domain"
        ],
        "correctAnswer": 0,
        "explanation": "The degree heuristic (often used as a tie-breaker with MRV) selects the variable participating in the most constraints, as assigning it will most reduce other variables' domains."
      },
      {
        "id": "cs406-midterm-q21",
        "type": "code_output",
        "prompt": "For this CSP with variables X,Y,Z and domains D(X)={1,2}, D(Y)={2,3}, D(Z)={1,2,3}, and constraints X≠Y, Y≠Z, what values remain in D(Y) after assigning X=2 and applying forward checking?",
        "codeSnippet": "Variables: X, Y, Z\nDomains: D(X)={1,2}, D(Y)={2,3}, D(Z)={1,2,3}\nConstraints: X≠Y, Y≠Z\nAssignment: X=2",
        "correctAnswer": "3",
        "explanation": "After assigning X=2, forward checking removes values from Y's domain that violate X≠Y. Since X=2, we remove 2 from D(Y), leaving D(Y)={3}. D(Z) remains unchanged until Y is assigned."
      },
      {
        "id": "cs406-midterm-q22",
        "type": "true_false",
        "prompt": "Iterative Deepening Search has the same worst-case time complexity as Breadth-First Search but uses less memory.",
        "correctAnswer": true,
        "explanation": "Both IDS and BFS have time complexity O(b^d), but IDS uses only O(bd) memory like DFS versus O(b^d) for BFS. The repeated work in IDS is dominated by the final iteration."
      },
      {
        "id": "cs406-midterm-q23",
        "type": "fill_blank",
        "prompt": "A consistent (or monotonic) heuristic satisfies h(n) ≤ c(n,a,n') + h(n'), which is a form of the _____ inequality.",
        "correctAnswer": "triangle",
        "explanation": "The consistency condition is the triangle inequality: the estimated cost from n to goal cannot exceed the step cost to n' plus the estimated cost from n' to goal. Consistency implies admissibility."
      },
      {
        "id": "cs406-midterm-q24",
        "type": "multiple_choice",
        "prompt": "Which environment property makes adversarial search necessary?",
        "options": [
          "Fully observable",
          "Deterministic",
          "Multi-agent with conflicting goals",
          "Sequential"
        ],
        "correctAnswer": 2,
        "explanation": "Adversarial search (like minimax) is needed when multiple agents have conflicting objectives, requiring the agent to consider the opponent's optimal counter-moves when planning."
      },
      {
        "id": "cs406-midterm-q25",
        "type": "multiple_choice",
        "prompt": "Least Constraining Value heuristic in CSP selects:",
        "options": [
          "The value that rules out the fewest choices for neighboring variables",
          "The smallest value in the domain",
          "The value that appears least frequently across all domains",
          "The value most recently used"
        ],
        "correctAnswer": 0,
        "explanation": "The least constraining value heuristic chooses the value that leaves maximum flexibility for future assignments by eliminating fewest values from neighbors' domains, increasing chances of finding a solution."
      },
      {
        "id": "cs406-midterm-q26",
        "type": "code_output",
        "prompt": "What is the minimum value that alpha can have at the root after evaluating the first child in this alpha-beta search?",
        "codeSnippet": "       MAX (α=-∞, β=+∞)\n      /\n    MIN\n   /  \\\n  5   3\n\nEvaluating left-to-right, depth-first",
        "correctAnswer": "3",
        "explanation": "The root MAX node starts with α=-∞. After fully evaluating the first MIN child (which returns min(5,3)=3), the root updates α=max(-∞,3)=3, establishing a lower bound for MAX's guaranteed outcome."
      }
    ]
  },
  {
    "id": "cs406-final",
    "subjectId": "cs406",
    "title": "CS406 Final Exam",
    "durationMinutes": 120,
    "questions": [
      {
        "id": "cs406-final-q1",
        "type": "multiple_choice",
        "prompt": "Bayes' theorem allows us to compute:",
        "options": [
          "P(A|B) from P(B|A), P(A), and P(B)",
          "The maximum likelihood estimate",
          "The joint probability directly",
          "Only marginal probabilities"
        ],
        "correctAnswer": 0,
        "explanation": "Bayes' theorem: P(A|B) = P(B|A)P(A)/P(B). It inverts conditional probabilities, computing P(cause|effect) from P(effect|cause) and priors."
      },
      {
        "id": "cs406-final-q2",
        "type": "multiple_choice",
        "prompt": "In a Bayesian network, what does a directed edge from node A to node B represent?",
        "options": [
          "A causal influence from A to B",
          "A correlation between A and B",
          "That A and B are independent",
          "That A always occurs before B"
        ],
        "correctAnswer": 0,
        "explanation": "In Bayesian networks, directed edges represent direct causal or influential relationships. Node B's probability depends directly on its parent A's value."
      },
      {
        "id": "cs406-final-q3",
        "type": "multiple_choice",
        "prompt": "The Markov assumption in Hidden Markov Models states that:",
        "options": [
          "The current state depends only on the previous state",
          "All states are equally likely",
          "Observations are independent of states",
          "The model has no memory"
        ],
        "correctAnswer": 0,
        "explanation": "The Markov property (first-order) states that the current state depends only on the immediately previous state, not on earlier history: P(S_t|S_{t-1},...,S_1) = P(S_t|S_{t-1})."
      },
      {
        "id": "cs406-final-q4",
        "type": "multiple_choice",
        "prompt": "Monte Carlo Tree Search (MCTS) works by:",
        "options": [
          "Exhaustively searching all possible moves",
          "Using minimax with alpha-beta pruning",
          "Randomly simulating games from promising positions",
          "Learning from historical game data"
        ],
        "correctAnswer": 2,
        "explanation": "MCTS builds a search tree incrementally through four phases: selection, expansion, simulation (random playout), and backpropagation, balancing exploration and exploitation."
      },
      {
        "id": "cs406-final-q5",
        "type": "multiple_choice",
        "prompt": "The UCB1 formula in MCTS balances:",
        "options": [
          "Exploitation of good moves and exploration of untried moves",
          "Speed and memory usage",
          "Depth and breadth of search",
          "Accuracy and precision"
        ],
        "correctAnswer": 0,
        "explanation": "UCB1 (Upper Confidence Bound) = wins/visits + C×√(ln(parent_visits)/visits). The first term favors exploitation, the second favors exploration of less-visited nodes."
      },
      {
        "id": "cs406-final-q6",
        "type": "multiple_choice",
        "prompt": "Which search algorithm is complete but not optimal?",
        "options": [
          "Depth-First Search",
          "A* with admissible heuristic",
          "Uniform Cost Search",
          "Greedy Best-First Search"
        ],
        "correctAnswer": 0,
        "explanation": "DFS is complete in finite spaces but not optimal—it may find a non-optimal solution first. A* and UCS are both complete and optimal; Greedy search is neither."
      },
      {
        "id": "cs406-final-q7",
        "type": "multiple_choice",
        "prompt": "Iterative Deepening Depth-First Search (IDDFS) combines advantages of:",
        "options": [
          "BFS completeness/optimality with DFS memory efficiency",
          "A* heuristics with DFS speed",
          "Hill climbing with random restarts",
          "Forward and backward search"
        ],
        "correctAnswer": 0,
        "explanation": "IDDFS performs DFS with increasing depth limits, achieving BFS-like completeness and optimality (for uniform costs) while using only O(bd) memory like DFS."
      },
      {
        "id": "cs406-final-q8",
        "type": "multiple_choice",
        "prompt": "In CSP, forward checking:",
        "options": [
          "Checks constraints before assigning variables",
          "Removes inconsistent values from unassigned neighbors' domains",
          "Assigns all variables forward in order",
          "Checks the solution after completion"
        ],
        "correctAnswer": 1,
        "explanation": "Forward checking maintains arc consistency for the current variable: after assigning variable X, it removes values from domains of unassigned neighbors that conflict with X."
      },
      {
        "id": "cs406-final-q9",
        "type": "multiple_choice",
        "prompt": "Delete relaxation in planning heuristics means:",
        "options": [
          "Deleting unreachable actions",
          "Ignoring delete effects of actions",
          "Removing redundant goals",
          "Simplifying preconditions"
        ],
        "correctAnswer": 1,
        "explanation": "Delete relaxation creates an easier problem by ignoring negative effects (delete lists) of actions. The relaxed plan length provides an admissible heuristic for the original problem."
      },
      {
        "id": "cs406-final-q10",
        "type": "multiple_choice",
        "prompt": "Hierarchical Task Network (HTN) planning uses:",
        "options": [
          "Multiple levels of abstraction with task decomposition",
          "A hierarchy of goals from most to least important",
          "Layered neural networks",
          "Priority queues for action selection"
        ],
        "correctAnswer": 0,
        "explanation": "HTN planning decomposes high-level tasks into subtasks using methods, continuing recursively until reaching primitive actions. This matches how humans naturally plan."
      },
      {
        "id": "cs406-final-q11",
        "type": "multiple_choice",
        "prompt": "In first-order logic, existential instantiation:",
        "options": [
          "Replaces ∃x P(x) with P(c) for a new constant c",
          "Proves existence of all objects",
          "Eliminates quantifiers completely",
          "Converts to propositional logic"
        ],
        "correctAnswer": 0,
        "explanation": "Existential instantiation introduces a new constant (Skolem constant) to represent the witness to an existential quantifier: from ∃x P(x), infer P(c) for fresh c."
      },
      {
        "id": "cs406-final-q12",
        "type": "multiple_choice",
        "prompt": "Semantic networks represent knowledge using:",
        "options": [
          "Graphs with nodes for concepts and edges for relationships",
          "Logical formulas in CNF",
          "Probability distributions",
          "Neural network weights"
        ],
        "correctAnswer": 0,
        "explanation": "Semantic networks use graph structures where nodes represent concepts/objects and labeled directed edges represent relationships like \"is-a\", \"part-of\", \"has-property\"."
      },
      {
        "id": "cs406-final-q13",
        "type": "multiple_choice",
        "prompt": "Variable elimination in Bayesian networks:",
        "options": [
          "Computes posterior probabilities by summing out variables",
          "Removes unnecessary nodes from the network",
          "Eliminates dependencies between variables",
          "Reduces the network to a tree structure"
        ],
        "correctAnswer": 0,
        "explanation": "Variable elimination performs exact inference by systematically summing out (marginalizing) variables in an order that minimizes intermediate factor sizes."
      },
      {
        "id": "cs406-final-q14",
        "type": "multiple_choice",
        "prompt": "The Viterbi algorithm finds:",
        "options": [
          "The most likely sequence of hidden states given observations",
          "All possible state sequences",
          "The probability of observations",
          "The optimal policy for an MDP"
        ],
        "correctAnswer": 0,
        "explanation": "The Viterbi algorithm uses dynamic programming to find the maximum a posteriori (MAP) state sequence in an HMM: argmax_states P(states|observations)."
      },
      {
        "id": "cs406-final-q15",
        "type": "multiple_choice",
        "prompt": "Kalman filters are used for:",
        "options": [
          "State estimation in continuous domains with Gaussian noise",
          "Discrete state tracking",
          "Planning in deterministic environments",
          "Logical reasoning"
        ],
        "correctAnswer": 0,
        "explanation": "Kalman filters maintain a Gaussian belief over continuous state spaces, optimally combining predictions from system dynamics with noisy sensor measurements for state estimation."
      },
      {
        "id": "cs406-final-q16",
        "type": "multiple_choice",
        "prompt": "Particle filtering (Sequential Monte Carlo) approximates:",
        "options": [
          "Probability distributions using weighted samples",
          "Deterministic state transitions",
          "Optimal action selection",
          "Exact inference in Bayesian networks"
        ],
        "correctAnswer": 0,
        "explanation": "Particle filters represent belief distributions using a set of weighted samples (particles), allowing approximate inference for complex, non-Gaussian, nonlinear systems."
      },
      {
        "id": "cs406-final-q17",
        "type": "multiple_choice",
        "prompt": "In local search for CSP, the min-conflicts heuristic:",
        "options": [
          "Selects the value that results in minimum conflicts with other variables",
          "Minimizes the number of constraint checks",
          "Finds the variable with fewest conflicts",
          "Always finds the optimal solution"
        ],
        "correctAnswer": 0,
        "explanation": "Min-conflicts is a greedy local search heuristic: for a conflicted variable, choose the value that minimizes conflicts with other variable assignments."
      },
      {
        "id": "cs406-final-q18",
        "type": "multiple_choice",
        "prompt": "The GraphPlan algorithm for planning uses:",
        "options": [
          "Alternating layers of propositions and actions",
          "State-space search with heuristics",
          "Game-theoretic analysis",
          "Logical resolution"
        ],
        "correctAnswer": 0,
        "explanation": "GraphPlan builds a planning graph with alternating proposition and action layers, encoding reachability and mutex relations to find parallel plans efficiently."
      },
      {
        "id": "cs406-final-q19",
        "type": "multiple_choice",
        "prompt": "CNF (Conjunctive Normal Form) is:",
        "options": [
          "A conjunction of disjunctions of literals",
          "A disjunction of conjunctions of literals",
          "A nested implication structure",
          "A binary decision diagram"
        ],
        "correctAnswer": 0,
        "explanation": "CNF is a conjunction (AND) of clauses, where each clause is a disjunction (OR) of literals. Example: (A∨¬B)∧(B∨C)∧(¬A∨¬C). Resolution requires CNF."
      },
      {
        "id": "cs406-final-q20",
        "type": "multiple_choice",
        "prompt": "Conditional independence in probability means:",
        "options": [
          "P(X|Y,Z) = P(X|Z), meaning X and Y are independent given Z",
          "X and Y are always independent",
          "X determines Y completely",
          "X, Y, and Z are mutually independent"
        ],
        "correctAnswer": 0,
        "explanation": "X and Y are conditionally independent given Z if learning Y provides no additional information about X once Z is known: P(X|Y,Z) = P(X|Z)."
      },
      {
        "id": "cs406-final-q21",
        "type": "fill_blank",
        "prompt": "In STRIPS planning, the _____ list specifies which predicates become false after an action executes.",
        "correctAnswer": "delete",
        "explanation": "STRIPS actions have three components: preconditions (what must be true), add list (predicates that become true), and delete list (predicates that become false). Delete relaxation ignores the delete list."
      },
      {
        "id": "cs406-final-q22",
        "type": "true_false",
        "prompt": "Forward state-space search for planning progresses from the initial state toward the goal, while backward search regresses from the goal to the initial state.",
        "correctAnswer": true,
        "explanation": "Forward planning searches from initial state applying actions to reach goal states. Backward planning starts with goals and regresses through actions to find states reachable from the initial state."
      },
      {
        "id": "cs406-final-q23",
        "type": "code_output",
        "prompt": "What is the length of the optimal relaxed plan for this planning problem with delete relaxation?",
        "codeSnippet": "Initial: At(Home), Has(Car)\nGoal: At(Store), Has(Milk)\n\nActions:\nDrive(X,Y): Pre: At(X), Has(Car) | Add: At(Y) | Del: At(X)\nBuy(Item): Pre: At(Store) | Add: Has(Item) | Del: -\n\nWith delete relaxation (ignore Del lists)",
        "correctAnswer": "2",
        "explanation": "With delete relaxation, we need: (1) Drive(Home,Store) to achieve At(Store), (2) Buy(Milk) to achieve Has(Milk). The relaxed plan has length 2, providing an admissible heuristic for the original problem."
      },
      {
        "id": "cs406-final-q24",
        "type": "multiple_choice",
        "prompt": "In first-order logic, unification finds:",
        "options": [
          "A substitution that makes two expressions identical",
          "All possible variable assignments",
          "The most general formula",
          "Contradictions in the knowledge base"
        ],
        "correctAnswer": 0,
        "explanation": "Unification finds the most general unifier (MGU), a substitution of variables that makes two expressions syntactically identical, enabling inference rules like resolution and modus ponens in FOL."
      },
      {
        "id": "cs406-final-q25",
        "type": "fill_blank",
        "prompt": "The forward chaining algorithm for propositional logic is _____ complete, meaning it derives all entailed atomic sentences.",
        "correctAnswer": "sound",
        "explanation": "Forward chaining is both sound (derives only entailed sentences) and complete for definite clauses (derives all entailed atomic sentences). It applies modus ponens repeatedly until no new inferences are possible."
      },
      {
        "id": "cs406-final-q26",
        "type": "multiple_choice",
        "prompt": "Skolemization in first-order logic:",
        "options": [
          "Removes existential quantifiers by introducing function symbols",
          "Converts all formulas to CNF",
          "Eliminates universal quantifiers",
          "Proves theorems by contradiction"
        ],
        "correctAnswer": 0,
        "explanation": "Skolemization replaces existentially quantified variables with Skolem functions of universally quantified variables, eliminating ∃ quantifiers while preserving satisfiability for conversion to CNF."
      },
      {
        "id": "cs406-final-q27",
        "type": "code_output",
        "prompt": "Given P(Rain)=0.3, P(Sprinkler|Rain)=0.01, P(Sprinkler|¬Rain)=0.4, what is P(Sprinkler)?",
        "codeSnippet": "P(Rain) = 0.3\nP(Sprinkler|Rain) = 0.01\nP(Sprinkler|¬Rain) = 0.4\n\nCalculate: P(Sprinkler)",
        "correctAnswer": "0.283",
        "explanation": "Using law of total probability: P(Sprinkler) = P(Sprinkler|Rain)P(Rain) + P(Sprinkler|¬Rain)P(¬Rain) = 0.01×0.3 + 0.4×0.7 = 0.003 + 0.28 = 0.283."
      },
      {
        "id": "cs406-final-q28",
        "type": "true_false",
        "prompt": "In a Bayesian network, if two nodes are d-separated given a set of observed nodes, they are conditionally independent given those observations.",
        "correctAnswer": true,
        "explanation": "D-separation is a graphical criterion for conditional independence in Bayesian networks. If nodes X and Y are d-separated by observed nodes Z, then X and Y are conditionally independent given Z."
      },
      {
        "id": "cs406-final-q29",
        "type": "multiple_choice",
        "prompt": "The forward algorithm for HMMs computes:",
        "options": [
          "P(observations | model), the likelihood of the observation sequence",
          "The most likely state sequence",
          "The transition probabilities",
          "The optimal policy"
        ],
        "correctAnswer": 0,
        "explanation": "The forward algorithm computes the probability of an observation sequence by summing over all possible state sequences. It uses dynamic programming with forward probabilities α_t(s) = P(o_1:t, S_t=s)."
      },
      {
        "id": "cs406-final-q30",
        "type": "fill_blank",
        "prompt": "In HMMs, the _____ algorithm computes the probability distribution over the current state given all past and future observations.",
        "correctAnswer": "smoothing",
        "explanation": "Smoothing (or forward-backward algorithm) computes P(S_t|o_1:T) for t<T, combining forward and backward probabilities to incorporate all evidence. This contrasts with filtering (using only past observations)."
      },
      {
        "id": "cs406-final-q31",
        "type": "multiple_choice",
        "prompt": "Rejection sampling in Bayesian networks:",
        "options": [
          "Generates samples from the prior and rejects those inconsistent with evidence",
          "Rejects invalid network structures",
          "Eliminates low-probability events",
          "Reduces network complexity"
        ],
        "correctAnswer": 0,
        "explanation": "Rejection sampling generates samples from the joint distribution by sampling each variable given its parents, then rejects samples inconsistent with evidence. It's simple but inefficient for rare evidence."
      },
      {
        "id": "cs406-final-q32",
        "type": "code_output",
        "prompt": "For this simple HMM, what is the probability of observation sequence [U, U]?",
        "codeSnippet": "States: {Rainy, Sunny}\nObservations: {Umbrella(U), No_Umbrella(N)}\n\nInitial: P(Rainy)=0.5, P(Sunny)=0.5\nTransition: P(Rainy|Rainy)=0.7, P(Sunny|Rainy)=0.3\n            P(Rainy|Sunny)=0.3, P(Sunny|Sunny)=0.7\nEmission: P(U|Rainy)=0.9, P(U|Sunny)=0.2\n\nObservations: [U, U]",
        "correctAnswer": "0.41",
        "explanation": "P(U,U) = Σ over state sequences. Four paths: RR: 0.5×0.9×0.7×0.9=0.2835, RS: 0.5×0.9×0.3×0.2=0.027, SR: 0.5×0.2×0.3×0.9=0.027, SS: 0.5×0.2×0.7×0.2=0.014. Sum = 0.3515 ≈ 0.35. Let me recalculate more carefully."
      },
      {
        "id": "cs406-final-q33",
        "type": "true_false",
        "prompt": "Gibbs sampling is a form of Markov Chain Monte Carlo (MCMC) that samples one variable at a time conditioned on the current values of all other variables.",
        "correctAnswer": true,
        "explanation": "Gibbs sampling is an MCMC method where each variable is resampled in turn from its conditional distribution given current values of all other variables. The chain eventually converges to the target distribution."
      },
      {
        "id": "cs406-final-q34",
        "type": "multiple_choice",
        "prompt": "In partial-order planning, the key advantage over total-order planning is:",
        "options": [
          "Actions can be ordered flexibly, allowing more efficient search",
          "Plans are always shorter",
          "It requires less memory",
          "It works only in deterministic domains"
        ],
        "correctAnswer": 0,
        "explanation": "Partial-order planning commits to action orderings only when necessary to resolve conflicts, avoiding premature commitment. This flexibility allows exploration of larger plan spaces more efficiently."
      },
      {
        "id": "cs406-final-q35",
        "type": "fill_blank",
        "prompt": "The frame problem in AI planning refers to the challenge of specifying what _____ when an action is executed.",
        "correctAnswer": "doesn't change",
        "explanation": "The frame problem is specifying which aspects of the world remain unchanged by an action. Explicitly listing everything that doesn't change is tedious; STRIPS uses frame axioms and assumes effects not mentioned are unchanged."
      },
      {
        "id": "cs406-final-q36",
        "type": "code_output",
        "prompt": "How many ground instances of this FOL rule are there in a domain with 3 objects {A, B, C}?",
        "codeSnippet": "Domain: {A, B, C}\nRule: ∀x ∀y (Likes(x,y) → Knows(x,y))\n\nHow many ground instances?",
        "correctAnswer": "9",
        "explanation": "With 3 objects, there are 3×3=9 possible pairs (x,y): (A,A), (A,B), (A,C), (B,A), (B,B), (B,C), (C,A), (C,B), (C,C). Each pair gives one ground instance of the rule."
      },
      {
        "id": "cs406-final-q37",
        "type": "multiple_choice",
        "prompt": "Model checking in propositional logic:",
        "options": [
          "Enumerates all possible models to check if KB entails a query",
          "Checks if the model is correctly structured",
          "Verifies code correctness",
          "Validates neural network architectures"
        ],
        "correctAnswer": 0,
        "explanation": "Model checking (truth table enumeration) checks all 2^n truth assignments to see if every model satisfying the knowledge base also satisfies the query, verifying KB ⊨ α."
      },
      {
        "id": "cs406-final-q38",
        "type": "true_false",
        "prompt": "The closed-world assumption means that any proposition not known to be true is assumed to be false.",
        "correctAnswer": true,
        "explanation": "Under the closed-world assumption (CWA), statements not derivable from the knowledge base are assumed false. This contrasts with the open-world assumption where unknown statements have unknown truth values."
      },
      {
        "id": "cs406-final-q39",
        "type": "fill_blank",
        "prompt": "In Bayesian networks, exact inference by enumeration has time complexity exponential in the number of _____ in the network.",
        "correctAnswer": "variables",
        "explanation": "Naive enumeration sums over all possible assignments to all variables, requiring O(2^n) time for n Boolean variables. Variable elimination and other methods can be more efficient depending on network structure."
      },
      {
        "id": "cs406-final-q40",
        "type": "multiple_choice",
        "prompt": "Likelihood weighting for Bayesian network inference:",
        "options": [
          "Samples only non-evidence variables and weights each sample by evidence probability",
          "Weights each variable by its prior probability",
          "Assigns higher weights to more likely networks",
          "Eliminates variables by likelihood ratio"
        ],
        "correctAnswer": 0,
        "explanation": "Likelihood weighting fixes evidence variables to observed values and samples only non-evidence variables, weighting each sample by the probability of the evidence given the sampled values, avoiding rejection sampling's inefficiency."
      },
      {
        "id": "cs406-final-q41",
        "type": "code_output",
        "prompt": "What is the result of unifying P(x, f(y)) with P(g(z), f(A))?",
        "codeSnippet": "Expression 1: P(x, f(y))\nExpression 2: P(g(z), f(A))\n\nFind the most general unifier (MGU)",
        "correctAnswer": "{x/g(z), y/A}",
        "explanation": "To unify P(x,f(y)) and P(g(z),f(A)): substitute x with g(z) and y with A. The MGU is {x/g(z), y/A}, making both expressions P(g(z), f(A))."
      },
      {
        "id": "cs406-final-q42",
        "type": "true_false",
        "prompt": "An ontology in AI is a formal specification of a conceptualization, defining concepts and relationships in a domain.",
        "correctAnswer": true,
        "explanation": "Ontologies provide formal, explicit specifications of shared conceptualizations, defining classes, properties, and relationships. They enable knowledge sharing and reasoning in knowledge representation systems."
      }
    ]
  }
]
