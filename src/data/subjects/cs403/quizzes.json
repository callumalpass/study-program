[
  {
    "id": "cs403-quiz-1-1",
    "subjectId": "cs403",
    "topicId": "cs403-topic-1",
    "title": "Topic 1: NP-Completeness — Fundamentals",
    "questions": [
      {
        "id": "cs403-q1",
        "type": "multiple_choice",
        "prompt": "Which complexity class contains all decision problems solvable by a deterministic algorithm in polynomial time?",
        "options": [
          "P",
          "NP",
          "co-NP",
          "PSPACE"
        ],
        "correctAnswer": "P",
        "explanation": "P is the class of decision problems solvable in polynomial time on a deterministic model. NP instead captures problems whose solutions can be verified in polynomial time."
      },
      {
        "id": "cs403-q2",
        "type": "multiple_choice",
        "prompt": "A problem is NP-complete if it is:",
        "options": [
          "In NP and NP-hard under polynomial-time many-one reductions",
          "NP-hard, regardless of whether it is in NP",
          "In P and has a polynomial-time verifier",
          "In NP and solvable in polynomial time"
        ],
        "correctAnswer": "In NP and NP-hard under polynomial-time many-one reductions",
        "explanation": "NP-complete means both membership in NP (poly-time verification) and NP-hardness (every NP problem reduces to it). NP-hard alone does not imply membership in NP."
      },
      {
        "id": "cs403-q3",
        "type": "fill_blank",
        "prompt": "Complete the statement: If $A \\le_p B$, then a polynomial-time algorithm for _____ implies a polynomial-time algorithm for $A$.",
        "correctAnswer": "B",
        "explanation": "A reduction $A \\le_p B$ transforms instances of A into instances of B in polynomial time. If you can solve B efficiently, you can solve A by reducing A to B and solving the transformed instance."
      },
      {
        "id": "cs403-q4",
        "type": "true_false",
        "prompt": "If some NP-complete problem can be solved in polynomial time, then P = NP.",
        "correctAnswer": true,
        "explanation": "If any NP-complete problem is in P, then every problem in NP reduces to it and is therefore also in P, implying P = NP."
      },
      {
        "id": "cs403-q5",
        "type": "code_output",
        "prompt": "What is the output of the following TypeScript snippet?",
        "codeSnippet": "function isSatisfied(lit: number, assignment: Record<number, boolean>): boolean {\n  const v = Math.abs(lit);\n  const val = assignment[v] ?? false;\n  return lit > 0 ? val : !val;\n}\n\nconst clause = [1, -2, 3];\nconst a = { 1: false, 2: true, 3: false };\nconsole.log(clause.some(l => isSatisfied(l, a)));",
        "correctAnswer": "false",
        "explanation": "Literal 1 is false, literal -2 is false because x2=true so ¬x2 is false, and literal 3 is false. Since no literal satisfies the clause, `some(...)` returns false and that is printed."
      }
    ]
  },
  {
    "id": "cs403-quiz-1-2",
    "subjectId": "cs403",
    "topicId": "cs403-topic-1",
    "title": "Topic 1: NP-Completeness — Application",
    "questions": [
      {
        "id": "cs403-q6",
        "type": "multiple_choice",
        "prompt": "To show a new problem X is NP-hard, you should typically:",
        "options": [
          "Reduce a known NP-hard/NP-complete problem to X",
          "Reduce X to a known NP-complete problem",
          "Show X has a polynomial-time verifier",
          "Show X is not in NP"
        ],
        "correctAnswer": "Reduce a known NP-hard/NP-complete problem to X",
        "explanation": "To prove NP-hardness, you want to show X is at least as hard as a known hard problem A by giving a polynomial-time reduction A → X."
      },
      {
        "id": "cs403-q7",
        "type": "multiple_choice",
        "prompt": "Which statement correctly distinguishes NP-hard from NP-complete?",
        "options": [
          "NP-complete problems are in NP; NP-hard problems may be outside NP",
          "NP-hard problems are easier than NP-complete problems",
          "NP-complete problems are in P; NP-hard problems are not",
          "NP-hard means “not solvable by nondeterminism”"
        ],
        "correctAnswer": "NP-complete problems are in NP; NP-hard problems may be outside NP",
        "explanation": "NP-complete = NP-hard + in NP. NP-hard is a lower bound notion and can include optimization problems or even undecidable problems."
      },
      {
        "id": "cs403-q8",
        "type": "multiple_choice",
        "prompt": "Which is a valid polynomial-time verifier statement for a decision problem in NP?",
        "options": [
          "Given an instance and a certificate, verify in polynomial time that the certificate proves a YES answer",
          "Given an instance, find a certificate in polynomial time",
          "Given a certificate, decide the problem without the instance",
          "Given an instance, verify all possible certificates in polynomial time"
        ],
        "correctAnswer": "Given an instance and a certificate, verify in polynomial time that the certificate proves a YES answer",
        "explanation": "NP is defined by polynomial-time verification of a proposed certificate for YES instances. Finding certificates (search) is a different requirement."
      },
      {
        "id": "cs403-q9",
        "type": "true_false",
        "prompt": "If A reduces to B in polynomial time and B is NP-hard, then A must be NP-hard.",
        "correctAnswer": false,
        "explanation": "A ≤p B means A is no harder than B. If B is hard, A could still be easy (e.g., A could be in P) because hardness does not transfer “backwards” along reductions."
      },
      {
        "id": "cs403-q10",
        "type": "fill_blank",
        "prompt": "Cook–Levin theorem shows that _____ is NP-complete.",
        "correctAnswer": "SAT",
        "explanation": "Cook–Levin establishes SAT as the first NP-complete problem by encoding polynomial-time nondeterministic computations as Boolean formulas."
      }
    ]
  },
  {
    "id": "cs403-quiz-1-3",
    "subjectId": "cs403",
    "topicId": "cs403-topic-1",
    "title": "Topic 1: NP-Completeness — Mastery",
    "questions": [
      {
        "id": "cs403-q11",
        "type": "multiple_choice",
        "prompt": "Which implication is known to be true?",
        "options": [
          "P ⊆ NP",
          "NP ⊆ P",
          "P = NP",
          "NP ∩ co-NP = ∅"
        ],
        "correctAnswer": "P ⊆ NP",
        "explanation": "Any problem solvable in polynomial time can have its solution verified in polynomial time (using an empty or trivial certificate), so P is contained in NP."
      },
      {
        "id": "cs403-q12",
        "type": "multiple_choice",
        "prompt": "If a language L is NP-complete, then its complement is:",
        "options": [
          "Not known to be NP-complete unless NP = co-NP",
          "Always NP-complete",
          "Always in P",
          "Always outside NP"
        ],
        "correctAnswer": "Not known to be NP-complete unless NP = co-NP",
        "explanation": "Whether complements of NP-complete languages are NP-complete is tied to whether NP equals co-NP, which is unknown. (co-NP contains complements of NP languages.)"
      },
      {
        "id": "cs403-q13",
        "type": "true_false",
        "prompt": "If an optimization problem is NP-hard, its corresponding decision version is necessarily NP-hard.",
        "correctAnswer": true,
        "explanation": "If you can solve the optimization version, you can answer the decision question by comparing the optimum to the threshold. This gives a polynomial-time reduction from decision to optimization."
      },
      {
        "id": "cs403-q14",
        "type": "multiple_choice",
        "prompt": "A polynomial-time Turing reduction (oracle reduction) is generally:",
        "options": [
          "At least as powerful as a polynomial-time many-one reduction",
          "Strictly weaker than a many-one reduction",
          "Only defined for optimization problems",
          "Equivalent to taking complements"
        ],
        "correctAnswer": "At least as powerful as a polynomial-time many-one reduction",
        "explanation": "Many-one reductions make one call after transforming the instance; Turing reductions can make multiple adaptive oracle queries, making them at least as powerful."
      },
      {
        "id": "cs403-q15",
        "type": "fill_blank",
        "prompt": "A problem is in NP if YES instances have certificates verifiable in _____ time.",
        "correctAnswer": "polynomial",
        "explanation": "NP is defined by polynomial-time verification of certificates for YES instances."
      }
    ]
  },
  {
    "id": "cs403-quiz-2-1",
    "subjectId": "cs403",
    "topicId": "cs403-topic-2",
    "title": "Topic 2: Approximation — Fundamentals",
    "questions": [
      {
        "id": "cs403-q16",
        "type": "multiple_choice",
        "prompt": "For a minimization problem, an algorithm is a ρ-approximation if:",
        "options": [
          "It always returns a solution with cost ≤ ρ · OPT",
          "It returns OPT with probability at least ρ",
          "It runs in time O(n^ρ)",
          "It returns a solution with cost ≥ ρ · OPT"
        ],
        "correctAnswer": "It always returns a solution with cost ≤ ρ · OPT",
        "explanation": "For minimization, approximation factor ρ means the algorithm’s solution cost is within a multiplicative factor ρ of the optimal cost."
      },
      {
        "id": "cs403-q17",
        "type": "multiple_choice",
        "prompt": "Which statement correctly defines an FPTAS?",
        "options": [
          "A (1+ε)-approximation scheme with runtime polynomial in n and 1/ε",
          "A constant-factor approximation with runtime polynomial in n",
          "An exact algorithm with expected polynomial runtime",
          "A scheme with runtime polynomial in n and log(1/ε)"
        ],
        "correctAnswer": "A (1+ε)-approximation scheme with runtime polynomial in n and 1/ε",
        "explanation": "An FPTAS is a fully polynomial-time approximation scheme: it produces a (1+ε) solution in time poly(n, 1/ε)."
      },
      {
        "id": "cs403-q18",
        "type": "true_false",
        "prompt": "In metric TSP (triangle inequality), Christofides’ algorithm guarantees a 3/2-approximation.",
        "correctAnswer": true,
        "explanation": "Christofides combines an MST with minimum-weight matching on odd-degree vertices to yield a tour of cost at most 1.5·OPT for metric TSP."
      },
      {
        "id": "cs403-q19",
        "type": "fill_blank",
        "prompt": "The greedy algorithm for Set Cover achieves an approximation ratio of Θ(_____) where n is the universe size.",
        "correctAnswer": "log n",
        "explanation": "Greedy set cover achieves an O(log n) approximation and this is tight under standard complexity assumptions."
      },
      {
        "id": "cs403-q20",
        "type": "multiple_choice",
        "prompt": "A classic 2-approximation for Vertex Cover is based on:",
        "options": [
          "Maximum matching",
          "Minimum spanning tree",
          "Shortest paths",
          "Dynamic programming"
        ],
        "correctAnswer": "Maximum matching",
        "explanation": "Take any maximal matching and include both endpoints of each matched edge; this yields a vertex cover at most twice optimal."
      }
    ]
  },
  {
    "id": "cs403-quiz-2-2",
    "subjectId": "cs403",
    "topicId": "cs403-topic-2",
    "title": "Topic 2: Approximation — Application",
    "questions": [
      {
        "id": "cs403-q21",
        "type": "multiple_choice",
        "prompt": "You have a 2-approximation algorithm for a minimization problem. If OPT = 10, the algorithm guarantees a solution of cost at most:",
        "options": [
          "5",
          "10",
          "20",
          "40"
        ],
        "correctAnswer": "20",
        "explanation": "A 2-approximation guarantees cost ≤ 2·OPT = 20 for minimization."
      },
      {
        "id": "cs403-q22",
        "type": "multiple_choice",
        "prompt": "For unweighted Vertex Cover, the algorithm that repeatedly picks an uncovered edge and adds both endpoints produces:",
        "options": [
          "A 2-approximation",
          "A 1.5-approximation",
          "An exact solution",
          "No approximation guarantee"
        ],
        "correctAnswer": "A 2-approximation",
        "explanation": "The picked edges form a matching, and any vertex cover must include at least one endpoint from each edge in the matching. Taking both endpoints gives factor 2."
      },
      {
        "id": "cs403-q23",
        "type": "code_output",
        "prompt": "What is printed by the following code (assume `OPT = 10`)?",
        "codeSnippet": "const OPT = 10;\nconst rho = 2;\nconst guarantee = rho * OPT;\nconsole.log(guarantee);",
        "correctAnswer": "20",
        "explanation": "The code computes ρ·OPT with ρ=2 and OPT=10, which is 20."
      },
      {
        "id": "cs403-q24",
        "type": "true_false",
        "prompt": "If a PTAS exists for an NP-hard problem, then P = NP.",
        "correctAnswer": false,
        "explanation": "A PTAS gives (1+ε)-approximation in polynomial time for each fixed ε, but the degree of the polynomial may depend on 1/ε. PTAS existence does not imply P=NP."
      },
      {
        "id": "cs403-q25",
        "type": "multiple_choice",
        "prompt": "For 0/1 Knapsack, which statement is true?",
        "options": [
          "There is an FPTAS",
          "No approximation is possible unless P=NP",
          "A 2-approximation is impossible",
          "The problem is solvable exactly in O(n log n)"
        ],
        "correctAnswer": "There is an FPTAS",
        "explanation": "0/1 Knapsack admits an FPTAS via value scaling and dynamic programming, despite being NP-hard."
      }
    ]
  },
  {
    "id": "cs403-quiz-2-3",
    "subjectId": "cs403",
    "topicId": "cs403-topic-2",
    "title": "Topic 2: Approximation — Mastery",
    "questions": [
      {
        "id": "cs403-q26",
        "type": "multiple_choice",
        "prompt": "Hardness of approximation results typically show that:",
        "options": [
          "No polynomial-time algorithm can approximate within a certain factor unless P=NP (or stronger assumptions)",
          "No exponential-time algorithm exists",
          "Randomized algorithms always beat deterministic ones",
          "Greedy algorithms are always optimal"
        ],
        "correctAnswer": "No polynomial-time algorithm can approximate within a certain factor unless P=NP (or stronger assumptions)",
        "explanation": "Inapproximability results bound what approximation ratios are achievable in polynomial time under widely believed assumptions."
      },
      {
        "id": "cs403-q27",
        "type": "multiple_choice",
        "prompt": "The integrality gap of an LP relaxation measures:",
        "options": [
          "How much worse the best integer solution can be compared to the fractional LP optimum",
          "The runtime of the simplex algorithm",
          "The number of constraints in the LP",
          "The probability that rounding succeeds"
        ],
        "correctAnswer": "How much worse the best integer solution can be compared to the fractional LP optimum",
        "explanation": "Integrality gap is the worst-case ratio between the optimal integer solution and the optimal fractional (LP) solution; it informs achievable approximation via rounding."
      },
      {
        "id": "cs403-q28",
        "type": "true_false",
        "prompt": "For minimization problems, rounding an LP solution can never give a solution better than OPT.",
        "correctAnswer": false,
        "explanation": "Rounding can sometimes produce an optimal or even equal-to-OPT solution; it just cannot beat the true optimum for the original integer problem."
      },
      {
        "id": "cs403-q29",
        "type": "fill_blank",
        "prompt": "A PTAS for Euclidean TSP exists in fixed dimension due to the work of _____.",
        "correctAnswer": "Arora",
        "explanation": "Arora (and independently Mitchell) developed PTAS results for Euclidean TSP in fixed dimension using geometric decompositions."
      },
      {
        "id": "cs403-q30",
        "type": "multiple_choice",
        "prompt": "A primal–dual approximation algorithm is most naturally associated with:",
        "options": [
          "Linear programming duality",
          "Divide-and-conquer recurrences",
          "Random sampling",
          "Amortized analysis"
        ],
        "correctAnswer": "Linear programming duality",
        "explanation": "Primal–dual methods simultaneously build a feasible primal solution and a dual certificate that lower-bounds OPT, yielding an approximation factor from complementary slackness-like arguments."
      }
    ]
  },
  {
    "id": "cs403-quiz-3-1",
    "subjectId": "cs403",
    "topicId": "cs403-topic-3",
    "title": "Topic 3: Randomization — Fundamentals",
    "questions": [
      {
        "id": "cs403-q31",
        "type": "multiple_choice",
        "prompt": "A Las Vegas randomized algorithm is one that:",
        "options": [
          "Always outputs a correct answer, but has random runtime",
          "Runs in fixed time but may be wrong",
          "Is correct only with probability ≥ 1/2",
          "Requires an oracle for randomness"
        ],
        "correctAnswer": "Always outputs a correct answer, but has random runtime",
        "explanation": "Las Vegas algorithms never sacrifice correctness; the randomness affects runtime (e.g., expected polynomial time), not the probability of error."
      },
      {
        "id": "cs403-q32",
        "type": "multiple_choice",
        "prompt": "Karger’s min-cut algorithm finds the true min-cut in one run with probability at least:",
        "options": [
          "2/(n(n-1))",
          "1/n",
          "1/2",
          "1/e"
        ],
        "correctAnswer": "2/(n(n-1))",
        "explanation": "Karger’s contraction algorithm succeeds with probability ≥ 2/(n(n−1)) per run; repeating boosts success probability."
      },
      {
        "id": "cs403-q33",
        "type": "true_false",
        "prompt": "Pairwise independent hash functions are sufficient to guarantee zero collisions.",
        "correctAnswer": false,
        "explanation": "Pairwise independence controls collision probability but does not eliminate collisions. Collisions are inevitable when mapping a larger domain to a smaller range."
      },
      {
        "id": "cs403-q34",
        "type": "fill_blank",
        "prompt": "Randomized quicksort has expected time complexity O(n _____).",
        "correctAnswer": "log n",
        "explanation": "Randomized quicksort runs in expected O(n log n) time due to the expected balance of partitions."
      },
      {
        "id": "cs403-q35",
        "type": "code_output",
        "prompt": "What is the output?",
        "codeSnippet": "function trial(p: number): boolean {\n  return Math.random() < p;\n}\n\nlet wins = 0;\nfor (let i = 0; i < 0; i++) {\n  if (trial(0.5)) wins++;\n}\nconsole.log(wins);",
        "correctAnswer": "0",
        "explanation": "The loop runs zero iterations, so `wins` stays 0 and 0 is printed. This question is about reading code carefully, not probability."
      }
    ]
  },
  {
    "id": "cs403-quiz-3-2",
    "subjectId": "cs403",
    "topicId": "cs403-topic-3",
    "title": "Topic 3: Randomization — Application",
    "questions": [
      {
        "id": "cs403-q36",
        "type": "multiple_choice",
        "prompt": "If an event happens with probability at least 1/2 in each independent trial, how many independent trials are needed to make failure probability ≤ 1/16?",
        "options": [
          "2",
          "4",
          "8",
          "16"
        ],
        "correctAnswer": "4",
        "explanation": "Failure per trial is ≤ 1/2. After t independent trials, failure probability is ≤ (1/2)^t. Setting (1/2)^t ≤ 1/16 gives t ≥ 4."
      },
      {
        "id": "cs403-q37",
        "type": "multiple_choice",
        "prompt": "Which technique is commonly used to reduce error probability in a Monte Carlo algorithm?",
        "options": [
          "Amplification via repetition and majority vote",
          "Memoization",
          "Topological sorting",
          "Dynamic programming"
        ],
        "correctAnswer": "Amplification via repetition and majority vote",
        "explanation": "Repeating independent runs and taking a majority vote (or appropriate aggregation) reduces error exponentially in the number of repetitions."
      },
      {
        "id": "cs403-q38",
        "type": "true_false",
        "prompt": "Miller–Rabin primality test can be made to have error probability at most 2^{-k} by running k independent rounds.",
        "correctAnswer": true,
        "explanation": "Each independent round reduces the probability that a composite number is declared “probably prime.” The error decreases exponentially with the number of rounds."
      },
      {
        "id": "cs403-q39",
        "type": "fill_blank",
        "prompt": "Reservoir sampling maintains a uniform random sample of size k from a stream of unknown length using O(_____) memory.",
        "correctAnswer": "k",
        "explanation": "Reservoir sampling stores only the k sampled items (plus small overhead), using O(k) memory independent of stream length."
      },
      {
        "id": "cs403-q40",
        "type": "multiple_choice",
        "prompt": "In randomized selection (Quickselect), the expected time is O(n) because:",
        "options": [
          "The expected size of the remaining subproblem decreases geometrically",
          "It sorts the array first",
          "It always picks the median pivot",
          "It uses a heap"
        ],
        "correctAnswer": "The expected size of the remaining subproblem decreases geometrically",
        "explanation": "With a random pivot, there is a constant probability of discarding a constant fraction of elements each step, giving expected linear time."
      }
    ]
  },
  {
    "id": "cs403-quiz-3-3",
    "subjectId": "cs403",
    "topicId": "cs403-topic-3",
    "title": "Topic 3: Randomization — Mastery",
    "questions": [
      {
        "id": "cs403-q41",
        "type": "multiple_choice",
        "prompt": "Yao’s minimax principle is used to relate:",
        "options": [
          "Randomized algorithm lower bounds to distributions over inputs",
          "Approximation ratios to LP duals",
          "Competitive ratios to amortized costs",
          "Hashing to sorting"
        ],
        "correctAnswer": "Randomized algorithm lower bounds to distributions over inputs",
        "explanation": "Yao’s principle states that the expected cost of the best randomized algorithm on the worst input is at least the expected cost of the best deterministic algorithm on some input distribution."
      },
      {
        "id": "cs403-q42",
        "type": "true_false",
        "prompt": "The linearity of expectation allows computing expected values without any independence assumptions.",
        "correctAnswer": true,
        "explanation": "Linearity of expectation holds regardless of whether random variables are independent, making it a powerful tool in randomized algorithm analysis."
      },
      {
        "id": "cs403-q43",
        "type": "multiple_choice",
        "prompt": "A Chernoff bound is most directly used to bound:",
        "options": [
          "The probability that the sum of independent random variables deviates far from its mean",
          "The worst-case runtime of deterministic algorithms",
          "Exact optimal solutions to NP-hard problems",
          "The number of edges in a graph"
        ],
        "correctAnswer": "The probability that the sum of independent random variables deviates far from its mean",
        "explanation": "Chernoff bounds provide exponentially small tail bounds for sums of independent bounded random variables, commonly used to show concentration around the mean."
      },
      {
        "id": "cs403-q44",
        "type": "fill_blank",
        "prompt": "A Monte Carlo algorithm that always runs in polynomial time but may be wrong has probabilistic _____ (not runtime).",
        "correctAnswer": "correctness",
        "explanation": "Monte Carlo algorithms have bounded runtime and may err; the randomness affects correctness probability rather than runtime."
      },
      {
        "id": "cs403-q45",
        "type": "multiple_choice",
        "prompt": "For Karger’s algorithm, repeating O(n² log n) times is enough to achieve:",
        "options": [
          "High probability of finding the min-cut",
          "Deterministic correctness",
          "Polynomial memory usage instead of linear",
          "Exact max-flow computation"
        ],
        "correctAnswer": "High probability of finding the min-cut",
        "explanation": "Each run succeeds with small probability, but repeating enough times amplifies success to high probability using the union bound and exponential decay."
      }
    ]
  },
  {
    "id": "cs403-quiz-4-1",
    "subjectId": "cs403",
    "topicId": "cs403-topic-4",
    "title": "Topic 4: Online — Fundamentals",
    "questions": [
      {
        "id": "cs403-q46",
        "type": "multiple_choice",
        "prompt": "An online algorithm is one that:",
        "options": [
          "Makes decisions without knowledge of future inputs",
          "Runs only on the internet",
          "Is randomized by definition",
          "Always has a polynomial-time guarantee"
        ],
        "correctAnswer": "Makes decisions without knowledge of future inputs",
        "explanation": "Online algorithms must decide as inputs arrive, without seeing the future. This is why competitive analysis compares them to an optimal offline algorithm."
      },
      {
        "id": "cs403-q47",
        "type": "fill_blank",
        "prompt": "The competitive ratio compares an online algorithm’s cost to the cost of an optimal _____ algorithm.",
        "correctAnswer": "offline",
        "explanation": "Competitive analysis compares an online algorithm to an optimal offline algorithm that knows the entire sequence in advance."
      },
      {
        "id": "cs403-q48",
        "type": "multiple_choice",
        "prompt": "For deterministic paging with cache size k, the competitive ratio lower bound is:",
        "options": [
          "k",
          "log k",
          "2",
          "1"
        ],
        "correctAnswer": "k",
        "explanation": "No deterministic online paging algorithm can do better than k-competitive in general; LRU and FIFO achieve k-competitive."
      },
      {
        "id": "cs403-q49",
        "type": "true_false",
        "prompt": "In the ski rental problem, buying immediately is always optimal.",
        "correctAnswer": false,
        "explanation": "Buying immediately is optimal only if you know you will ski long enough. Without future knowledge, you trade off between renting and buying; the classic deterministic strategy buys after B rental days."
      },
      {
        "id": "cs403-q50",
        "type": "multiple_choice",
        "prompt": "In the secretary problem, the optimal strategy rejects about the first:",
        "options": [
          "n/e candidates",
          "n/2 candidates",
          "n/3 candidates",
          "log n candidates"
        ],
        "correctAnswer": "n/e candidates",
        "explanation": "The classic optimal stopping rule observes the first ~n/e candidates, then selects the next candidate better than all observed, achieving success probability ~1/e."
      }
    ]
  },
  {
    "id": "cs403-quiz-4-2",
    "subjectId": "cs403",
    "topicId": "cs403-topic-4",
    "title": "Topic 4: Online — Application",
    "questions": [
      {
        "id": "cs403-q51",
        "type": "multiple_choice",
        "prompt": "Suppose ski rental buy cost B = 10 and rent cost per day is 1. If you rent for 10 days and then buy, your cost is:",
        "options": [
          "10",
          "11",
          "20",
          "100"
        ],
        "correctAnswer": "20",
        "explanation": "Renting 10 days costs 10, then buying costs 10, total 20."
      },
      {
        "id": "cs403-q52",
        "type": "multiple_choice",
        "prompt": "For paging with cache size k=2, consider request sequence A, B, C, A, B, C. Which algorithm tends to do poorly on this cyclic pattern?",
        "options": [
          "LRU",
          "OPT",
          "An offline algorithm",
          "A clairvoyant algorithm"
        ],
        "correctAnswer": "LRU",
        "explanation": "With cache size 2 and a cycle of 3 pages, LRU will fault on every request after warm-up because it always evicts the page needed soon. OPT would keep the two pages used soonest."
      },
      {
        "id": "cs403-q53",
        "type": "true_false",
        "prompt": "For paging, OPT can be implemented online without future knowledge.",
        "correctAnswer": false,
        "explanation": "OPT (Belady’s algorithm) evicts the page whose next use is farthest in the future, which requires future knowledge and is therefore offline."
      },
      {
        "id": "cs403-q54",
        "type": "code_output",
        "prompt": "What does this print?",
        "codeSnippet": "function rentThenBuy(days: number, B: number): number {\n  let cost = 0;\n  for (let d = 1; d <= days; d++) {\n    cost += 1;\n    if (d === B) cost += B;\n  }\n  return cost;\n}\n\nconsole.log(rentThenBuy(3, 2));",
        "correctAnswer": "5",
        "explanation": "Day 1 adds 1 (cost=1). Day 2 adds 1 then buys for 2 (cost=4). Day 3 adds 1 (cost=5), so it prints 5."
      },
      {
        "id": "cs403-q55",
        "type": "fill_blank",
        "prompt": "A deterministic algorithm for ski rental that buys after B rental days is _____-competitive.",
        "correctAnswer": "2",
        "explanation": "Buying after B days yields a worst-case competitive ratio of 2 for the ski rental problem (with unit rental cost and buy cost B)."
      }
    ]
  },
  {
    "id": "cs403-quiz-4-3",
    "subjectId": "cs403",
    "topicId": "cs403-topic-4",
    "title": "Topic 4: Online — Mastery",
    "questions": [
      {
        "id": "cs403-q56",
        "type": "multiple_choice",
        "prompt": "Randomization can improve competitive ratios by:",
        "options": [
          "Making it harder for an adaptive adversary to force worst-case behavior",
          "Allowing access to future inputs",
          "Turning NP-hard problems into P",
          "Eliminating the need for proofs"
        ],
        "correctAnswer": "Making it harder for an adaptive adversary to force worst-case behavior",
        "explanation": "In some online problems, randomized strategies achieve better expected competitive ratios against an oblivious adversary, compared to deterministic lower bounds."
      },
      {
        "id": "cs403-q57",
        "type": "true_false",
        "prompt": "A competitive ratio of 1 means an online algorithm matches OPT on every input sequence.",
        "correctAnswer": true,
        "explanation": "1-competitive means cost(A) ≤ 1·OPT + c, so aside from an additive constant, it matches optimal for all sequences."
      },
      {
        "id": "cs403-q58",
        "type": "multiple_choice",
        "prompt": "In online bipartite matching, the classic Karp–Vazirani–Vazirani algorithm achieves competitive ratio:",
        "options": [
          "1 - 1/e",
          "1/2",
          "2/3",
          "1/e"
        ],
        "correctAnswer": "1 - 1/e",
        "explanation": "The randomized Ranking algorithm achieves a (1−1/e)-competitive ratio for online bipartite matching under standard models."
      },
      {
        "id": "cs403-q59",
        "type": "fill_blank",
        "prompt": "In competitive analysis for minimization, we compare costs; for maximization, we compare achieved value relative to OPT, yielding a competitive _____.",
        "correctAnswer": "ratio",
        "explanation": "Both settings use a ratio notion; the inequality direction flips for maximization, but the concept remains a competitive ratio against OPT."
      },
      {
        "id": "cs403-q60",
        "type": "multiple_choice",
        "prompt": "The k-server problem is challenging primarily because:",
        "options": [
          "The state depends on server positions and future requests are unknown",
          "Distances are always zero",
          "It reduces to sorting",
          "It can be solved by a single greedy choice"
        ],
        "correctAnswer": "The state depends on server positions and future requests are unknown",
        "explanation": "k-server decisions depend on current server configuration and unknown future requests, leading to complex adversarial sequences and deep competitive analysis."
      }
    ]
  },
  {
    "id": "cs403-quiz-5-1",
    "subjectId": "cs403",
    "topicId": "cs403-topic-5",
    "title": "Topic 5: Advanced DP — Fundamentals",
    "questions": [
      {
        "id": "cs403-q61",
        "type": "multiple_choice",
        "prompt": "Dynamic programming is most appropriate when a problem has:",
        "options": [
          "Optimal substructure and overlapping subproblems",
          "Only optimal substructure",
          "Only overlapping subproblems",
          "No repeated states"
        ],
        "correctAnswer": "Optimal substructure and overlapping subproblems",
        "explanation": "DP exploits overlapping subproblems (reuse) and optimal substructure (optimal solution can be built from optimal subsolutions)."
      },
      {
        "id": "cs403-q62",
        "type": "fill_blank",
        "prompt": "In matrix-chain multiplication, the DP recurrence typically considers splitting the chain at an index _____.",
        "correctAnswer": "k",
        "explanation": "The recurrence tries all split points k between i and j and chooses the one minimizing total multiplications."
      },
      {
        "id": "cs403-q63",
        "type": "true_false",
        "prompt": "The standard matrix-chain multiplication DP runs in O(n^3) time and O(n^2) space.",
        "correctAnswer": true,
        "explanation": "The DP fills an n×n table and for each (i, j) considers O(n) split points, yielding O(n^3) time and O(n^2) space."
      },
      {
        "id": "cs403-q64",
        "type": "multiple_choice",
        "prompt": "Which DP problem is commonly solved using an edit-distance table?",
        "options": [
          "String similarity",
          "Maximum flow",
          "Convex hull",
          "Set cover"
        ],
        "correctAnswer": "String similarity",
        "explanation": "Edit distance computes the minimum number of edits to transform one string into another using a DP table over prefix lengths."
      },
      {
        "id": "cs403-q65",
        "type": "code_output",
        "prompt": "What does this print?",
        "codeSnippet": "const dp: number[] = [0, 1, 1, 2];\nconsole.log(dp[3]);",
        "correctAnswer": "2",
        "explanation": "The code prints the element at index 3 of the array, which is 2."
      }
    ]
  },
  {
    "id": "cs403-quiz-5-2",
    "subjectId": "cs403",
    "topicId": "cs403-topic-5",
    "title": "Topic 5: Advanced DP — Application",
    "questions": [
      {
        "id": "cs403-q66",
        "type": "multiple_choice",
        "prompt": "In Longest Common Subsequence DP, the table entry dp[i][j] typically represents:",
        "options": [
          "LCS length of prefixes X[0..i) and Y[0..j)",
          "Shortest path between i and j",
          "Number of mismatches in prefixes",
          "The lexicographically smallest subsequence"
        ],
        "correctAnswer": "LCS length of prefixes X[0..i) and Y[0..j)",
        "explanation": "Standard LCS DP defines dp[i][j] as the LCS length of the first i characters of X and the first j characters of Y."
      },
      {
        "id": "cs403-q67",
        "type": "true_false",
        "prompt": "For edit distance with unit costs, dp[i][j] can be computed from dp[i-1][j], dp[i][j-1], and dp[i-1][j-1].",
        "correctAnswer": true,
        "explanation": "Insert, delete, and substitute correspond to dp[i][j-1], dp[i-1][j], and dp[i-1][j-1] transitions."
      },
      {
        "id": "cs403-q68",
        "type": "multiple_choice",
        "prompt": "Held–Karp for TSP is an example of DP over:",
        "options": [
          "Subsets",
          "Trees only",
          "Matrices only",
          "Greedy choices"
        ],
        "correctAnswer": "Subsets",
        "explanation": "Held–Karp uses DP over subsets of visited cities and an endpoint, leading to O(n^2 2^n) time."
      },
      {
        "id": "cs403-q69",
        "type": "fill_blank",
        "prompt": "The typical time complexity of Held–Karp TSP is O(n^2 · _____).",
        "correctAnswer": "2^n",
        "explanation": "Held–Karp runs in O(n^2 2^n) time by iterating over all subsets and endpoints."
      },
      {
        "id": "cs403-q70",
        "type": "multiple_choice",
        "prompt": "Which optimization can reduce a DP from O(n^2) space to O(n) space in many problems?",
        "options": [
          "Keeping only the previous row/column when transitions are local",
          "Using recursion instead of iteration",
          "Sorting the input first",
          "Using a heap"
        ],
        "correctAnswer": "Keeping only the previous row/column when transitions are local",
        "explanation": "If dp[i][*] depends only on dp[i-1][*] (or a constant number of prior rows), you can roll arrays and reduce space."
      }
    ]
  },
  {
    "id": "cs403-quiz-5-3",
    "subjectId": "cs403",
    "topicId": "cs403-topic-5",
    "title": "Topic 5: Advanced DP — Mastery",
    "questions": [
      {
        "id": "cs403-q71",
        "type": "multiple_choice",
        "prompt": "Knuth optimization applies to certain interval DP recurrences when:",
        "options": [
          "Quadrangle inequality / monotone optima conditions hold",
          "The DP is over subsets",
          "The DP is randomized",
          "The DP table is sparse"
        ],
        "correctAnswer": "Quadrangle inequality / monotone optima conditions hold",
        "explanation": "Knuth optimization reduces O(n^3) interval DP to O(n^2) when the argmin is monotone and the cost function satisfies required properties."
      },
      {
        "id": "cs403-q72",
        "type": "true_false",
        "prompt": "Bitset convolution tricks can sometimes speed up subset DP for moderate n by using word-level parallelism.",
        "correctAnswer": true,
        "explanation": "Representing sets as bitsets can accelerate transitions via bit operations and SIMD-like parallelism, although it depends on the DP structure."
      },
      {
        "id": "cs403-q73",
        "type": "fill_blank",
        "prompt": "A common technique to speed up DP transitions is to maintain the best candidate in a monotone queue (a form of _____ optimization).",
        "correctAnswer": "convex hull",
        "explanation": "Certain DP recurrences can be optimized using convex hull trick (CHT) or monotone queue techniques when transitions have linear/convex structure."
      },
      {
        "id": "cs403-q74",
        "type": "multiple_choice",
        "prompt": "For subset DP, a typical state is dp[S][v], where S is a subset and v is:",
        "options": [
          "An endpoint/last element",
          "A random seed",
          "A hash function",
          "A heap size"
        ],
        "correctAnswer": "An endpoint/last element",
        "explanation": "Subset DP often tracks the cost of visiting exactly S and ending at v (e.g., Held–Karp). v encodes the “last” choice."
      },
      {
        "id": "cs403-q75",
        "type": "multiple_choice",
        "prompt": "Which statement about DP is generally true?",
        "options": [
          "DP trades space for time by reusing computed subproblems",
          "DP always yields exponential-time algorithms",
          "DP never uses recursion",
          "DP requires randomness"
        ],
        "correctAnswer": "DP trades space for time by reusing computed subproblems",
        "explanation": "DP stores intermediate results to avoid recomputation, often reducing exponential recursion to polynomial time at the cost of additional memory."
      }
    ]
  },
  {
    "id": "cs403-quiz-6-1",
    "subjectId": "cs403",
    "topicId": "cs403-topic-6",
    "title": "Topic 6: Network Flow — Fundamentals",
    "questions": [
      {
        "id": "cs403-q76",
        "type": "multiple_choice",
        "prompt": "A flow network is typically a:",
        "options": [
          "Directed graph with capacities",
          "Undirected graph with weights",
          "Tree with priorities",
          "Planar graph only"
        ],
        "correctAnswer": "Directed graph with capacities",
        "explanation": "Standard max-flow is defined on directed edges with nonnegative capacities, with a source and sink."
      },
      {
        "id": "cs403-q77",
        "type": "fill_blank",
        "prompt": "In a flow network, the residual capacity on a forward edge (u, v) is c(u, v) − _____.",
        "correctAnswer": "f(u, v)",
        "explanation": "Residual capacity tracks how much more flow can be pushed: c_f(u,v) = c(u,v) − f(u,v) for forward edges."
      },
      {
        "id": "cs403-q78",
        "type": "true_false",
        "prompt": "If there is no s→t path in the residual graph, the current flow is maximum.",
        "correctAnswer": true,
        "explanation": "Ford–Fulkerson stops when no augmenting path exists. At that point, the reachable set from s defines a cut whose capacity equals the flow value, proving optimality."
      },
      {
        "id": "cs403-q79",
        "type": "multiple_choice",
        "prompt": "Edmonds–Karp is Ford–Fulkerson where augmenting paths are found using:",
        "options": [
          "BFS (shortest in edges)",
          "DFS (deepest first)",
          "Dijkstra",
          "Bellman–Ford"
        ],
        "correctAnswer": "BFS (shortest in edges)",
        "explanation": "Edmonds–Karp chooses shortest augmenting paths by number of edges using BFS, yielding a polynomial-time bound."
      },
      {
        "id": "cs403-q80",
        "type": "multiple_choice",
        "prompt": "The max-flow min-cut theorem states that:",
        "options": [
          "The value of the maximum s–t flow equals the capacity of the minimum s–t cut",
          "The minimum cut is always unique",
          "Every flow is a cut",
          "Max flow equals number of vertices"
        ],
        "correctAnswer": "The value of the maximum s–t flow equals the capacity of the minimum s–t cut",
        "explanation": "Max-flow min-cut connects flows (primal) and cuts (dual): the maximum flow value equals the minimum cut capacity."
      }
    ]
  },
  {
    "id": "cs403-quiz-6-2",
    "subjectId": "cs403",
    "topicId": "cs403-topic-6",
    "title": "Topic 6: Network Flow — Application",
    "questions": [
      {
        "id": "cs403-q81",
        "type": "multiple_choice",
        "prompt": "Bipartite matching can be reduced to max flow by:",
        "options": [
          "Adding a source connected to left nodes and a sink connected from right nodes, all capacities 1",
          "Running Dijkstra on the bipartite graph",
          "Taking the MST of the bipartite graph",
          "Using dynamic programming over subsets"
        ],
        "correctAnswer": "Adding a source connected to left nodes and a sink connected from right nodes, all capacities 1",
        "explanation": "Construct a flow network with unit capacities: source→left (1), left→right edges (1), right→sink (1). The max flow equals maximum matching size."
      },
      {
        "id": "cs403-q82",
        "type": "true_false",
        "prompt": "Push–relabel maintains a preflow that may violate flow conservation at intermediate vertices.",
        "correctAnswer": true,
        "explanation": "Push–relabel algorithms allow excess at vertices (preflow) and iteratively push excess and relabel heights until a valid maximum flow is obtained."
      },
      {
        "id": "cs403-q83",
        "type": "multiple_choice",
        "prompt": "Minimum-cost flow extends max flow by also minimizing:",
        "options": [
          "Total edge cost of the shipped flow",
          "Number of vertices used",
          "Graph diameter",
          "Maximum degree"
        ],
        "correctAnswer": "Total edge cost of the shipped flow",
        "explanation": "Min-cost flow assigns costs to edges and seeks a feasible flow of given value with minimum total cost."
      },
      {
        "id": "cs403-q84",
        "type": "fill_blank",
        "prompt": "A circulation is a flow with no designated source/sink that satisfies conservation at _____ vertices.",
        "correctAnswer": "all",
        "explanation": "A circulation respects flow conservation at every vertex; constraints come from demands/supplies and edge capacities."
      },
      {
        "id": "cs403-q85",
        "type": "multiple_choice",
        "prompt": "Which application is a natural fit for max flow?",
        "options": [
          "Project selection / closure problems",
          "Sorting numbers",
          "Computing convex hull",
          "Finding primes"
        ],
        "correctAnswer": "Project selection / closure problems",
        "explanation": "Many selection problems reduce to min-cut / max-flow (e.g., maximum closure, project selection with prerequisites) by building a flow network and taking an s–t cut."
      }
    ]
  },
  {
    "id": "cs403-quiz-6-3",
    "subjectId": "cs403",
    "topicId": "cs403-topic-6",
    "title": "Topic 6: Network Flow — Mastery",
    "questions": [
      {
        "id": "cs403-q86",
        "type": "multiple_choice",
        "prompt": "A standard reason Ford–Fulkerson can take exponential time is that:",
        "options": [
          "With irrational capacities, it may never terminate (or may take extremely many augmentations)",
          "BFS is too slow",
          "It requires planar graphs",
          "It always picks minimum cuts first"
        ],
        "correctAnswer": "With irrational capacities, it may never terminate (or may take extremely many augmentations)",
        "explanation": "Ford–Fulkerson’s augmentation count can depend on the numeric value of capacities and the choice of augmenting paths; with irrational capacities it may not terminate."
      },
      {
        "id": "cs403-q87",
        "type": "true_false",
        "prompt": "In Edmonds–Karp, the shortest-path distance (in edges) from s to any vertex in the residual graph never decreases over time.",
        "correctAnswer": true,
        "explanation": "A key invariant in Edmonds–Karp is that BFS layer distances in the residual graph are nondecreasing as augmentations proceed, leading to O(VE^2) time."
      },
      {
        "id": "cs403-q88",
        "type": "multiple_choice",
        "prompt": "The min-cut in an s–t flow network can be recovered at termination by:",
        "options": [
          "Taking vertices reachable from s in the final residual graph",
          "Taking vertices with maximum degree",
          "Taking the smallest SCC",
          "Sorting edges by capacity"
        ],
        "correctAnswer": "Taking vertices reachable from s in the final residual graph",
        "explanation": "When no augmenting path exists, the reachable set S from s in the residual graph forms an s–t cut (S, V\\S) whose capacity equals the max flow value."
      },
      {
        "id": "cs403-q89",
        "type": "fill_blank",
        "prompt": "The dual of the max-flow LP corresponds to the minimum _____ problem.",
        "correctAnswer": "cut",
        "explanation": "Max flow and min cut are primal/dual linear programs, and strong duality yields equality of optimal values."
      },
      {
        "id": "cs403-q90",
        "type": "multiple_choice",
        "prompt": "Multi-commodity flow differs from single-commodity max flow because:",
        "options": [
          "Multiple flows share edge capacities, creating coupling constraints",
          "It requires a single source and sink",
          "It forbids fractional solutions",
          "It can be solved by one BFS"
        ],
        "correctAnswer": "Multiple flows share edge capacities, creating coupling constraints",
        "explanation": "In multi-commodity flow, different commodities compete for capacity on the same edges, leading to coupled constraints and typically harder optimization problems."
      }
    ]
  },
  {
    "id": "cs403-quiz-7-1",
    "subjectId": "cs403",
    "topicId": "cs403-topic-7",
    "title": "Topic 7: Geometry — Fundamentals",
    "questions": [
      {
        "id": "cs403-q91",
        "type": "multiple_choice",
        "prompt": "The convex hull of a set of points in the plane is:",
        "options": [
          "The smallest convex polygon containing all points",
          "The set of all points",
          "The Delaunay triangulation",
          "The minimum spanning tree"
        ],
        "correctAnswer": "The smallest convex polygon containing all points",
        "explanation": "The convex hull is the minimal convex set containing the points; in 2D it is a convex polygon whose vertices are a subset of the points."
      },
      {
        "id": "cs403-q92",
        "type": "fill_blank",
        "prompt": "Graham scan runs in O(n _____) time due to sorting by angle.",
        "correctAnswer": "log n",
        "explanation": "Graham scan sorts points (O(n log n)) and then does a linear scan, so the total time is O(n log n)."
      },
      {
        "id": "cs403-q93",
        "type": "true_false",
        "prompt": "Orientation tests in computational geometry can be computed using a 2D cross product (signed area).",
        "correctAnswer": true,
        "explanation": "The sign of the cross product (b−a)×(c−a) indicates clockwise vs counterclockwise turn, central to convex hull and segment intersection algorithms."
      },
      {
        "id": "cs403-q94",
        "type": "multiple_choice",
        "prompt": "A sweep line algorithm is characterized by:",
        "options": [
          "Processing events in sorted order while maintaining an active set",
          "Randomly sampling points",
          "Always recursing on halves",
          "Using max flow as a subroutine"
        ],
        "correctAnswer": "Processing events in sorted order while maintaining an active set",
        "explanation": "Sweep line methods sort “events” (like segment endpoints) and maintain a data structure of active objects intersecting the sweep line."
      },
      {
        "id": "cs403-q95",
        "type": "code_output",
        "prompt": "What does this print?",
        "codeSnippet": "function cross(ax: number, ay: number, bx: number, by: number): number {\n  return ax * by - ay * bx;\n}\n// a=(0,0), b=(1,0), c=(1,1)\nconst ab = { x: 1, y: 0 };\nconst ac = { x: 1, y: 1 };\nconsole.log(Math.sign(cross(ab.x, ab.y, ac.x, ac.y)));",
        "correctAnswer": "1",
        "explanation": "The cross product is 1*1 − 0*1 = 1, positive, indicating a counterclockwise turn; Math.sign prints 1."
      }
    ]
  },
  {
    "id": "cs403-quiz-7-2",
    "subjectId": "cs403",
    "topicId": "cs403-topic-7",
    "title": "Topic 7: Geometry — Application",
    "questions": [
      {
        "id": "cs403-q96",
        "type": "multiple_choice",
        "prompt": "The divide-and-conquer closest pair of points algorithm runs in:",
        "options": [
          "O(n log n)",
          "O(n^2)",
          "O(log n)",
          "O(n log^2 n)"
        ],
        "correctAnswer": "O(n log n)",
        "explanation": "Closest pair can be solved in O(n log n) by sorting once and using a divide-and-conquer merge step that checks a constant number of neighbors in the strip."
      },
      {
        "id": "cs403-q97",
        "type": "true_false",
        "prompt": "Line segment intersection can be solved in O(n log n) time for n segments using a sweep line algorithm.",
        "correctAnswer": true,
        "explanation": "Bentley–Ottmann finds all intersections in O((n+k) log n), and detecting whether any intersection exists can be done in O(n log n)."
      },
      {
        "id": "cs403-q98",
        "type": "fill_blank",
        "prompt": "Voronoi diagrams are dual to the _____ triangulation.",
        "correctAnswer": "Delaunay",
        "explanation": "The Delaunay triangulation is the geometric dual of the Voronoi diagram: edges connect sites with adjacent Voronoi cells."
      },
      {
        "id": "cs403-q99",
        "type": "multiple_choice",
        "prompt": "A common data structure for 2D orthogonal range searching is a:",
        "options": [
          "Range tree",
          "Heap",
          "Union-find",
          "Trie"
        ],
        "correctAnswer": "Range tree",
        "explanation": "Range trees (and kd-trees) are standard structures for orthogonal range searching, enabling sublinear query times with preprocessing."
      },
      {
        "id": "cs403-q100",
        "type": "multiple_choice",
        "prompt": "Polygon triangulation is often used to:",
        "options": [
          "Decompose a polygon into triangles for rendering or dynamic programming",
          "Compute max flow",
          "Solve set cover exactly",
          "Generate random graphs"
        ],
        "correctAnswer": "Decompose a polygon into triangles for rendering or dynamic programming",
        "explanation": "Triangulation breaks a polygon into triangles, useful in graphics and as a basis for DP solutions on polygons."
      }
    ]
  },
  {
    "id": "cs403-quiz-7-3",
    "subjectId": "cs403",
    "topicId": "cs403-topic-7",
    "title": "Topic 7: Geometry — Mastery",
    "questions": [
      {
        "id": "cs403-q101",
        "type": "multiple_choice",
        "prompt": "Robust computational geometry implementations must often address:",
        "options": [
          "Floating-point precision and degeneracies (collinearity, duplicates)",
          "Only asymptotic runtime",
          "That all inputs are in general position",
          "That sorting is impossible"
        ],
        "correctAnswer": "Floating-point precision and degeneracies (collinearity, duplicates)",
        "explanation": "Geometric predicates are sensitive to numeric error and degenerate cases. Robust implementations use exact arithmetic, epsilons carefully, or symbolic perturbation."
      },
      {
        "id": "cs403-q102",
        "type": "true_false",
        "prompt": "In the plane, computing a convex hull can be done in expected O(n) time using randomized incremental construction.",
        "correctAnswer": true,
        "explanation": "There are randomized incremental algorithms with expected linear time under certain models, though the most common deterministic algorithms are O(n log n)."
      },
      {
        "id": "cs403-q103",
        "type": "fill_blank",
        "prompt": "A standard approach to avoid many floating-point issues in orientation is to use exact _____ arithmetic when feasible.",
        "correctAnswer": "integer",
        "explanation": "If coordinates are integers and within safe range, computing cross products with integer arithmetic avoids rounding error (though overflow must still be managed)."
      },
      {
        "id": "cs403-q104",
        "type": "multiple_choice",
        "prompt": "The output-sensitive convex hull algorithm Jarvis March runs in:",
        "options": [
          "O(nh)",
          "O(n log n)",
          "O(n^2)",
          "O(h log n)"
        ],
        "correctAnswer": "O(nh)",
        "explanation": "Jarvis March (gift wrapping) takes O(nh) time where h is the number of hull vertices, making it fast when the hull is small."
      },
      {
        "id": "cs403-q105",
        "type": "multiple_choice",
        "prompt": "Which statement about computational geometry algorithms is generally true?",
        "options": [
          "Many algorithms rely on sorting events/points and geometric predicates like orientation",
          "Most problems reduce to max flow",
          "Precision issues never arise in practice",
          "All problems have linear-time deterministic solutions"
        ],
        "correctAnswer": "Many algorithms rely on sorting events/points and geometric predicates like orientation",
        "explanation": "A large fraction of planar computational geometry uses sorting and a small set of geometric predicates (orientation, in-circle), combined with sweeps or divide-and-conquer."
      }
    ]
  }
]