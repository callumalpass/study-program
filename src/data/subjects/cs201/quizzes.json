[
  {
    "id": "cs201-quiz-1-1",
    "subjectId": "cs201",
    "topicId": "cs201-1",
    "title": "Algorithm Analysis Fundamentals",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "What does Big-O notation describe regarding an algorithm?",
        "options": [
          "The exact time it takes to run in seconds",
          "The worst-case growth rate of operations as input size increases",
          "The best-case memory usage",
          "The average time taken on a specific CPU"
        ],
        "correctAnswer": 1,
        "explanation": "Big-O notation provides an upper bound on the growth rate of the algorithm's running time relative to the input size, independent of hardware."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "Which of the following represents constant time complexity?",
        "options": [
          "O(1)",
          "O(n)",
          "O(log n)",
          "O(n^2)"
        ],
        "correctAnswer": 0,
        "explanation": "O(1) implies the operation takes the same amount of time regardless of the input size."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "In Big-O analysis, we ignore lower-order terms and constants.",
        "correctAnswer": true,
        "explanation": "Yes, for asymptotic analysis, we care about the dominant term as n approaches infinity. 5n^2 + 100n becomes O(n^2)."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "What is the time complexity of iterating through a list of size n?",
        "options": [
          "O(1)",
          "O(n)",
          "O(log n)",
          "O(n^2)"
        ],
        "correctAnswer": 1,
        "explanation": "Visiting every element once performs n operations, resulting in linear time O(n)."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "The notation used to describe the asymptotic lower bound of an algorithm is Big-______.",
        "correctAnswer": "Omega",
        "explanation": "Big-Omega (Ω) describes the asymptotic lower bound on the growth rate."
      }
    ]
  },
  {
    "id": "cs201-quiz-1-2",
    "subjectId": "cs201",
    "topicId": "cs201-1",
    "title": "Big-O Application",
    "questions": [
      {
        "id": "q1",
        "type": "code_output",
        "prompt": "What is the Big-O complexity of this code?",
        "codeSnippet": "def func(n):\n    for i in range(n):\n        print(i)\n    for j in range(n):\n        print(j)",
        "options": [
          "O(n)",
          "O(n^2)",
          "O(1)",
          "O(2n)"
        ],
        "correctAnswer": 0,
        "explanation": "The loops are sequential, not nested. O(n) + O(n) = O(2n), which simplifies to O(n)."
      },
      {
        "id": "q2",
        "type": "code_output",
        "prompt": "What is the Big-O complexity of this code?",
        "codeSnippet": "def func(n):\n    for i in range(n):\n        for j in range(n):\n            print(i, j)",
        "options": [
          "O(n)",
          "O(n^2)",
          "O(log n)",
          "O(n!)"
        ],
        "correctAnswer": 1,
        "explanation": "The loops are nested. For each of the n iterations of i, the inner loop runs n times. n * n = n^2."
      },
      {
        "id": "q3",
        "type": "multiple_choice",
        "prompt": "Which complexity class is generally considered better (faster) for large n?",
        "options": [
          "O(n)",
          "O(n log n)",
          "O(n^2)",
          "O(2^n)"
        ],
        "correctAnswer": 0,
        "explanation": "O(n) grows slower than O(n log n), O(n^2), and O(2^n)."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "Binary Search has a time complexity of:",
        "options": [
          "O(n)",
          "O(log n)",
          "O(1)",
          "O(n^2)"
        ],
        "correctAnswer": 1,
        "explanation": "Binary search divides the search space in half at each step, resulting in logarithmic complexity."
      },
      {
        "id": "q5",
        "type": "code_output",
        "prompt": "What is the complexity if the loop runs `i = i * 2` instead of `i++` up to n?",
        "codeSnippet": "i = 1\nwhile i < n:\n    print(i)\n    i = i * 2",
        "options": [
          "O(n)",
          "O(n^2)",
          "O(log n)",
          "O(1)"
        ],
        "correctAnswer": 2,
        "explanation": "The variable i doubles each time, so it reaches n in log2(n) steps."
      }
    ]
  },
  {
    "id": "cs201-quiz-1-3",
    "subjectId": "cs201",
    "topicId": "cs201-1",
    "title": "Advanced Analysis",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "What is the complexity of an algorithm that reduces the problem size by 1 at each step (e.g. recursion n -> n-1)?",
        "options": [
          "O(n)",
          "O(log n)",
          "O(n^2)",
          "O(1)"
        ],
        "correctAnswer": 0,
        "explanation": "If you do constant work and reduce problem size by 1, you do n steps. T(n) = T(n-1) + O(1) => O(n)."
      },
      {
        "id": "q2",
        "type": "true_false",
        "prompt": "It is possible for an O(n^2) algorithm to run faster than an O(n) algorithm for small inputs.",
        "correctAnswer": true,
        "explanation": "Yes, because of the constants. 1000n vs n^2. For n=5, 5000 > 25. The O(n^2) is faster."
      },
      {
        "id": "q3",
        "type": "multiple_choice",
        "prompt": "What is the complexity of accessing the nth element in a Linked List?",
        "options": [
          "O(1)",
          "O(n)",
          "O(log n)",
          "O(n^2)"
        ],
        "correctAnswer": 1,
        "explanation": "Unlike arrays (O(1)), you must traverse the linked list pointers from the head to reach the nth node."
      },
      {
        "id": "q4",
        "type": "code_output",
        "prompt": "Analyze this complexity:",
        "codeSnippet": "def func(n):\n    if n <= 1: return\n    func(n - 1)\n    func(n - 1)",
        "options": [
          "O(n)",
          "O(n^2)",
          "O(2^n)",
          "O(log n)"
        ],
        "correctAnswer": 2,
        "explanation": "Each call branches into two recursive calls, creating a binary tree of depth n. 2^0 + 2^1 + ... + 2^n nodes."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "If T(n) = 2T(n/2) + O(n), then by Master Theorem, T(n) is O(_______).",
        "correctAnswer": "n log n",
        "explanation": "This is the standard Merge Sort recurrence case where work is balanced."
      }
    ]
  },
  {
    "id": "cs201-quiz-2-1",
    "subjectId": "cs201",
    "topicId": "cs201-2",
    "title": "Sorting Fundamentals",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "Which sorting algorithm repeatedly finds the minimum element and places it at the beginning?",
        "options": [
          "Bubble Sort",
          "Selection Sort",
          "Insertion Sort",
          "Merge Sort"
        ],
        "correctAnswer": 1,
        "explanation": "Selection Sort works by selecting the minimum element from the unsorted portion and swapping it with the first unsorted element."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "What is the average-case time complexity of Quick Sort?",
        "options": [
          "O(n)",
          "O(n log n)",
          "O(n^2)",
          "O(log n)"
        ],
        "correctAnswer": 1,
        "explanation": "Quick Sort has an average-case complexity of O(n log n) when pivots divide the array reasonably well."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "Merge Sort is a stable sorting algorithm.",
        "correctAnswer": true,
        "explanation": "Merge Sort preserves the relative order of equal elements, making it stable."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "Which sorting algorithm is most efficient for nearly-sorted data?",
        "options": [
          "Quick Sort",
          "Selection Sort",
          "Insertion Sort",
          "Heap Sort"
        ],
        "correctAnswer": 2,
        "explanation": "Insertion Sort runs in O(n) time on nearly-sorted data because elements need minimal shifting."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "The space complexity of Merge Sort is O(___).",
        "correctAnswer": "n",
        "explanation": "Merge Sort requires O(n) auxiliary space to merge the sorted subarrays."
      }
    ]
  },
  {
    "id": "cs201-quiz-2-2",
    "subjectId": "cs201",
    "topicId": "cs201-2",
    "title": "Sorting Analysis",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "What causes Quick Sort to degrade to O(n^2) time complexity?",
        "options": [
          "Random input data",
          "Choosing the first element as pivot on sorted data",
          "Using too much memory",
          "Having duplicate elements"
        ],
        "correctAnswer": 1,
        "explanation": "When the pivot is always the smallest or largest element (e.g., first element on sorted data), partitions become unbalanced."
      },
      {
        "id": "q2",
        "type": "code_output",
        "prompt": "After one pass of Bubble Sort (left to right), what is guaranteed?",
        "codeSnippet": "arr = [5, 3, 8, 4, 2]\n# One pass of bubble sort",
        "options": [
          "The array is sorted",
          "The smallest element is at position 0",
          "The largest element is at the last position",
          "Nothing is guaranteed"
        ],
        "correctAnswer": 2,
        "explanation": "Bubble Sort \"bubbles up\" the largest element to the end after each complete pass."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "Heap Sort is a stable sorting algorithm.",
        "correctAnswer": false,
        "explanation": "Heap Sort is not stable because the heap operations can change the relative order of equal elements."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "Which algorithm has the best worst-case time complexity?",
        "options": [
          "Quick Sort",
          "Bubble Sort",
          "Merge Sort",
          "Insertion Sort"
        ],
        "correctAnswer": 2,
        "explanation": "Merge Sort has O(n log n) worst-case, while Quick Sort can degrade to O(n^2) and Bubble/Insertion are O(n^2)."
      },
      {
        "id": "q5",
        "type": "multiple_choice",
        "prompt": "What is the primary advantage of Heap Sort over Merge Sort?",
        "options": [
          "Better average-case performance",
          "Stability",
          "O(1) auxiliary space",
          "Simpler implementation"
        ],
        "correctAnswer": 2,
        "explanation": "Heap Sort sorts in-place using only O(1) extra space, while Merge Sort requires O(n) auxiliary space."
      }
    ]
  },
  {
    "id": "cs201-quiz-2-3",
    "subjectId": "cs201",
    "topicId": "cs201-2",
    "title": "Sorting Applications",
    "questions": [
      {
        "id": "q1",
        "type": "code_output",
        "prompt": "What sorting algorithm does this represent?",
        "codeSnippet": "def sort(arr):\n    for i in range(1, len(arr)):\n        key = arr[i]\n        j = i - 1\n        while j >= 0 and arr[j] > key:\n            arr[j + 1] = arr[j]\n            j -= 1\n        arr[j + 1] = key",
        "options": [
          "Bubble Sort",
          "Selection Sort",
          "Insertion Sort",
          "Quick Sort"
        ],
        "correctAnswer": 2,
        "explanation": "This is Insertion Sort - it takes each element and inserts it into its correct position in the sorted portion."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "Python's built-in sort() uses which algorithm?",
        "options": [
          "Quick Sort",
          "Merge Sort",
          "Timsort",
          "Heap Sort"
        ],
        "correctAnswer": 2,
        "explanation": "Python uses Timsort, a hybrid of Merge Sort and Insertion Sort, optimized for real-world data."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "Selection Sort performs the minimum number of swaps among O(n^2) sorting algorithms.",
        "correctAnswer": true,
        "explanation": "Selection Sort makes exactly n-1 swaps (one per pass), which is optimal for minimizing writes."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "When sorting records where maintaining original order of equal elements matters, which should you use?",
        "options": [
          "Quick Sort",
          "Heap Sort",
          "Merge Sort",
          "Selection Sort"
        ],
        "correctAnswer": 2,
        "explanation": "When stability matters (preserving order of equal elements), use a stable sort like Merge Sort."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "The technique of choosing the median of three elements as pivot in Quick Sort helps avoid ______ case performance.",
        "correctAnswer": "worst",
        "explanation": "Median-of-three pivot selection helps avoid the worst case of O(n^2) on sorted or reverse-sorted input."
      }
    ]
  },
  {
    "id": "cs201-quiz-3-1",
    "subjectId": "cs201",
    "topicId": "cs201-3",
    "title": "Searching Fundamentals",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "What is the prerequisite for Binary Search?",
        "options": [
          "The array must be in a linked list",
          "The array must be sorted",
          "The array must have unique elements",
          "The array must be small"
        ],
        "correctAnswer": 1,
        "explanation": "Binary Search requires sorted data to determine which half to search next."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "What is the time complexity of Linear Search?",
        "options": [
          "O(1)",
          "O(log n)",
          "O(n)",
          "O(n^2)"
        ],
        "correctAnswer": 2,
        "explanation": "Linear Search checks each element one by one, requiring up to n comparisons in the worst case."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "Binary Search can be used on a linked list efficiently.",
        "correctAnswer": false,
        "explanation": "Binary Search requires O(1) random access. Linked lists have O(n) access time, negating the benefit."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "In Binary Search, if arr[mid] > target, what should you do?",
        "options": [
          "Search the right half",
          "Search the left half",
          "Return mid",
          "Return -1"
        ],
        "correctAnswer": 1,
        "explanation": "If the middle element is greater than target, the target must be in the left (smaller) half."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "For an array of 1 million sorted elements, Binary Search needs at most ____ comparisons.",
        "correctAnswer": "20",
        "explanation": "log2(1,000,000) ≈ 20. Binary Search halves the search space each time."
      }
    ]
  },
  {
    "id": "cs201-quiz-3-2",
    "subjectId": "cs201",
    "topicId": "cs201-3",
    "title": "Binary Search Variants",
    "questions": [
      {
        "id": "q1",
        "type": "code_output",
        "prompt": "What does this modified binary search return?",
        "codeSnippet": "def search(arr, target):\n    low, high = 0, len(arr) - 1\n    result = -1\n    while low <= high:\n        mid = (low + high) // 2\n        if arr[mid] == target:\n            result = mid\n            high = mid - 1  # Keep searching left\n        elif arr[mid] < target:\n            low = mid + 1\n        else:\n            high = mid - 1\n    return result",
        "options": [
          "The index of target",
          "The first occurrence of target",
          "The last occurrence of target",
          "The count of target"
        ],
        "correctAnswer": 1,
        "explanation": "When target is found, it continues searching left (high = mid - 1) to find the first occurrence."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "What is the safe way to calculate mid to avoid integer overflow?",
        "options": [
          "mid = (low + high) / 2",
          "mid = low + (high - low) / 2",
          "mid = high - low / 2",
          "mid = (low * high) / 2"
        ],
        "correctAnswer": 1,
        "explanation": "low + (high - low) // 2 avoids overflow that can occur with (low + high) // 2 in some languages."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "Interpolation Search outperforms Binary Search on all sorted datasets.",
        "correctAnswer": false,
        "explanation": "Interpolation Search is only better for uniformly distributed data. On non-uniform data, it can be O(n)."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "What is the purpose of finding \"lower bound\" in a sorted array?",
        "options": [
          "Find the smallest element",
          "Find the first position where target could be inserted",
          "Find the last element smaller than target",
          "Count elements equal to target"
        ],
        "correctAnswer": 1,
        "explanation": "Lower bound returns the first position where target could be inserted while maintaining sorted order."
      },
      {
        "id": "q5",
        "type": "multiple_choice",
        "prompt": "How many elements are eliminated after each comparison in Binary Search?",
        "options": [
          "1",
          "log n",
          "Half of remaining",
          "n - 1"
        ],
        "correctAnswer": 2,
        "explanation": "Each comparison eliminates approximately half of the remaining search space."
      }
    ]
  },
  {
    "id": "cs201-quiz-3-3",
    "subjectId": "cs201",
    "topicId": "cs201-3",
    "title": "Search Applications",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "You need to search a list once. The list is unsorted. What should you do?",
        "options": [
          "Sort then Binary Search",
          "Use Linear Search",
          "Use Interpolation Search",
          "Use a Hash Table"
        ],
        "correctAnswer": 1,
        "explanation": "For a single search, Linear Search O(n) is faster than Sort O(n log n) + Binary Search O(log n)."
      },
      {
        "id": "q2",
        "type": "true_false",
        "prompt": "Binary Search can be used to find the square root of a number.",
        "correctAnswer": true,
        "explanation": "Binary Search can find sqrt(n) by searching for x where x*x = n in the range [0, n]."
      },
      {
        "id": "q3",
        "type": "multiple_choice",
        "prompt": "What data structure provides O(1) average-case search?",
        "options": [
          "Sorted Array",
          "Linked List",
          "Hash Table",
          "Binary Search Tree"
        ],
        "correctAnswer": 2,
        "explanation": "Hash Tables provide O(1) average-case lookup through direct addressing via hash functions."
      },
      {
        "id": "q4",
        "type": "code_output",
        "prompt": "What is wrong with this Binary Search?",
        "codeSnippet": "def search(arr, target):\n    low, high = 0, len(arr) - 1\n    while low < high:  # Bug here\n        mid = (low + high) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] < target:\n            low = mid + 1\n        else:\n            high = mid - 1\n    return -1",
        "options": [
          "mid calculation is wrong",
          "Should be low <= high",
          "Return value is wrong",
          "high initialization is wrong"
        ],
        "correctAnswer": 1,
        "explanation": "Using low < high instead of low <= high misses the case when low == high (single element remaining)."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "Binary Search is an example of the ______ and Conquer paradigm.",
        "correctAnswer": "Divide",
        "explanation": "Binary Search divides the problem in half at each step, a key characteristic of Divide and Conquer."
      }
    ]
  },
  {
    "id": "cs201-quiz-4-1",
    "subjectId": "cs201",
    "topicId": "cs201-4",
    "title": "Divide and Conquer Basics",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "What are the three steps of Divide and Conquer?",
        "options": [
          "Split, Sort, Merge",
          "Divide, Conquer, Combine",
          "Break, Solve, Join",
          "Partition, Recurse, Return"
        ],
        "correctAnswer": 1,
        "explanation": "D&C has three steps: Divide the problem, Conquer (solve) subproblems recursively, Combine solutions."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "Which algorithm is NOT a Divide and Conquer algorithm?",
        "options": [
          "Merge Sort",
          "Quick Sort",
          "Insertion Sort",
          "Binary Search"
        ],
        "correctAnswer": 2,
        "explanation": "Insertion Sort builds the solution incrementally without dividing the problem into subproblems."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "In Divide and Conquer, subproblems should ideally be independent of each other.",
        "correctAnswer": true,
        "explanation": "Independent subproblems allow for efficient solving. Overlapping subproblems are better suited for DP."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "What is the recurrence relation for Merge Sort?",
        "options": [
          "T(n) = T(n-1) + O(n)",
          "T(n) = 2T(n/2) + O(n)",
          "T(n) = T(n/2) + O(1)",
          "T(n) = 2T(n-1) + O(1)"
        ],
        "correctAnswer": 1,
        "explanation": "Merge Sort splits into 2 halves (2T(n/2)) and merges in linear time (O(n))."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "The ______ Theorem provides a formula for solving recurrence relations of the form T(n) = aT(n/b) + f(n).",
        "correctAnswer": "Master",
        "explanation": "The Master Theorem is a \"recipe\" for solving common divide-and-conquer recurrences."
      }
    ]
  },
  {
    "id": "cs201-quiz-4-2",
    "subjectId": "cs201",
    "topicId": "cs201-4",
    "title": "Master Theorem",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "For T(n) = 2T(n/2) + O(1), what is the complexity?",
        "options": [
          "O(n)",
          "O(log n)",
          "O(n log n)",
          "O(n^2)"
        ],
        "correctAnswer": 0,
        "explanation": "a=2, b=2, d=0. Since a > b^d (2 > 1), T(n) = O(n^log_b(a)) = O(n)."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "For T(n) = T(n/2) + O(1) (Binary Search), what is the complexity?",
        "options": [
          "O(n)",
          "O(log n)",
          "O(n log n)",
          "O(1)"
        ],
        "correctAnswer": 1,
        "explanation": "a=1, b=2, d=0. Since a = b^d (1 = 1), T(n) = O(n^d log n) = O(log n)."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "The Master Theorem can solve all recurrence relations.",
        "correctAnswer": false,
        "explanation": "Master Theorem only applies to recurrences of the form T(n) = aT(n/b) + f(n). Many recurrences don't fit this form."
      },
      {
        "id": "q4",
        "type": "code_output",
        "prompt": "What is the time complexity of this algorithm?",
        "codeSnippet": "def mystery(arr, low, high):\n    if low >= high:\n        return\n    mid = (low + high) // 2\n    mystery(arr, low, mid)\n    mystery(arr, mid + 1, high)\n    # O(n) work here\n    merge(arr, low, mid, high)",
        "options": [
          "O(n)",
          "O(n log n)",
          "O(n^2)",
          "O(log n)"
        ],
        "correctAnswer": 1,
        "explanation": "This is Merge Sort: T(n) = 2T(n/2) + O(n) = O(n log n) by the Master Theorem."
      },
      {
        "id": "q5",
        "type": "multiple_choice",
        "prompt": "In the Master Theorem, when does the \"combine\" step dominate?",
        "options": [
          "When a > b^d",
          "When a = b^d",
          "When a < b^d",
          "Never"
        ],
        "correctAnswer": 2,
        "explanation": "When a < b^d, the work done at each level decreases, so the combine step at the root dominates: O(n^d)."
      }
    ]
  },
  {
    "id": "cs201-quiz-4-3",
    "subjectId": "cs201",
    "topicId": "cs201-4",
    "title": "D&C Applications",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "The Maximum Subarray problem can be solved in what time using D&C?",
        "options": [
          "O(n)",
          "O(n log n)",
          "O(n^2)",
          "O(n^3)"
        ],
        "correctAnswer": 1,
        "explanation": "D&C achieves O(n log n) by splitting, finding max in each half, and checking crossing subarrays."
      },
      {
        "id": "q2",
        "type": "true_false",
        "prompt": "Karatsuba multiplication uses Divide and Conquer to multiply large numbers faster than O(n^2).",
        "correctAnswer": true,
        "explanation": "Karatsuba achieves O(n^1.585) by cleverly reducing 4 recursive multiplications to 3."
      },
      {
        "id": "q3",
        "type": "multiple_choice",
        "prompt": "What happens if Divide and Conquer splits into very unbalanced subproblems?",
        "options": [
          "Performance improves",
          "Performance degrades significantly",
          "No effect on performance",
          "Space usage decreases"
        ],
        "correctAnswer": 1,
        "explanation": "Unbalanced splits (like 1 and n-1) lead to O(n^2) instead of O(n log n) - this is why Quick Sort can be slow."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "The Closest Pair of Points problem has what complexity using D&C?",
        "options": [
          "O(n)",
          "O(n log n)",
          "O(n^2)",
          "O(n^3)"
        ],
        "correctAnswer": 1,
        "explanation": "D&C achieves O(n log n) for closest pair, much better than brute force O(n^2)."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "When subproblems in D&C overlap significantly, you should use ______ Programming instead.",
        "correctAnswer": "Dynamic",
        "explanation": "Dynamic Programming is designed for overlapping subproblems, storing solutions to avoid recomputation."
      }
    ]
  },
  {
    "id": "cs201-quiz-5-1",
    "subjectId": "cs201",
    "topicId": "cs201-5",
    "title": "DP Fundamentals",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "What are the two key properties required for Dynamic Programming?",
        "options": [
          "Sorting and Searching",
          "Optimal Substructure and Overlapping Subproblems",
          "Divide and Conquer",
          "Greedy Choice and Local Optimum"
        ],
        "correctAnswer": 1,
        "explanation": "DP requires optimal substructure (solution built from subproblem solutions) and overlapping subproblems (same subproblems solved multiple times)."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "What is Memoization?",
        "options": [
          "Bottom-up iteration",
          "Top-down recursion with caching",
          "Sorting before processing",
          "Using hash tables for search"
        ],
        "correctAnswer": 1,
        "explanation": "Memoization is top-down: solve recursively but cache results to avoid recomputation."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "The naive recursive Fibonacci has exponential time complexity O(2^n).",
        "correctAnswer": true,
        "explanation": "Without memoization, each call branches into two, creating an exponential number of calls."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "What is the time complexity of Fibonacci with DP?",
        "options": [
          "O(2^n)",
          "O(n^2)",
          "O(n)",
          "O(log n)"
        ],
        "correctAnswer": 2,
        "explanation": "With DP (memoization or tabulation), each subproblem is solved once, giving O(n) time."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "Building a solution from smallest subproblems up is called ______.",
        "correctAnswer": "Tabulation",
        "explanation": "Tabulation (bottom-up DP) fills a table starting from base cases, building up to the answer."
      }
    ]
  },
  {
    "id": "cs201-quiz-5-2",
    "subjectId": "cs201",
    "topicId": "cs201-5",
    "title": "Classic DP Problems",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "In the 0/1 Knapsack problem, what does \"0/1\" mean?",
        "options": [
          "Items have binary weights",
          "Each item can be taken at most once (take or leave)",
          "There are only 2 items",
          "The knapsack has 1 compartment"
        ],
        "correctAnswer": 1,
        "explanation": "0/1 means each item is either taken (1) or not taken (0) - no fractions allowed."
      },
      {
        "id": "q2",
        "type": "code_output",
        "prompt": "What problem does this DP solve?",
        "codeSnippet": "dp[i][j] = dp[i-1][j-1] + 1 if s1[i-1] == s2[j-1]\n         else max(dp[i-1][j], dp[i][j-1])",
        "options": [
          "Edit Distance",
          "Longest Common Subsequence",
          "Knapsack",
          "Coin Change"
        ],
        "correctAnswer": 1,
        "explanation": "This recurrence finds the Longest Common Subsequence (LCS) by matching characters or taking max of excluding either."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "The Coin Change problem (minimum coins) can be solved greedily for all coin denominations.",
        "correctAnswer": false,
        "explanation": "Greedy fails for some denominations (e.g., coins [1,3,4] for amount 6: greedy gives 4+1+1=3 coins, optimal is 3+3=2)."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "What is the space complexity of naive 2D DP for LCS of strings of length m and n?",
        "options": [
          "O(1)",
          "O(m+n)",
          "O(mn)",
          "O(m^2 + n^2)"
        ],
        "correctAnswer": 2,
        "explanation": "Standard LCS DP uses a 2D table of size m×n, giving O(mn) space."
      },
      {
        "id": "q5",
        "type": "multiple_choice",
        "prompt": "The \"Climbing Stairs\" problem (ways to climb n stairs with 1 or 2 steps) is equivalent to:",
        "options": [
          "Binary Search",
          "Fibonacci Sequence",
          "Quick Sort partition",
          "Graph BFS"
        ],
        "correctAnswer": 1,
        "explanation": "Ways(n) = Ways(n-1) + Ways(n-2), which is exactly the Fibonacci recurrence."
      }
    ]
  },
  {
    "id": "cs201-quiz-5-3",
    "subjectId": "cs201",
    "topicId": "cs201-5",
    "title": "DP Optimization",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "If dp[i] only depends on dp[i-1], what space optimization is possible?",
        "options": [
          "No optimization possible",
          "Reduce from O(n) to O(1)",
          "Reduce from O(n^2) to O(n)",
          "Use recursion instead"
        ],
        "correctAnswer": 1,
        "explanation": "When only the previous state is needed, use two variables instead of an array, achieving O(1) space."
      },
      {
        "id": "q2",
        "type": "true_false",
        "prompt": "Memoization and Tabulation always have the same time complexity for a given problem.",
        "correctAnswer": true,
        "explanation": "Both approaches solve each unique subproblem exactly once, resulting in the same asymptotic time complexity."
      },
      {
        "id": "q3",
        "type": "multiple_choice",
        "prompt": "What is a key advantage of Tabulation over Memoization?",
        "options": [
          "Easier to implement",
          "No recursion stack overhead",
          "Better time complexity",
          "Works on more problems"
        ],
        "correctAnswer": 1,
        "explanation": "Tabulation uses iteration, avoiding recursion stack overflow issues for large inputs."
      },
      {
        "id": "q4",
        "type": "code_output",
        "prompt": "What is the space complexity of this optimized Fibonacci?",
        "codeSnippet": "def fib(n):\n    if n <= 1: return n\n    a, b = 0, 1\n    for _ in range(2, n + 1):\n        a, b = b, a + b\n    return b",
        "options": [
          "O(n)",
          "O(log n)",
          "O(1)",
          "O(n^2)"
        ],
        "correctAnswer": 2,
        "explanation": "Only two variables (a, b) are used regardless of n, giving O(1) space."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "The number of unique subproblems determines the ______ of a DP solution.",
        "correctAnswer": "time complexity",
        "explanation": "Since each subproblem is solved once, total time equals number of subproblems × time per subproblem."
      }
    ]
  },
  {
    "id": "cs201-quiz-6-1",
    "subjectId": "cs201",
    "topicId": "cs201-6",
    "title": "Greedy Fundamentals",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "What is the Greedy Choice Property?",
        "options": [
          "Always choose the largest element",
          "A globally optimal solution can be reached by making locally optimal choices",
          "Sort the input before processing",
          "Use recursion for all decisions"
        ],
        "correctAnswer": 1,
        "explanation": "Greedy algorithms work when making the best local choice at each step leads to a global optimum."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "Which problem can be solved optimally with a greedy algorithm?",
        "options": [
          "0/1 Knapsack",
          "Longest Common Subsequence",
          "Activity Selection",
          "Traveling Salesman"
        ],
        "correctAnswer": 2,
        "explanation": "Activity Selection (choosing non-overlapping activities) has the greedy choice property."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "Greedy algorithms always find the optimal solution.",
        "correctAnswer": false,
        "explanation": "Greedy only works for problems with the greedy choice property. It fails for 0/1 Knapsack, TSP, etc."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "In Activity Selection, what greedy strategy works?",
        "options": [
          "Choose the longest activity first",
          "Choose the activity that starts earliest",
          "Choose the activity that finishes earliest",
          "Choose randomly"
        ],
        "correctAnswer": 2,
        "explanation": "Selecting the earliest-finishing activity leaves maximum time for remaining activities."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "In Fractional Knapsack, items are sorted by their value-to-______ ratio.",
        "correctAnswer": "weight",
        "explanation": "Taking items with highest value/weight ratio first maximizes value per unit capacity."
      }
    ]
  },
  {
    "id": "cs201-quiz-6-2",
    "subjectId": "cs201",
    "topicId": "cs201-6",
    "title": "Greedy vs DP",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "Why does greedy fail for 0/1 Knapsack?",
        "options": [
          "Items are too heavy",
          "Taking the \"best\" item may prevent better combinations",
          "The problem is NP-hard",
          "Sorting is too slow"
        ],
        "correctAnswer": 1,
        "explanation": "Taking a high-ratio item might use capacity that could hold multiple smaller items with greater total value."
      },
      {
        "id": "q2",
        "type": "true_false",
        "prompt": "Fractional Knapsack can be solved greedily, but 0/1 Knapsack cannot.",
        "correctAnswer": true,
        "explanation": "Fractional Knapsack allows partial items, so greedy by value/weight ratio works. 0/1 requires DP."
      },
      {
        "id": "q3",
        "type": "multiple_choice",
        "prompt": "What is typically the time complexity of greedy algorithms?",
        "options": [
          "O(1)",
          "O(n)",
          "O(n log n)",
          "O(2^n)"
        ],
        "correctAnswer": 2,
        "explanation": "Most greedy algorithms involve sorting O(n log n) followed by a linear scan O(n)."
      },
      {
        "id": "q4",
        "type": "code_output",
        "prompt": "This greedy approach fails for which coin set?",
        "codeSnippet": "def min_coins(coins, amount):\n    coins.sort(reverse=True)\n    count = 0\n    for coin in coins:\n        while amount >= coin:\n            amount -= coin\n            count += 1\n    return count",
        "options": [
          "coins = [1, 5, 10, 25]",
          "coins = [1, 3, 4]",
          "coins = [1, 2, 5]",
          "coins = [1]"
        ],
        "correctAnswer": 1,
        "explanation": "For coins [1,3,4] and amount 6: greedy gives 4+1+1=3 coins, but optimal is 3+3=2 coins."
      },
      {
        "id": "q5",
        "type": "multiple_choice",
        "prompt": "When should you use DP instead of Greedy?",
        "options": [
          "When the input is sorted",
          "When local choices affect future options in complex ways",
          "When the input is small",
          "When speed is critical"
        ],
        "correctAnswer": 1,
        "explanation": "Use DP when the optimal choice depends on exploring multiple possibilities, not just the locally best one."
      }
    ]
  },
  {
    "id": "cs201-quiz-6-3",
    "subjectId": "cs201",
    "topicId": "cs201-6",
    "title": "Greedy Applications",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "Huffman Coding is a greedy algorithm for:",
        "options": [
          "Sorting data",
          "Data compression",
          "Graph traversal",
          "Searching"
        ],
        "correctAnswer": 1,
        "explanation": "Huffman Coding creates optimal prefix-free codes for data compression by greedily combining lowest-frequency nodes."
      },
      {
        "id": "q2",
        "type": "true_false",
        "prompt": "Dijkstra's shortest path algorithm uses a greedy approach.",
        "correctAnswer": true,
        "explanation": "Dijkstra greedily selects the unvisited node with smallest distance, which works for non-negative weights."
      },
      {
        "id": "q3",
        "type": "multiple_choice",
        "prompt": "What data structure is commonly used in greedy algorithms?",
        "options": [
          "Stack",
          "Queue",
          "Priority Queue (Heap)",
          "Linked List"
        ],
        "correctAnswer": 2,
        "explanation": "Priority queues efficiently retrieve the \"best\" element (min or max), essential for greedy selection."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "Which Minimum Spanning Tree algorithm is greedy?",
        "options": [
          "Only Kruskal's",
          "Only Prim's",
          "Both Kruskal's and Prim's",
          "Neither"
        ],
        "correctAnswer": 2,
        "explanation": "Both are greedy: Kruskal's picks smallest edges globally, Prim's picks smallest edges from current tree."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "To prove a greedy algorithm is correct, we often use the ______ argument.",
        "correctAnswer": "exchange",
        "explanation": "The exchange argument shows that swapping a non-greedy choice with a greedy one never makes things worse."
      }
    ]
  },
  {
    "id": "cs201-quiz-7-1",
    "subjectId": "cs201",
    "topicId": "cs201-7",
    "title": "Graph Basics",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "What is the space complexity of an adjacency matrix for a graph with V vertices?",
        "options": [
          "O(V)",
          "O(E)",
          "O(V^2)",
          "O(V + E)"
        ],
        "correctAnswer": 2,
        "explanation": "An adjacency matrix is a V×V 2D array, requiring O(V^2) space regardless of edge count."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "Which representation is better for sparse graphs?",
        "options": [
          "Adjacency Matrix",
          "Adjacency List",
          "Both are equal",
          "Edge List"
        ],
        "correctAnswer": 1,
        "explanation": "Adjacency List uses O(V + E) space, much better than O(V^2) for sparse graphs where E << V^2."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "BFS uses a queue while DFS uses a stack (or recursion).",
        "correctAnswer": true,
        "explanation": "BFS explores level by level (FIFO queue), DFS goes deep first (LIFO stack/recursion)."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "What is the time complexity of BFS on a graph with V vertices and E edges?",
        "options": [
          "O(V)",
          "O(E)",
          "O(V + E)",
          "O(V * E)"
        ],
        "correctAnswer": 2,
        "explanation": "BFS visits each vertex once O(V) and examines each edge once O(E), giving O(V + E)."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "BFS finds the shortest path in ______ graphs.",
        "correctAnswer": "unweighted",
        "explanation": "BFS guarantees shortest path only when all edges have equal weight (unweighted). For weighted graphs, use Dijkstra."
      }
    ]
  },
  {
    "id": "cs201-quiz-7-2",
    "subjectId": "cs201",
    "topicId": "cs201-7",
    "title": "Shortest Paths",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "Dijkstra's algorithm fails when the graph has:",
        "options": [
          "Cycles",
          "Disconnected components",
          "Negative edge weights",
          "More than 1000 vertices"
        ],
        "correctAnswer": 2,
        "explanation": "Dijkstra assumes once a node is finalized, its distance is optimal. Negative edges can violate this."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "What is the time complexity of Dijkstra with a binary heap?",
        "options": [
          "O(V^2)",
          "O(E log V)",
          "O(V + E)",
          "O(E * V)"
        ],
        "correctAnswer": 1,
        "explanation": "With a binary heap, each of E edge relaxations takes O(log V), giving O(E log V)."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "Bellman-Ford can detect negative cycles in a graph.",
        "correctAnswer": true,
        "explanation": "After V-1 iterations, if any edge can still be relaxed, a negative cycle exists."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "What is the time complexity of Bellman-Ford?",
        "options": [
          "O(V + E)",
          "O(E log V)",
          "O(V * E)",
          "O(V^3)"
        ],
        "correctAnswer": 2,
        "explanation": "Bellman-Ford relaxes all E edges V-1 times, giving O(V * E)."
      },
      {
        "id": "q5",
        "type": "multiple_choice",
        "prompt": "For single-source shortest paths with non-negative weights, which algorithm is fastest?",
        "options": [
          "BFS",
          "Dijkstra",
          "Bellman-Ford",
          "Floyd-Warshall"
        ],
        "correctAnswer": 1,
        "explanation": "Dijkstra O(E log V) is faster than Bellman-Ford O(VE) for non-negative weights."
      }
    ]
  },
  {
    "id": "cs201-quiz-7-3",
    "subjectId": "cs201",
    "topicId": "cs201-7",
    "title": "Graph Applications",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "Topological sort is only possible for:",
        "options": [
          "Undirected graphs",
          "Directed Acyclic Graphs (DAGs)",
          "Complete graphs",
          "Weighted graphs"
        ],
        "correctAnswer": 1,
        "explanation": "Topological ordering requires no cycles (a node can't come before itself), so only DAGs qualify."
      },
      {
        "id": "q2",
        "type": "true_false",
        "prompt": "DFS can be used to detect cycles in a directed graph.",
        "correctAnswer": true,
        "explanation": "During DFS, if we encounter a node that's currently in the recursion stack, there's a cycle."
      },
      {
        "id": "q3",
        "type": "code_output",
        "prompt": "What does this code compute?",
        "codeSnippet": "def traverse(graph, start):\n    visited = set()\n    queue = deque([start])\n    visited.add(start)\n    dist = {start: 0}\n    while queue:\n        node = queue.popleft()\n        for neighbor in graph[node]:\n            if neighbor not in visited:\n                visited.add(neighbor)\n                dist[neighbor] = dist[node] + 1\n                queue.append(neighbor)\n    return dist",
        "options": [
          "DFS traversal order",
          "Shortest distances from start (unweighted)",
          "Topological sort",
          "Connected components"
        ],
        "correctAnswer": 1,
        "explanation": "This is BFS tracking distances. Each neighbor is one step further than the current node."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "What is a common application of topological sort?",
        "options": [
          "Finding shortest paths",
          "Build system dependencies",
          "Detecting cycles",
          "Finding connected components"
        ],
        "correctAnswer": 1,
        "explanation": "Topological sort orders tasks so dependencies come first - essential for build systems and scheduling."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "The Union-Find (Disjoint Set Union) data structure is commonly used in ______'s algorithm for MST.",
        "correctAnswer": "Kruskal",
        "explanation": "Kruskal's algorithm uses Union-Find to efficiently check if adding an edge creates a cycle."
      }
    ]
  },
  {
    "id": "cs201-quiz-8-1",
    "subjectId": "cs201",
    "topicId": "cs201-8",
    "title": "Proving Correctness",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "A loop invariant must be true at which points?",
        "options": [
          "Only at the start of the loop",
          "Only at the end of the loop",
          "At initialization, before each iteration, and at termination",
          "Only when the loop counter is even"
        ],
        "correctAnswer": 2,
        "explanation": "Loop invariants must hold at initialization, be maintained by each iteration, and imply correctness at termination."
      },
      {
        "id": "q2",
        "type": "true_false",
        "prompt": "\"It works for all my test cases\" is a valid proof of correctness.",
        "correctAnswer": false,
        "explanation": "Testing shows presence of bugs, not absence. A proof must hold for ALL possible inputs."
      },
      {
        "id": "q3",
        "type": "multiple_choice",
        "prompt": "To prove a recursive algorithm correct, which technique is most appropriate?",
        "options": [
          "Loop invariants",
          "Mathematical induction",
          "Empirical testing",
          "Big-O analysis"
        ],
        "correctAnswer": 1,
        "explanation": "Induction mirrors recursion: prove base case, assume works for smaller inputs, prove it works for current input."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "For Insertion Sort, a good loop invariant is:",
        "options": [
          "The array is fully sorted",
          "arr[0..i-1] contains the original elements in sorted order",
          "arr[i] is the minimum",
          "The loop runs n times"
        ],
        "correctAnswer": 1,
        "explanation": "At each iteration, the subarray arr[0..i-1] is sorted and contains the original elements from those positions."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "The three parts of a loop invariant proof are: Initialization, ______, and Termination.",
        "correctAnswer": "Maintenance",
        "explanation": "Maintenance shows that if the invariant holds before an iteration, it holds after the iteration too."
      }
    ]
  },
  {
    "id": "cs201-quiz-8-2",
    "subjectId": "cs201",
    "topicId": "cs201-8",
    "title": "Complexity Classes",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "What does P stand for in complexity theory?",
        "options": [
          "Polynomial time solvable problems",
          "Probabilistic problems",
          "Parallel problems",
          "Pseudo-polynomial problems"
        ],
        "correctAnswer": 0,
        "explanation": "P is the class of problems solvable in polynomial time O(n^k) for some constant k."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "What does NP stand for?",
        "options": [
          "Non-Polynomial",
          "Not Practical",
          "Nondeterministic Polynomial",
          "Nearly Polynomial"
        ],
        "correctAnswer": 2,
        "explanation": "NP means Nondeterministic Polynomial - problems whose solutions can be verified in polynomial time."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "Every problem in P is also in NP.",
        "correctAnswer": true,
        "explanation": "If you can solve a problem in polynomial time, you can certainly verify a solution in polynomial time. P ⊆ NP."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "If P = NP, what would it mean?",
        "options": [
          "Computers would be infinitely fast",
          "All NP problems would have polynomial-time solutions",
          "NP problems would become unsolvable",
          "Nothing would change"
        ],
        "correctAnswer": 1,
        "explanation": "P = NP would mean every problem with efficiently verifiable solutions also has efficient solutions."
      },
      {
        "id": "q5",
        "type": "fill_blank",
        "prompt": "NP-Complete problems are the ______ problems in NP.",
        "correctAnswer": "hardest",
        "explanation": "NP-Complete problems are at least as hard as any problem in NP. Solving one efficiently would solve all of NP."
      }
    ]
  },
  {
    "id": "cs201-quiz-8-3",
    "subjectId": "cs201",
    "topicId": "cs201-8",
    "title": "NP-Completeness",
    "questions": [
      {
        "id": "q1",
        "type": "multiple_choice",
        "prompt": "Which of these is an NP-Complete problem?",
        "options": [
          "Sorting",
          "Binary Search",
          "Traveling Salesman (decision)",
          "Finding GCD"
        ],
        "correctAnswer": 2,
        "explanation": "Traveling Salesman (decision version: is there a tour ≤ k?) is a classic NP-Complete problem."
      },
      {
        "id": "q2",
        "type": "multiple_choice",
        "prompt": "What is a reduction in complexity theory?",
        "options": [
          "Making an algorithm faster",
          "Transforming one problem into another",
          "Removing redundant code",
          "Simplifying mathematical expressions"
        ],
        "correctAnswer": 1,
        "explanation": "A reduction transforms problem A into problem B, showing that solving B would solve A."
      },
      {
        "id": "q3",
        "type": "true_false",
        "prompt": "If problem A reduces to problem B in polynomial time, and B is in P, then A is in P.",
        "correctAnswer": true,
        "explanation": "We can transform A to B in poly-time, solve B in poly-time, giving a poly-time solution for A."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "What should you do if you identify a problem as NP-Complete?",
        "options": [
          "Keep trying to find an O(n^2) solution",
          "Consider approximation algorithms or heuristics",
          "Prove P = NP first",
          "Give up on the problem entirely"
        ],
        "correctAnswer": 1,
        "explanation": "For NP-Complete problems, use approximations, heuristics, or special-case solutions instead of exact algorithms."
      },
      {
        "id": "q5",
        "type": "multiple_choice",
        "prompt": "SAT (Boolean Satisfiability) is significant because:",
        "options": [
          "It was the first problem proven NP-Complete",
          "It can be solved in linear time",
          "It has no applications",
          "It is not in NP"
        ],
        "correctAnswer": 0,
        "explanation": "SAT was proven NP-Complete by Cook in 1971, establishing the foundation of NP-Completeness theory."
      }
    ]
  }
]