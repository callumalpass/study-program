[
  {
    "id": "cs304-t1-ex01",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "Simple Tokenizer for Arithmetic",
    "difficulty": 1,
    "description": "Implement a basic tokenizer that recognizes numbers, operators (+, -, *, /), and parentheses in arithmetic expressions.",
    "starterCode": "def tokenize(input_str):\n    \"\"\"\n    Tokenize an arithmetic expression.\n    Return a list of tuples: [(token_type, value), ...]\n    Types: NUMBER, PLUS, MINUS, MULTIPLY, DIVIDE, LPAREN, RPAREN\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nprint(tokenize(\"12 + 34 * (5 - 6)\"))",
    "solution": "def tokenize(input_str):\n    \"\"\"\n    Tokenize an arithmetic expression.\n    Return a list of tuples: [(token_type, value), ...]\n    \"\"\"\n    tokens = []\n    i = 0\n\n    while i < len(input_str):\n        if input_str[i].isspace():\n            i += 1\n            continue\n\n        if input_str[i].isdigit():\n            num = ''\n            while i < len(input_str) and input_str[i].isdigit():\n                num += input_str[i]\n                i += 1\n            tokens.append(('NUMBER', int(num)))\n        elif input_str[i] == '+':\n            tokens.append(('PLUS', '+'))\n            i += 1\n        elif input_str[i] == '-':\n            tokens.append(('MINUS', '-'))\n            i += 1\n        elif input_str[i] == '*':\n            tokens.append(('MULTIPLY', '*'))\n            i += 1\n        elif input_str[i] == '/':\n            tokens.append(('DIVIDE', '/'))\n            i += 1\n        elif input_str[i] == '(':\n            tokens.append(('LPAREN', '('))\n            i += 1\n        elif input_str[i] == ')':\n            tokens.append(('RPAREN', ')'))\n            i += 1\n        else:\n            raise ValueError(f\"Unknown character: {input_str[i]}\")\n\n    return tokens\n\n# Test\nprint(tokenize(\"12 + 34 * (5 - 6)\"))",
    "testCases": [
      {
        "input": "42",
        "expectedOutput": "[('NUMBER', 42)]",
        "isHidden": false,
        "description": "Single number"
      },
      {
        "input": "1 + 2",
        "expectedOutput": "[('NUMBER', 1), ('PLUS', '+'), ('NUMBER', 2)]",
        "isHidden": false,
        "description": "Simple addition"
      },
      {
        "input": "(10 - 5) * 3",
        "expectedOutput": "[('LPAREN', '('), ('NUMBER', 10), ('MINUS', '-'), ('NUMBER', 5), ('RPAREN', ')'), ('MULTIPLY', '*'), ('NUMBER', 3)]",
        "isHidden": true,
        "description": "Complex expression"
      }
    ],
    "hints": [
      "Process the input character by character",
      "Use a while loop with an index variable",
      "Handle multi-digit numbers by accumulating digits"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex02",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "Identifier Recognition",
    "difficulty": 2,
    "description": "Extend the tokenizer to recognize identifiers (variable names) that start with a letter or underscore, followed by letters, digits, or underscores.",
    "starterCode": "def tokenize_with_identifiers(input_str):\n    \"\"\"\n    Tokenize input recognizing numbers, operators, and identifiers.\n    Return list of tuples: [(token_type, value), ...]\n    Types: NUMBER, IDENTIFIER, PLUS, MINUS, MULTIPLY, DIVIDE, ASSIGN\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nprint(tokenize_with_identifiers(\"x = 10 + y2\"))",
    "solution": "def tokenize_with_identifiers(input_str):\n    \"\"\"\n    Tokenize input recognizing numbers, operators, and identifiers.\n    \"\"\"\n    tokens = []\n    i = 0\n\n    while i < len(input_str):\n        if input_str[i].isspace():\n            i += 1\n            continue\n\n        if input_str[i].isdigit():\n            num = ''\n            while i < len(input_str) and input_str[i].isdigit():\n                num += input_str[i]\n                i += 1\n            tokens.append(('NUMBER', int(num)))\n        elif input_str[i].isalpha() or input_str[i] == '_':\n            identifier = ''\n            while i < len(input_str) and (input_str[i].isalnum() or input_str[i] == '_'):\n                identifier += input_str[i]\n                i += 1\n            tokens.append(('IDENTIFIER', identifier))\n        elif input_str[i] == '=':\n            tokens.append(('ASSIGN', '='))\n            i += 1\n        elif input_str[i] == '+':\n            tokens.append(('PLUS', '+'))\n            i += 1\n        elif input_str[i] == '-':\n            tokens.append(('MINUS', '-'))\n            i += 1\n        elif input_str[i] == '*':\n            tokens.append(('MULTIPLY', '*'))\n            i += 1\n        elif input_str[i] == '/':\n            tokens.append(('DIVIDE', '/'))\n            i += 1\n        else:\n            raise ValueError(f\"Unknown character: {input_str[i]}\")\n\n    return tokens\n\n# Test\nprint(tokenize_with_identifiers(\"x = 10 + y2\"))",
    "testCases": [
      {
        "input": "abc",
        "expectedOutput": "[('IDENTIFIER', 'abc')]",
        "isHidden": false,
        "description": "Simple identifier"
      },
      {
        "input": "_var123",
        "expectedOutput": "[('IDENTIFIER', '_var123')]",
        "isHidden": false,
        "description": "Identifier with underscore and digits"
      },
      {
        "input": "x = 10 + y2",
        "expectedOutput": "[('IDENTIFIER', 'x'), ('ASSIGN', '='), ('NUMBER', 10), ('PLUS', '+'), ('IDENTIFIER', 'y2')]",
        "isHidden": true,
        "description": "Assignment expression"
      }
    ],
    "hints": [
      "Check if character is a letter or underscore for identifier start",
      "Use isalpha() and isalnum() methods",
      "Identifiers can contain digits but cannot start with them"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex03",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "Keyword Recognition",
    "difficulty": 2,
    "description": "Implement keyword recognition by distinguishing reserved words (if, else, while, return) from regular identifiers.",
    "starterCode": "KEYWORDS = {'if', 'else', 'while', 'return', 'def', 'class'}\n\ndef tokenize_with_keywords(input_str):\n    \"\"\"\n    Tokenize input distinguishing keywords from identifiers.\n    Types: KEYWORD, IDENTIFIER, NUMBER, operators\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nprint(tokenize_with_keywords(\"if x == 10 return y\"))",
    "solution": "KEYWORDS = {'if', 'else', 'while', 'return', 'def', 'class'}\n\ndef tokenize_with_keywords(input_str):\n    \"\"\"\n    Tokenize input distinguishing keywords from identifiers.\n    \"\"\"\n    tokens = []\n    i = 0\n\n    while i < len(input_str):\n        if input_str[i].isspace():\n            i += 1\n            continue\n\n        if input_str[i].isdigit():\n            num = ''\n            while i < len(input_str) and input_str[i].isdigit():\n                num += input_str[i]\n                i += 1\n            tokens.append(('NUMBER', int(num)))\n        elif input_str[i].isalpha() or input_str[i] == '_':\n            word = ''\n            while i < len(input_str) and (input_str[i].isalnum() or input_str[i] == '_'):\n                word += input_str[i]\n                i += 1\n            if word in KEYWORDS:\n                tokens.append(('KEYWORD', word))\n            else:\n                tokens.append(('IDENTIFIER', word))\n        elif input_str[i:i+2] == '==':\n            tokens.append(('EQUALS', '=='))\n            i += 2\n        elif input_str[i] == '=':\n            tokens.append(('ASSIGN', '='))\n            i += 1\n        elif input_str[i] == '+':\n            tokens.append(('PLUS', '+'))\n            i += 1\n        elif input_str[i] == '-':\n            tokens.append(('MINUS', '-'))\n            i += 1\n        elif input_str[i] == '*':\n            tokens.append(('MULTIPLY', '*'))\n            i += 1\n        elif input_str[i] == '/':\n            tokens.append(('DIVIDE', '/'))\n            i += 1\n        else:\n            raise ValueError(f\"Unknown character: {input_str[i]}\")\n\n    return tokens\n\n# Test\nprint(tokenize_with_keywords(\"if x == 10 return y\"))",
    "testCases": [
      {
        "input": "if",
        "expectedOutput": "[('KEYWORD', 'if')]",
        "isHidden": false,
        "description": "Single keyword"
      },
      {
        "input": "myvar",
        "expectedOutput": "[('IDENTIFIER', 'myvar')]",
        "isHidden": false,
        "description": "Identifier that is not a keyword"
      },
      {
        "input": "if x == 10 return y",
        "expectedOutput": "[('KEYWORD', 'if'), ('IDENTIFIER', 'x'), ('EQUALS', '=='), ('NUMBER', 10), ('KEYWORD', 'return'), ('IDENTIFIER', 'y')]",
        "isHidden": true,
        "description": "Conditional return statement"
      }
    ],
    "hints": [
      "First tokenize as identifier, then check if it is in the KEYWORDS set",
      "Keywords are context-free in most languages",
      "Handle multi-character operators like == before single character ones"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex04",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "Regular Expression Matcher",
    "difficulty": 3,
    "description": "Implement a simple regular expression matcher that supports literals, * (zero or more), and . (any character).",
    "starterCode": "def regex_match(pattern, text):\n    \"\"\"\n    Return True if pattern matches text.\n    Supports: literals, . (any char), * (zero or more of previous)\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nprint(regex_match(\"a*b\", \"aaab\"))  # True\nprint(regex_match(\"a.c\", \"abc\"))   # True\nprint(regex_match(\".*\", \"hello\"))  # True",
    "solution": "def regex_match(pattern, text):\n    \"\"\"\n    Return True if pattern matches text.\n    Supports: literals, . (any char), * (zero or more of previous)\n    \"\"\"\n    if not pattern:\n        return not text\n\n    first_match = bool(text) and (pattern[0] == text[0] or pattern[0] == '.')\n\n    if len(pattern) >= 2 and pattern[1] == '*':\n        # Two possibilities: skip the * pattern, or use it\n        return (regex_match(pattern[2:], text) or\n                (first_match and regex_match(pattern, text[1:])))\n    else:\n        return first_match and regex_match(pattern[1:], text[1:])\n\n# Test\nprint(regex_match(\"a*b\", \"aaab\"))  # True\nprint(regex_match(\"a.c\", \"abc\"))   # True\nprint(regex_match(\".*\", \"hello\"))  # True",
    "testCases": [
      {
        "input": "abc|abc",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Exact match"
      },
      {
        "input": "a*b|aaab",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Star quantifier"
      },
      {
        "input": ".*|hello",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Match anything"
      },
      {
        "input": "a.c|abc",
        "expectedOutput": "True",
        "isHidden": true,
        "description": "Dot wildcard"
      },
      {
        "input": "a*b|b",
        "expectedOutput": "True",
        "isHidden": true,
        "description": "Star with zero matches"
      }
    ],
    "hints": [
      "Use recursion to handle the pattern matching",
      "Handle the * operator by trying both zero and one-or-more matches",
      "Check if the next character is * before consuming current character"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex05",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "NFA State Representation",
    "difficulty": 3,
    "description": "Implement a Non-deterministic Finite Automaton (NFA) data structure with epsilon transitions.",
    "starterCode": "class NFA:\n    def __init__(self, states, alphabet, transitions, start, accept):\n        \"\"\"\n        states: set of state names\n        alphabet: set of input symbols\n        transitions: dict {(state, symbol): set of next states}\n        start: start state\n        accept: set of accept states\n        Use None for epsilon transitions\n        \"\"\"\n        # Your code here\n        pass\n\n    def epsilon_closure(self, states):\n        \"\"\"Return set of states reachable via epsilon transitions\"\"\"\n        # Your code here\n        pass\n\n# Test\nnfa = NFA({'q0', 'q1', 'q2'}, {'a', 'b'},\n          {('q0', 'a'): {'q1'}, ('q1', None): {'q2'}},\n          'q0', {'q2'})\nprint(nfa.epsilon_closure({'q1'}))  # Should include q2",
    "solution": "class NFA:\n    def __init__(self, states, alphabet, transitions, start, accept):\n        \"\"\"\n        states: set of state names\n        alphabet: set of input symbols\n        transitions: dict {(state, symbol): set of next states}\n        start: start state\n        accept: set of accept states\n        Use None for epsilon transitions\n        \"\"\"\n        self.states = states\n        self.alphabet = alphabet\n        self.transitions = transitions\n        self.start = start\n        self.accept = accept\n\n    def epsilon_closure(self, states):\n        \"\"\"Return set of states reachable via epsilon transitions\"\"\"\n        closure = set(states)\n        stack = list(states)\n\n        while stack:\n            state = stack.pop()\n            epsilon_states = self.transitions.get((state, None), set())\n            for next_state in epsilon_states:\n                if next_state not in closure:\n                    closure.add(next_state)\n                    stack.append(next_state)\n\n        return closure\n\n# Test\nnfa = NFA({'q0', 'q1', 'q2'}, {'a', 'b'},\n          {('q0', 'a'): {'q1'}, ('q1', None): {'q2'}},\n          'q0', {'q2'})\nprint(nfa.epsilon_closure({'q1'}))  # Should include q2",
    "testCases": [
      {
        "input": "{'q1'}",
        "expectedOutput": "{'q1', 'q2'}",
        "isHidden": false,
        "description": "Epsilon closure from q1"
      },
      {
        "input": "{'q0'}",
        "expectedOutput": "{'q0'}",
        "isHidden": false,
        "description": "No epsilon transitions from q0"
      },
      {
        "input": "{'q1', 'q0'}",
        "expectedOutput": "{'q0', 'q1', 'q2'}",
        "isHidden": true,
        "description": "Closure from multiple states"
      }
    ],
    "hints": [
      "Use a stack or queue to traverse epsilon transitions",
      "Keep track of visited states to avoid infinite loops",
      "Initialize closure with the input states"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex06",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "NFA Simulation",
    "difficulty": 3,
    "description": "Implement the accepts method for an NFA that determines if a string is accepted.",
    "starterCode": "class NFA:\n    def __init__(self, states, alphabet, transitions, start, accept):\n        self.states = states\n        self.alphabet = alphabet\n        self.transitions = transitions\n        self.start = start\n        self.accept = accept\n\n    def epsilon_closure(self, states):\n        closure = set(states)\n        stack = list(states)\n        while stack:\n            state = stack.pop()\n            epsilon_states = self.transitions.get((state, None), set())\n            for next_state in epsilon_states:\n                if next_state not in closure:\n                    closure.add(next_state)\n                    stack.append(next_state)\n        return closure\n\n    def accepts(self, input_string):\n        \"\"\"Return True if NFA accepts the input string\"\"\"\n        # Your code here\n        pass\n\n# Test\nnfa = NFA({'q0', 'q1'}, {'a', 'b'},\n          {('q0', 'a'): {'q0', 'q1'}, ('q0', 'b'): {'q0'}},\n          'q0', {'q1'})\nprint(nfa.accepts(\"bba\"))  # True",
    "solution": "class NFA:\n    def __init__(self, states, alphabet, transitions, start, accept):\n        self.states = states\n        self.alphabet = alphabet\n        self.transitions = transitions\n        self.start = start\n        self.accept = accept\n\n    def epsilon_closure(self, states):\n        closure = set(states)\n        stack = list(states)\n        while stack:\n            state = stack.pop()\n            epsilon_states = self.transitions.get((state, None), set())\n            for next_state in epsilon_states:\n                if next_state not in closure:\n                    closure.add(next_state)\n                    stack.append(next_state)\n        return closure\n\n    def accepts(self, input_string):\n        \"\"\"Return True if NFA accepts the input string\"\"\"\n        current_states = self.epsilon_closure({self.start})\n\n        for symbol in input_string:\n            next_states = set()\n            for state in current_states:\n                next_states.update(self.transitions.get((state, symbol), set()))\n            current_states = self.epsilon_closure(next_states)\n\n        return bool(current_states & self.accept)\n\n# Test\nnfa = NFA({'q0', 'q1'}, {'a', 'b'},\n          {('q0', 'a'): {'q0', 'q1'}, ('q0', 'b'): {'q0'}},\n          'q0', {'q1'})\nprint(nfa.accepts(\"bba\"))  # True",
    "testCases": [
      {
        "input": "bba",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "String ending with a"
      },
      {
        "input": "bbb",
        "expectedOutput": "False",
        "isHidden": false,
        "description": "String not ending with a"
      },
      {
        "input": "a",
        "expectedOutput": "True",
        "isHidden": true,
        "description": "Single character accepted"
      }
    ],
    "hints": [
      "Start with epsilon closure of the start state",
      "For each input symbol, compute all possible next states",
      "Check if any final state is in the accept states"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex07",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "DFA Implementation",
    "difficulty": 2,
    "description": "Implement a Deterministic Finite Automaton (DFA) with a single transition function.",
    "starterCode": "class DFA:\n    def __init__(self, states, alphabet, transitions, start, accept):\n        \"\"\"\n        transitions: dict {(state, symbol): next_state}\n        Each (state, symbol) maps to exactly one state\n        \"\"\"\n        # Your code here\n        pass\n\n    def accepts(self, input_string):\n        \"\"\"Return True if DFA accepts the input string\"\"\"\n        # Your code here\n        pass\n\n# Test\ndfa = DFA({'q0', 'q1', 'q2'}, {'0', '1'},\n          {('q0', '0'): 'q0', ('q0', '1'): 'q1',\n           ('q1', '0'): 'q0', ('q1', '1'): 'q2',\n           ('q2', '0'): 'q2', ('q2', '1'): 'q2'},\n          'q0', {'q2'})\nprint(dfa.accepts(\"011\"))  # True",
    "solution": "class DFA:\n    def __init__(self, states, alphabet, transitions, start, accept):\n        \"\"\"\n        transitions: dict {(state, symbol): next_state}\n        Each (state, symbol) maps to exactly one state\n        \"\"\"\n        self.states = states\n        self.alphabet = alphabet\n        self.transitions = transitions\n        self.start = start\n        self.accept = accept\n\n    def accepts(self, input_string):\n        \"\"\"Return True if DFA accepts the input string\"\"\"\n        current_state = self.start\n\n        for symbol in input_string:\n            if (current_state, symbol) not in self.transitions:\n                return False\n            current_state = self.transitions[(current_state, symbol)]\n\n        return current_state in self.accept\n\n# Test\ndfa = DFA({'q0', 'q1', 'q2'}, {'0', '1'},\n          {('q0', '0'): 'q0', ('q0', '1'): 'q1',\n           ('q1', '0'): 'q0', ('q1', '1'): 'q2',\n           ('q2', '0'): 'q2', ('q2', '1'): 'q2'},\n          'q0', {'q2'})\nprint(dfa.accepts(\"011\"))  # True",
    "testCases": [
      {
        "input": "011",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Contains substring 11"
      },
      {
        "input": "010",
        "expectedOutput": "False",
        "isHidden": false,
        "description": "Does not contain 11"
      },
      {
        "input": "1111",
        "expectedOutput": "True",
        "isHidden": true,
        "description": "Multiple 11 substrings"
      }
    ],
    "hints": [
      "DFA has exactly one transition for each (state, symbol) pair",
      "Track a single current state as you process input",
      "Much simpler than NFA - no epsilon closures or multiple states"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex08",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "String Literal Tokenization",
    "difficulty": 3,
    "description": "Implement tokenization of string literals with escape sequences (\\n, \\t, \\\\, \\\").",
    "starterCode": "def tokenize_string(input_str):\n    \"\"\"\n    Tokenize a string literal handling escape sequences.\n    Return the actual string value (with escapes processed).\n    Input includes the surrounding quotes.\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nprint(tokenize_string('\"hello\\nworld\"'))  # \"hello\nworld\"\nprint(tokenize_string('\"say \\\"hi\\\"\"'))   # \"say \"hi\"\"",
    "solution": "def tokenize_string(input_str):\n    \"\"\"\n    Tokenize a string literal handling escape sequences.\n    Return the actual string value (with escapes processed).\n    Input includes the surrounding quotes.\n    \"\"\"\n    if not input_str.startswith('\"') or not input_str.endswith('\"'):\n        raise ValueError(\"String must be enclosed in quotes\")\n\n    content = input_str[1:-1]  # Remove quotes\n    result = []\n    i = 0\n\n    while i < len(content):\n        if content[i] == '\\' and i + 1 < len(content):\n            next_char = content[i + 1]\n            if next_char == 'n':\n                result.append('\n')\n            elif next_char == 't':\n                result.append('\t')\n            elif next_char == '\\':\n                result.append('\\')\n            elif next_char == '\"':\n                result.append('\"')\n            else:\n                raise ValueError(f\"Unknown escape sequence: \\{next_char}\")\n            i += 2\n        else:\n            result.append(content[i])\n            i += 1\n\n    return ''.join(result)\n\n# Test\nprint(repr(tokenize_string('\"hello\\nworld\"')))  # \"hello\nworld\"\nprint(repr(tokenize_string('\"say \\\"hi\\\"\"')))   # \"say \"hi\"\"",
    "testCases": [
      {
        "input": "\"hello\"",
        "expectedOutput": "'hello'",
        "isHidden": false,
        "description": "Simple string"
      },
      {
        "input": "\"hello\\nworld\"",
        "expectedOutput": "'hello\\nworld'",
        "isHidden": false,
        "description": "String with newline escape"
      },
      {
        "input": "\"tab\\there\"",
        "expectedOutput": "'tab\\there'",
        "isHidden": true,
        "description": "String with tab escape"
      },
      {
        "input": "\"quote\\\"mark\"",
        "expectedOutput": "'quote\"mark'",
        "isHidden": true,
        "description": "String with escaped quote"
      }
    ],
    "hints": [
      "Process characters one at a time",
      "When you encounter backslash, check the next character",
      "Map escape sequences to their actual character values"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex09",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "Comment Handling",
    "difficulty": 2,
    "description": "Extend tokenizer to skip single-line (//) and multi-line (/* */) comments.",
    "starterCode": "def tokenize_with_comments(input_str):\n    \"\"\"\n    Tokenize input while skipping comments.\n    // starts single-line comment (to end of line)\n    /* */ delimits multi-line comment\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ncode = '''x = 5 // assign value\ny = /* mid comment */ 10'''\nprint(tokenize_with_comments(code))",
    "solution": "def tokenize_with_comments(input_str):\n    \"\"\"\n    Tokenize input while skipping comments.\n    // starts single-line comment (to end of line)\n    /* */ delimits multi-line comment\n    \"\"\"\n    tokens = []\n    i = 0\n\n    while i < len(input_str):\n        # Skip whitespace\n        if input_str[i].isspace():\n            i += 1\n            continue\n\n        # Check for comments\n        if i + 1 < len(input_str) and input_str[i:i+2] == '//':\n            # Skip to end of line\n            while i < len(input_str) and input_str[i] != '\n':\n                i += 1\n            continue\n\n        if i + 1 < len(input_str) and input_str[i:i+2] == '/*':\n            # Skip to */\n            i += 2\n            while i + 1 < len(input_str) and input_str[i:i+2] != '*/':\n                i += 1\n            i += 2  # Skip */\n            continue\n\n        # Regular tokenization\n        if input_str[i].isdigit():\n            num = ''\n            while i < len(input_str) and input_str[i].isdigit():\n                num += input_str[i]\n                i += 1\n            tokens.append(('NUMBER', int(num)))\n        elif input_str[i].isalpha() or input_str[i] == '_':\n            identifier = ''\n            while i < len(input_str) and (input_str[i].isalnum() or input_str[i] == '_'):\n                identifier += input_str[i]\n                i += 1\n            tokens.append(('IDENTIFIER', identifier))\n        elif input_str[i] == '=':\n            tokens.append(('ASSIGN', '='))\n            i += 1\n        else:\n            i += 1\n\n    return tokens\n\n# Test\ncode = '''x = 5 // assign value\ny = /* mid comment */ 10'''\nprint(tokenize_with_comments(code))",
    "testCases": [
      {
        "input": "x = 5 // comment",
        "expectedOutput": "[('IDENTIFIER', 'x'), ('ASSIGN', '='), ('NUMBER', 5)]",
        "isHidden": false,
        "description": "Single-line comment"
      },
      {
        "input": "a = /* skip */ 1",
        "expectedOutput": "[('IDENTIFIER', 'a'), ('ASSIGN', '='), ('NUMBER', 1)]",
        "isHidden": false,
        "description": "Multi-line comment inline"
      },
      {
        "input": "x = 5\ny = 10",
        "expectedOutput": "[('IDENTIFIER', 'x'), ('ASSIGN', '='), ('NUMBER', 5), ('IDENTIFIER', 'y'), ('ASSIGN', '='), ('NUMBER', 10)]",
        "isHidden": true,
        "description": "Multiple lines no comments"
      }
    ],
    "hints": [
      "Check for comment start sequences before regular tokenization",
      "For //, skip until newline",
      "For /* */, skip until you find */",
      "Use continue to restart the loop after skipping comments"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex10",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "Floating Point Numbers",
    "difficulty": 3,
    "description": "Implement tokenization of floating point numbers in scientific notation (e.g., 3.14, 2.5e-3, 1E+10).",
    "starterCode": "def tokenize_float(input_str):\n    \"\"\"\n    Tokenize floating point numbers including scientific notation.\n    Examples: 3.14, 2.5e-3, 1E+10, .5, 5.\n    Return ('FLOAT', float_value)\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nprint(tokenize_float(\"3.14\"))      # ('FLOAT', 3.14)\nprint(tokenize_float(\"2.5e-3\"))    # ('FLOAT', 0.0025)\nprint(tokenize_float(\"1E+10\"))     # ('FLOAT', 1e10)",
    "solution": "def tokenize_float(input_str):\n    \"\"\"\n    Tokenize floating point numbers including scientific notation.\n    Examples: 3.14, 2.5e-3, 1E+10, .5, 5.\n    Return ('FLOAT', float_value)\n    \"\"\"\n    import re\n\n    # Pattern: optional digits, optional decimal point with digits, optional exponent\n    pattern = r'^([0-9]*.?[0-9]+)([eE][+-]?[0-9]+)?$'\n    match = re.match(pattern, input_str.strip())\n\n    if match:\n        return ('FLOAT', float(input_str))\n    else:\n        raise ValueError(f\"Invalid float: {input_str}\")\n\n# Alternative without regex:\ndef tokenize_float_manual(input_str):\n    s = input_str.strip()\n    i = 0\n\n    # Integer part\n    int_part = ''\n    while i < len(s) and s[i].isdigit():\n        int_part += s[i]\n        i += 1\n\n    # Decimal part\n    dec_part = ''\n    if i < len(s) and s[i] == '.':\n        dec_part = '.'\n        i += 1\n        while i < len(s) and s[i].isdigit():\n            dec_part += s[i]\n            i += 1\n\n    # Must have either integer or decimal digits\n    if not int_part and dec_part == '.':\n        raise ValueError(\"Invalid float\")\n\n    # Exponent part\n    exp_part = ''\n    if i < len(s) and s[i] in 'eE':\n        exp_part = s[i]\n        i += 1\n        if i < len(s) and s[i] in '+-':\n            exp_part += s[i]\n            i += 1\n        while i < len(s) and s[i].isdigit():\n            exp_part += s[i]\n            i += 1\n\n    if i != len(s):\n        raise ValueError(\"Invalid float\")\n\n    return ('FLOAT', float(int_part + dec_part + exp_part))\n\n# Test\nprint(tokenize_float(\"3.14\"))      # ('FLOAT', 3.14)\nprint(tokenize_float(\"2.5e-3\"))    # ('FLOAT', 0.0025)\nprint(tokenize_float(\"1E+10\"))     # ('FLOAT', 1e10)",
    "testCases": [
      {
        "input": "3.14",
        "expectedOutput": "('FLOAT', 3.14)",
        "isHidden": false,
        "description": "Simple decimal"
      },
      {
        "input": "2.5e-3",
        "expectedOutput": "('FLOAT', 0.0025)",
        "isHidden": false,
        "description": "Scientific notation with negative exponent"
      },
      {
        "input": "1E+10",
        "expectedOutput": "('FLOAT', 10000000000.0)",
        "isHidden": true,
        "description": "Scientific notation with positive exponent"
      },
      {
        "input": ".5",
        "expectedOutput": "('FLOAT', 0.5)",
        "isHidden": true,
        "description": "Leading decimal point"
      }
    ],
    "hints": [
      "You can use Python's float() function to parse the final value",
      "Handle optional parts: integer, decimal, exponent",
      "Exponent can have optional + or - sign",
      "Consider using regex or manual character scanning"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex11",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "NFA to DFA Conversion - Simple Case",
    "difficulty": 4,
    "description": "Implement the subset construction algorithm to convert a simple NFA to a DFA.",
    "starterCode": "def nfa_to_dfa(nfa):\n    \"\"\"\n    Convert NFA to DFA using subset construction.\n    nfa: dict with 'states', 'alphabet', 'transitions', 'start', 'accept'\n    Return equivalent DFA structure.\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nnfa = {\n    'states': {'q0', 'q1', 'q2'},\n    'alphabet': {'a', 'b'},\n    'transitions': {\n        ('q0', 'a'): {'q0', 'q1'},\n        ('q0', 'b'): {'q0'},\n        ('q1', 'b'): {'q2'}\n    },\n    'start': 'q0',\n    'accept': {'q2'}\n}\ndfa = nfa_to_dfa(nfa)\nprint(len(dfa['states']))  # Number of DFA states",
    "solution": "def nfa_to_dfa(nfa):\n    \"\"\"\n    Convert NFA to DFA using subset construction.\n    \"\"\"\n    def get_transitions(states, symbol):\n        \"\"\"Get all states reachable from states via symbol\"\"\"\n        result = set()\n        for state in states:\n            result.update(nfa['transitions'].get((state, symbol), set()))\n        return result\n\n    # Start with the start state as a set\n    start_set = frozenset({nfa['start']})\n    dfa_states = {start_set}\n    dfa_transitions = {}\n    unmarked = [start_set]\n\n    while unmarked:\n        current = unmarked.pop()\n\n        for symbol in nfa['alphabet']:\n            next_states = get_transitions(current, symbol)\n            next_set = frozenset(next_states)\n\n            if next_set:  # Only add non-empty sets\n                dfa_transitions[(current, symbol)] = next_set\n\n                if next_set not in dfa_states:\n                    dfa_states.add(next_set)\n                    unmarked.append(next_set)\n\n    # Accept states are those containing an NFA accept state\n    dfa_accept = {s for s in dfa_states\n                  if any(state in nfa['accept'] for state in s)}\n\n    return {\n        'states': dfa_states,\n        'alphabet': nfa['alphabet'],\n        'transitions': dfa_transitions,\n        'start': start_set,\n        'accept': dfa_accept\n    }\n\n# Test\nnfa = {\n    'states': {'q0', 'q1', 'q2'},\n    'alphabet': {'a', 'b'},\n    'transitions': {\n        ('q0', 'a'): {'q0', 'q1'},\n        ('q0', 'b'): {'q0'},\n        ('q1', 'b'): {'q2'}\n    },\n    'start': 'q0',\n    'accept': {'q2'}\n}\ndfa = nfa_to_dfa(nfa)\nprint(len(dfa['states']))  # Number of DFA states",
    "testCases": [
      {
        "input": "nfa1",
        "expectedOutput": "4",
        "isHidden": false,
        "description": "NFA with multiple transitions results in DFA"
      },
      {
        "input": "nfa2",
        "expectedOutput": "3",
        "isHidden": true,
        "description": "Different NFA structure"
      }
    ],
    "hints": [
      "Use frozenset to represent DFA states (sets of NFA states)",
      "Start with the NFA start state as a single-element set",
      "Process each unmarked DFA state by computing transitions",
      "A DFA state is accepting if it contains any NFA accept state"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex12",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "Maximal Munch Tokenization",
    "difficulty": 3,
    "description": "Implement maximal munch (longest match) tokenization for recognizing multi-character operators.",
    "starterCode": "def tokenize_maximal_munch(input_str):\n    \"\"\"\n    Tokenize using maximal munch for operators.\n    Operators: ==, !=, <=, >=, <, >, =, +, -, *, /\n    Always prefer longer match (e.g., == over =)\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nprint(tokenize_maximal_munch(\"x == 5\"))\nprint(tokenize_maximal_munch(\"y != 10\"))",
    "solution": "def tokenize_maximal_munch(input_str):\n    \"\"\"\n    Tokenize using maximal munch for operators.\n    Operators: ==, !=, <=, >=, <, >, =, +, -, *, /\n    Always prefer longer match (e.g., == over =)\n    \"\"\"\n    # Two-character operators must be checked first\n    two_char_ops = {'==': 'EQ', '!=': 'NE', '<=': 'LE', '>=': 'GE'}\n    one_char_ops = {'<': 'LT', '>': 'GT', '=': 'ASSIGN',\n                    '+': 'PLUS', '-': 'MINUS', '*': 'MUL', '/': 'DIV'}\n\n    tokens = []\n    i = 0\n\n    while i < len(input_str):\n        if input_str[i].isspace():\n            i += 1\n            continue\n\n        # Try two-character operators first (maximal munch)\n        if i + 1 < len(input_str) and input_str[i:i+2] in two_char_ops:\n            tokens.append((two_char_ops[input_str[i:i+2]], input_str[i:i+2]))\n            i += 2\n        # Then try one-character operators\n        elif input_str[i] in one_char_ops:\n            tokens.append((one_char_ops[input_str[i]], input_str[i]))\n            i += 1\n        # Numbers\n        elif input_str[i].isdigit():\n            num = ''\n            while i < len(input_str) and input_str[i].isdigit():\n                num += input_str[i]\n                i += 1\n            tokens.append(('NUMBER', int(num)))\n        # Identifiers\n        elif input_str[i].isalpha() or input_str[i] == '_':\n            ident = ''\n            while i < len(input_str) and (input_str[i].isalnum() or input_str[i] == '_'):\n                ident += input_str[i]\n                i += 1\n            tokens.append(('IDENTIFIER', ident))\n        else:\n            raise ValueError(f\"Unknown character: {input_str[i]}\")\n\n    return tokens\n\n# Test\nprint(tokenize_maximal_munch(\"x == 5\"))\nprint(tokenize_maximal_munch(\"y != 10\"))",
    "testCases": [
      {
        "input": "x == 5",
        "expectedOutput": "[('IDENTIFIER', 'x'), ('EQ', '=='), ('NUMBER', 5)]",
        "isHidden": false,
        "description": "Equality operator"
      },
      {
        "input": "y != 10",
        "expectedOutput": "[('IDENTIFIER', 'y'), ('NE', '!='), ('NUMBER', 10)]",
        "isHidden": false,
        "description": "Not equal operator"
      },
      {
        "input": "a = b",
        "expectedOutput": "[('IDENTIFIER', 'a'), ('ASSIGN', '='), ('IDENTIFIER', 'b')]",
        "isHidden": true,
        "description": "Single character assignment"
      },
      {
        "input": "x <= y",
        "expectedOutput": "[('IDENTIFIER', 'x'), ('LE', '<='), ('IDENTIFIER', 'y')]",
        "isHidden": true,
        "description": "Less than or equal"
      }
    ],
    "hints": [
      "Check for longer operators before shorter ones",
      "Use a dictionary for quick operator lookup",
      "Always consume the maximum number of characters possible"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex13",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "DFA Minimization - Partition Refinement",
    "difficulty": 5,
    "description": "Implement DFA minimization using the partition refinement algorithm to merge equivalent states.",
    "starterCode": "def minimize_dfa(dfa):\n    \"\"\"\n    Minimize a DFA by merging equivalent states.\n    dfa: dict with 'states', 'alphabet', 'transitions', 'start', 'accept'\n    Return minimized DFA with fewest states.\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ndfa = {\n    'states': {'q0', 'q1', 'q2', 'q3'},\n    'alphabet': {'a', 'b'},\n    'transitions': {\n        ('q0', 'a'): 'q1', ('q0', 'b'): 'q2',\n        ('q1', 'a'): 'q1', ('q1', 'b'): 'q3',\n        ('q2', 'a'): 'q1', ('q2', 'b'): 'q2',\n        ('q3', 'a'): 'q1', ('q3', 'b'): 'q3'\n    },\n    'start': 'q0',\n    'accept': {'q3'}\n}\nmin_dfa = minimize_dfa(dfa)\nprint(len(min_dfa['states']))",
    "solution": "def minimize_dfa(dfa):\n    \"\"\"\n    Minimize a DFA by merging equivalent states.\n    Uses partition refinement algorithm.\n    \"\"\"\n    states = dfa['states']\n    alphabet = dfa['alphabet']\n    transitions = dfa['transitions']\n    accept = dfa['accept']\n\n    # Initial partition: accepting vs non-accepting states\n    partitions = [accept, states - accept]\n    partitions = [p for p in partitions if p]  # Remove empty sets\n\n    changed = True\n    while changed:\n        changed = False\n        new_partitions = []\n\n        for partition in partitions:\n            # Try to split this partition\n            splits = {}\n\n            for state in partition:\n                # Create signature: which partition each symbol leads to\n                signature = tuple(\n                    next((i for i, p in enumerate(partitions)\n                          if transitions.get((state, symbol)) in p), None)\n                    for symbol in sorted(alphabet)\n                )\n\n                if signature not in splits:\n                    splits[signature] = set()\n                splits[signature].add(state)\n\n            if len(splits) > 1:\n                changed = True\n\n            new_partitions.extend(splits.values())\n\n        partitions = new_partitions\n\n    # Build minimized DFA\n    # Map each state to its partition\n    state_to_partition = {}\n    for i, partition in enumerate(partitions):\n        for state in partition:\n            state_to_partition[state] = i\n\n    # Create new transitions\n    new_transitions = {}\n    for (state, symbol), target in transitions.items():\n        new_state = state_to_partition[state]\n        new_target = state_to_partition[target]\n        new_transitions[(new_state, symbol)] = new_target\n\n    new_start = state_to_partition[dfa['start']]\n    new_accept = {state_to_partition[s] for s in accept}\n\n    return {\n        'states': set(range(len(partitions))),\n        'alphabet': alphabet,\n        'transitions': new_transitions,\n        'start': new_start,\n        'accept': new_accept\n    }\n\n# Test\ndfa = {\n    'states': {'q0', 'q1', 'q2', 'q3'},\n    'alphabet': {'a', 'b'},\n    'transitions': {\n        ('q0', 'a'): 'q1', ('q0', 'b'): 'q2',\n        ('q1', 'a'): 'q1', ('q1', 'b'): 'q3',\n        ('q2', 'a'): 'q1', ('q2', 'b'): 'q2',\n        ('q3', 'a'): 'q1', ('q3', 'b'): 'q3'\n    },\n    'start': 'q0',\n    'accept': {'q3'}\n}\nmin_dfa = minimize_dfa(dfa)\nprint(len(min_dfa['states']))",
    "testCases": [
      {
        "input": "dfa1",
        "expectedOutput": "3",
        "isHidden": false,
        "description": "DFA with redundant states"
      },
      {
        "input": "dfa2",
        "expectedOutput": "2",
        "isHidden": true,
        "description": "DFA that minimizes to 2 states"
      }
    ],
    "hints": [
      "Start with two partitions: accepting and non-accepting states",
      "Repeatedly refine partitions based on transition behavior",
      "Two states are equivalent if they transition to the same partitions",
      "Stop when no partition can be split further"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex14",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "Lexical Error Recovery",
    "difficulty": 4,
    "description": "Implement error recovery in a tokenizer that skips invalid characters and reports errors with line/column info.",
    "starterCode": "def tokenize_with_errors(input_str):\n    \"\"\"\n    Tokenize input and report errors without stopping.\n    Return (tokens, errors) where errors is list of:\n    {'line': line_num, 'col': col_num, 'char': bad_char}\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ncode = '''x = 5\ny @ 10\nz = 15'''\ntokens, errors = tokenize_with_errors(code)\nprint(f\"Tokens: {tokens}\")\nprint(f\"Errors: {errors}\")",
    "solution": "def tokenize_with_errors(input_str):\n    \"\"\"\n    Tokenize input and report errors without stopping.\n    Return (tokens, errors) where errors is list of:\n    {'line': line_num, 'col': col_num, 'char': bad_char}\n    \"\"\"\n    tokens = []\n    errors = []\n    i = 0\n    line = 1\n    col = 1\n\n    while i < len(input_str):\n        start_col = col\n\n        if input_str[i] == '\n':\n            line += 1\n            col = 1\n            i += 1\n            continue\n\n        if input_str[i].isspace():\n            col += 1\n            i += 1\n            continue\n\n        # Numbers\n        if input_str[i].isdigit():\n            num = ''\n            while i < len(input_str) and input_str[i].isdigit():\n                num += input_str[i]\n                i += 1\n                col += 1\n            tokens.append(('NUMBER', int(num)))\n        # Identifiers\n        elif input_str[i].isalpha() or input_str[i] == '_':\n            ident = ''\n            while i < len(input_str) and (input_str[i].isalnum() or input_str[i] == '_'):\n                ident += input_str[i]\n                i += 1\n                col += 1\n            tokens.append(('IDENTIFIER', ident))\n        # Valid operators\n        elif input_str[i] in '=+-*/':\n            tokens.append(('OPERATOR', input_str[i]))\n            i += 1\n            col += 1\n        # Invalid character - report error and skip\n        else:\n            errors.append({\n                'line': line,\n                'col': start_col,\n                'char': input_str[i]\n            })\n            i += 1\n            col += 1\n\n    return tokens, errors\n\n# Test\ncode = '''x = 5\ny @ 10\nz = 15'''\ntokens, errors = tokenize_with_errors(code)\nprint(f\"Tokens: {tokens}\")\nprint(f\"Errors: {errors}\")",
    "testCases": [
      {
        "input": "x = 5",
        "expectedOutput": "(tokens, [])",
        "isHidden": false,
        "description": "No errors"
      },
      {
        "input": "y @ 10",
        "expectedOutput": "(tokens, [{'line': 1, 'col': 3, 'char': '@'}])",
        "isHidden": false,
        "description": "Invalid operator"
      },
      {
        "input": "a #\nb",
        "expectedOutput": "(tokens, [{'line': 1, 'col': 3, 'char': '#'}])",
        "isHidden": true,
        "description": "Error on first line"
      }
    ],
    "hints": [
      "Track line and column numbers as you scan",
      "When encountering an invalid character, record the error and continue",
      "Increment line counter on newline, reset column to 1",
      "Don't stop tokenization on errors - collect them all"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex15",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "Context-Sensitive Tokenization",
    "difficulty": 4,
    "description": "Implement tokenization where < can mean either less-than or the start of a template (like C++ templates), depending on context.",
    "starterCode": "def tokenize_context_sensitive(input_str, in_template=False):\n    \"\"\"\n    Tokenize with context-sensitive handling of < and >.\n    When in_template=True, < and > are TEMPLATE_OPEN/CLOSE.\n    Otherwise, they are LT/GT operators.\n    Handle 'template' keyword to enter template context.\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nprint(tokenize_context_sensitive(\"a < b\"))\nprint(tokenize_context_sensitive(\"template<int>\"))",
    "solution": "def tokenize_context_sensitive(input_str, in_template=False):\n    \"\"\"\n    Tokenize with context-sensitive handling of < and >.\n    When in_template=True, < and > are TEMPLATE_OPEN/CLOSE.\n    Otherwise, they are LT/GT operators.\n    \"\"\"\n    tokens = []\n    i = 0\n    template_depth = 0\n\n    while i < len(input_str):\n        if input_str[i].isspace():\n            i += 1\n            continue\n\n        # Identifiers and keywords\n        if input_str[i].isalpha() or input_str[i] == '_':\n            word = ''\n            while i < len(input_str) and (input_str[i].isalnum() or input_str[i] == '_'):\n                word += input_str[i]\n                i += 1\n\n            if word == 'template':\n                tokens.append(('KEYWORD', 'template'))\n                # Next < will be template open\n                # We'll handle this in < processing\n            else:\n                tokens.append(('IDENTIFIER', word))\n\n        # Numbers\n        elif input_str[i].isdigit():\n            num = ''\n            while i < len(input_str) and input_str[i].isdigit():\n                num += input_str[i]\n                i += 1\n            tokens.append(('NUMBER', int(num)))\n\n        # Context-sensitive < and >\n        elif input_str[i] == '<':\n            # Check if previous token was 'template' keyword or we're in template\n            if (tokens and tokens[-1] == ('KEYWORD', 'template')) or template_depth > 0:\n                tokens.append(('TEMPLATE_OPEN', '<'))\n                template_depth += 1\n            else:\n                tokens.append(('LT', '<'))\n            i += 1\n\n        elif input_str[i] == '>':\n            if template_depth > 0:\n                tokens.append(('TEMPLATE_CLOSE', '>'))\n                template_depth -= 1\n            else:\n                tokens.append(('GT', '>'))\n            i += 1\n\n        else:\n            i += 1\n\n    return tokens\n\n# Test\nprint(tokenize_context_sensitive(\"a < b\"))\nprint(tokenize_context_sensitive(\"template<int>\"))",
    "testCases": [
      {
        "input": "a < b",
        "expectedOutput": "[('IDENTIFIER', 'a'), ('LT', '<'), ('IDENTIFIER', 'b')]",
        "isHidden": false,
        "description": "Less-than operator"
      },
      {
        "input": "template<int>",
        "expectedOutput": "[('KEYWORD', 'template'), ('TEMPLATE_OPEN', '<'), ('IDENTIFIER', 'int'), ('TEMPLATE_CLOSE', '>')]",
        "isHidden": false,
        "description": "Template syntax"
      },
      {
        "input": "template<pair<int>>",
        "expectedOutput": "nested templates",
        "isHidden": true,
        "description": "Nested template parameters"
      }
    ],
    "hints": [
      "Keep track of whether you're inside template brackets",
      "Use a depth counter for nested templates",
      "Check previous token to see if it was the template keyword",
      "This is why C++ is hard to parse!"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t1-ex16",
    "subjectId": "cs304",
    "topicId": "cs304-topic-1",
    "title": "Complete Lexer with Position Tracking",
    "difficulty": 5,
    "description": "Build a complete lexer that tracks file position, handles all previous token types, and returns a token stream with metadata.",
    "starterCode": "class Token:\n    def __init__(self, type, value, line, col, length):\n        self.type = type\n        self.value = value\n        self.line = line\n        self.col = col\n        self.length = length\n\n    def __repr__(self):\n        return f\"Token({self.type}, {self.value!r}, {self.line}:{self.col})\"\n\nclass Lexer:\n    def __init__(self, input_str):\n        self.input = input_str\n        self.pos = 0\n        self.line = 1\n        self.col = 1\n\n    def tokenize(self):\n        \"\"\"Return list of Token objects\"\"\"\n        # Your code here\n        pass\n\n# Test\nlexer = Lexer('x = 42 // comment\\ny = \"hello\"')\ntokens = lexer.tokenize()\nfor tok in tokens:\n    print(tok)",
    "solution": "class Token:\n    def __init__(self, type, value, line, col, length):\n        self.type = type\n        self.value = value\n        self.line = line\n        self.col = col\n        self.length = length\n\n    def __repr__(self):\n        return f\"Token({self.type}, {self.value!r}, {self.line}:{self.col})\"\n\nclass Lexer:\n    def __init__(self, input_str):\n        self.input = input_str\n        self.pos = 0\n        self.line = 1\n        self.col = 1\n\n    def peek(self, offset=0):\n        pos = self.pos + offset\n        return self.input[pos] if pos < len(self.input) else None\n\n    def advance(self):\n        if self.pos < len(self.input):\n            if self.input[self.pos] == '\n':\n                self.line += 1\n                self.col = 1\n            else:\n                self.col += 1\n            self.pos += 1\n\n    def skip_whitespace(self):\n        while self.peek() and self.peek().isspace():\n            self.advance()\n\n    def tokenize(self):\n        tokens = []\n\n        while self.pos < len(self.input):\n            self.skip_whitespace()\n            if self.pos >= len(self.input):\n                break\n\n            start_line, start_col = self.line, self.col\n\n            # Comments\n            if self.peek() == '/' and self.peek(1) == '/':\n                while self.peek() and self.peek() != '\n':\n                    self.advance()\n                continue\n\n            # Strings\n            if self.peek() == '\"':\n                self.advance()\n                value = ''\n                while self.peek() and self.peek() != '\"':\n                    if self.peek() == '\\':\n                        self.advance()\n                        if self.peek() == 'n':\n                            value += '\n'\n                        elif self.peek() == 't':\n                            value += '\t'\n                        elif self.peek():\n                            value += self.peek()\n                        self.advance()\n                    else:\n                        value += self.peek()\n                        self.advance()\n                self.advance()  # closing \"\n                tokens.append(Token('STRING', value, start_line, start_col, self.col - start_col))\n\n            # Numbers\n            elif self.peek() and self.peek().isdigit():\n                value = ''\n                while self.peek() and self.peek().isdigit():\n                    value += self.peek()\n                    self.advance()\n                tokens.append(Token('NUMBER', int(value), start_line, start_col, self.col - start_col))\n\n            # Identifiers\n            elif self.peek() and (self.peek().isalpha() or self.peek() == '_'):\n                value = ''\n                while self.peek() and (self.peek().isalnum() or self.peek() == '_'):\n                    value += self.peek()\n                    self.advance()\n                tokens.append(Token('IDENTIFIER', value, start_line, start_col, self.col - start_col))\n\n            # Operators\n            elif self.peek() == '=' and self.peek(1) == '=':\n                self.advance()\n                self.advance()\n                tokens.append(Token('EQUALS', '==', start_line, start_col, 2))\n            elif self.peek() == '=':\n                self.advance()\n                tokens.append(Token('ASSIGN', '=', start_line, start_col, 1))\n            elif self.peek() in '+-*/':\n                op = self.peek()\n                self.advance()\n                tokens.append(Token('OPERATOR', op, start_line, start_col, 1))\n            else:\n                self.advance()\n\n        return tokens\n\n# Test\nlexer = Lexer('x = 42 // comment\\ny = \"hello\"')\ntokens = lexer.tokenize()\nfor tok in tokens:\n    print(tok)",
    "testCases": [
      {
        "input": "x = 42",
        "expectedOutput": "3 tokens",
        "isHidden": false,
        "description": "Simple assignment"
      },
      {
        "input": "x = 42 // comment",
        "expectedOutput": "3 tokens (comment ignored)",
        "isHidden": false,
        "description": "Assignment with comment"
      },
      {
        "input": "y = \"hello\"",
        "expectedOutput": "3 tokens with string",
        "isHidden": true,
        "description": "String literal"
      }
    ],
    "hints": [
      "Use a Lexer class to maintain state (position, line, column)",
      "Implement helper methods like peek(), advance(), skip_whitespace()",
      "Create Token objects with full position metadata",
      "Handle all token types from previous exercises",
      "Track line and column accurately through newlines"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex01",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Simple Recursive Descent Parser",
    "difficulty": 2,
    "description": "Implement a recursive descent parser for arithmetic expressions with addition and multiplication following the grammar: E  T + E | T, T  num.",
    "starterCode": "class Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n\n    def peek(self):\n        return self.tokens[self.pos] if self.pos < len(self.tokens) else None\n\n    def consume(self, expected_type):\n        \"\"\"Consume and return token if it matches expected type\"\"\"\n        # Your code here\n        pass\n\n    def parse_expression(self):\n        \"\"\"E  T + E | T\"\"\"\n        # Your code here\n        pass\n\n    def parse_term(self):\n        \"\"\"T  num\"\"\"\n        # Your code here\n        pass\n\n# Test\ntokens = [('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\nresult = parser.parse_expression()\nprint(result)",
    "solution": "class Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n\n    def peek(self):\n        return self.tokens[self.pos] if self.pos < len(self.tokens) else None\n\n    def consume(self, expected_type):\n        \"\"\"Consume and return token if it matches expected type\"\"\"\n        token = self.peek()\n        if not token or token[0] != expected_type:\n            raise SyntaxError(f\"Expected {expected_type}, got {token}\")\n        self.pos += 1\n        return token\n\n    def parse_expression(self):\n        \"\"\"E  T + E | T\"\"\"\n        left = self.parse_term()\n\n        if self.peek() and self.peek()[0] == 'PLUS':\n            self.consume('PLUS')\n            right = self.parse_expression()\n            return ('ADD', left, right)\n\n        return left\n\n    def parse_term(self):\n        \"\"\"T  num\"\"\"\n        token = self.consume('NUMBER')\n        return ('NUM', token[1])\n\n# Test\ntokens = [('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\nresult = parser.parse_expression()\nprint(result)",
    "testCases": [
      {
        "input": "[('NUMBER', 5)]",
        "expectedOutput": "('NUM', 5)",
        "isHidden": false,
        "description": "Single number"
      },
      {
        "input": "[('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]",
        "expectedOutput": "('ADD', ('NUM', 5), ('NUM', 3))",
        "isHidden": false,
        "description": "Simple addition"
      },
      {
        "input": "[('NUMBER', 1), ('PLUS', '+'), ('NUMBER', 2), ('PLUS', '+'), ('NUMBER', 3)]",
        "expectedOutput": "nested ADD",
        "isHidden": true,
        "description": "Right-associative addition chain"
      }
    ],
    "hints": [
      "Each grammar rule becomes a parsing method",
      "Use peek() to look ahead without consuming",
      "Consume tokens that match the expected type",
      "Return parse tree nodes as tuples"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex02",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Grammar Ambiguity Detection",
    "difficulty": 3,
    "description": "Implement a function that detects if a grammar is ambiguous by checking for conflicts in a simple case (multiple derivations for the same string).",
    "starterCode": "def is_ambiguous_grammar(grammar, test_strings):\n    \"\"\"\n    Check if grammar produces multiple parse trees for any test string.\n    grammar: dict of production rules\n    test_strings: list of strings to test\n    Return True if any string has multiple derivations.\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'E'], ['E', '*', 'E'], ['num']]\n}\nprint(is_ambiguous_grammar(grammar, ['num+num*num']))",
    "solution": "def is_ambiguous_grammar(grammar, test_strings):\n    \"\"\"\n    Check if grammar produces multiple parse trees for any test string.\n    This is a simplified version that checks for the classic ambiguity pattern.\n    \"\"\"\n    # Check for ambiguous patterns in the grammar itself\n    def has_ambiguous_operators(productions):\n        \"\"\"Check if grammar has operators at same precedence level\"\"\"\n        operators = []\n        for prod in productions:\n            if len(prod) == 3 and prod[0] == prod[2]:  # E  E op E\n                operators.append(prod[1])\n        # If multiple operators exist with same recursive pattern, likely ambiguous\n        return len(operators) > 1\n\n    # Simple heuristic: if we have E  E + E | E * E, it's ambiguous\n    for nonterminal, productions in grammar.items():\n        if has_ambiguous_operators(productions):\n            return True\n\n    return False\n\n# More sophisticated version using CYK-style parsing\ndef is_ambiguous_grammar_advanced(grammar, test_strings):\n    \"\"\"\n    Actually parse test strings and count derivations.\n    This is computationally expensive but more accurate.\n    \"\"\"\n    def count_parse_trees(string, symbol, memo=None):\n        if memo is None:\n            memo = {}\n\n        if (string, symbol) in memo:\n            return memo[(string, symbol)]\n\n        if symbol not in grammar:\n            # Terminal\n            count = 1 if string == symbol else 0\n            memo[(string, symbol)] = count\n            return count\n\n        total = 0\n        for production in grammar[symbol]:\n            if len(production) == 1:\n                # E  num\n                total += count_parse_trees(string, production[0], memo)\n            elif len(production) == 3:\n                # E  E + E - try all splits\n                for i in range(len(string)):\n                    left = string[:i]\n                    right = string[i+1:]\n                    if i < len(string) and string[i] == production[1]:\n                        left_count = count_parse_trees(left, production[0], memo)\n                        right_count = count_parse_trees(right, production[2], memo)\n                        total += left_count * right_count\n\n        memo[(string, symbol)] = total\n        return total\n\n    for test_str in test_strings:\n        if count_parse_trees(test_str, 'E') > 1:\n            return True\n\n    return False\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'E'], ['E', '*', 'E'], ['num']]\n}\nprint(is_ambiguous_grammar(grammar, ['num+num*num']))",
    "testCases": [
      {
        "input": "grammar1",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Ambiguous arithmetic grammar"
      },
      {
        "input": "grammar2",
        "expectedOutput": "False",
        "isHidden": true,
        "description": "Unambiguous grammar with precedence"
      }
    ],
    "hints": [
      "A grammar is ambiguous if one string has multiple parse trees",
      "Look for patterns like E  E + E | E * E (same precedence)",
      "You can check heuristically or actually parse test strings",
      "This is undecidable in general, so use approximations"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex03",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "First and Follow Sets",
    "difficulty": 3,
    "description": "Compute FIRST and FOLLOW sets for a context-free grammar, used in LL parsing.",
    "starterCode": "def compute_first_sets(grammar):\n    \"\"\"\n    Compute FIRST sets for each nonterminal.\n    grammar: dict {nonterminal: [[production], ...]}\n    Return: dict {symbol: set of terminals}\n    \"\"\"\n    # Your code here\n    pass\n\ndef compute_follow_sets(grammar, start_symbol):\n    \"\"\"\n    Compute FOLLOW sets for each nonterminal.\n    Return: dict {nonterminal: set of terminals}\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'S': [['A', 'B']],\n    'A': [['a'], ['']],\n    'B': [['b']]\n}\nprint(compute_first_sets(grammar))\nprint(compute_follow_sets(grammar, 'S'))",
    "solution": "def compute_first_sets(grammar):\n    \"\"\"\n    Compute FIRST sets for each nonterminal.\n    grammar: dict {nonterminal: [[production], ...]}\n    Return: dict {symbol: set of terminals}\n    \"\"\"\n    first = {nt: set() for nt in grammar}\n\n    # Terminals have themselves in FIRST\n    all_symbols = set()\n    for productions in grammar.values():\n        for prod in productions:\n            all_symbols.update(prod)\n\n    terminals = all_symbols - set(grammar.keys())\n\n    changed = True\n    while changed:\n        changed = False\n        for nonterminal in grammar:\n            for production in grammar[nonterminal]:\n                # Empty production\n                if production == ['']:\n                    if '' not in first[nonterminal]:\n                        first[nonterminal].add('')\n                        changed = True\n                    continue\n\n                # Process symbols in production\n                for symbol in production:\n                    if symbol in terminals:\n                        if symbol not in first[nonterminal]:\n                            first[nonterminal].add(symbol)\n                            changed = True\n                        break\n                    else:\n                        # Nonterminal\n                        before = len(first[nonterminal])\n                        first[nonterminal].update(first[symbol] - {''})\n                        if len(first[nonterminal]) > before:\n                            changed = True\n\n                        if '' not in first[symbol]:\n                            break\n                else:\n                    # All symbols can derive epsilon\n                    if '' not in first[nonterminal]:\n                        first[nonterminal].add('')\n                        changed = True\n\n    return first\n\ndef compute_follow_sets(grammar, start_symbol):\n    \"\"\"\n    Compute FOLLOW sets for each nonterminal.\n    Return: dict {nonterminal: set of terminals}\n    \"\"\"\n    first = compute_first_sets(grammar)\n    follow = {nt: set() for nt in grammar}\n    follow[start_symbol].add('$')  # End marker\n\n    changed = True\n    while changed:\n        changed = False\n        for nonterminal in grammar:\n            for production in grammar[nonterminal]:\n                for i, symbol in enumerate(production):\n                    if symbol not in grammar:\n                        continue  # Terminal\n\n                    # Everything after symbol\n                    rest = production[i+1:]\n\n                    if not rest:\n                        # Symbol is last - add FOLLOW(nonterminal)\n                        before = len(follow[symbol])\n                        follow[symbol].update(follow[nonterminal])\n                        if len(follow[symbol]) > before:\n                            changed = True\n                    else:\n                        # Add FIRST(rest) to FOLLOW(symbol)\n                        for next_symbol in rest:\n                            if next_symbol in grammar:\n                                before = len(follow[symbol])\n                                follow[symbol].update(first[next_symbol] - {''})\n                                if len(follow[symbol]) > before:\n                                    changed = True\n                                if '' not in first[next_symbol]:\n                                    break\n                            else:\n                                # Terminal\n                                if next_symbol not in follow[symbol]:\n                                    follow[symbol].add(next_symbol)\n                                    changed = True\n                                break\n                        else:\n                            # All symbols in rest can derive epsilon\n                            before = len(follow[symbol])\n                            follow[symbol].update(follow[nonterminal])\n                            if len(follow[symbol]) > before:\n                                changed = True\n\n    return follow\n\n# Test\ngrammar = {\n    'S': [['A', 'B']],\n    'A': [['a'], ['']],\n    'B': [['b']]\n}\nprint(compute_first_sets(grammar))\nprint(compute_follow_sets(grammar, 'S'))",
    "testCases": [
      {
        "input": "grammar1",
        "expectedOutput": "FIRST(A) = {a, }, FIRST(B) = {b}",
        "isHidden": false,
        "description": "Simple grammar"
      },
      {
        "input": "grammar2",
        "expectedOutput": "FOLLOW(A) = {b}",
        "isHidden": true,
        "description": "Follow set computation"
      }
    ],
    "hints": [
      "FIRST(X) is the set of terminals that can start strings derived from X",
      "If X  , then   FIRST(X)",
      "FOLLOW(X) is the set of terminals that can appear after X",
      "Use fixed-point iteration until sets stop growing"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex04",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "LL(1) Parse Table Construction",
    "difficulty": 4,
    "description": "Build an LL(1) parse table from a grammar using FIRST and FOLLOW sets.",
    "starterCode": "def build_ll1_table(grammar, start_symbol):\n    \"\"\"\n    Build LL(1) parsing table.\n    Return: dict {(nonterminal, terminal): production}\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'E': [['T', 'E_prime']],\n    'E_prime': [['PLUS', 'T', 'E_prime'], ['']],\n    'T': [['num']]\n}\ntable = build_ll1_table(grammar, 'E')\nprint(table[('E', 'num')])  # Should be ['T', 'E_prime']",
    "solution": "def compute_first_sets(grammar):\n    \"\"\"Compute FIRST sets\"\"\"\n    first = {nt: set() for nt in grammar}\n    all_symbols = set()\n    for productions in grammar.values():\n        for prod in productions:\n            all_symbols.update(prod)\n    terminals = all_symbols - set(grammar.keys())\n\n    changed = True\n    while changed:\n        changed = False\n        for nonterminal in grammar:\n            for production in grammar[nonterminal]:\n                if production == ['']:\n                    if '' not in first[nonterminal]:\n                        first[nonterminal].add('')\n                        changed = True\n                    continue\n\n                for symbol in production:\n                    if symbol in terminals:\n                        if symbol not in first[nonterminal]:\n                            first[nonterminal].add(symbol)\n                            changed = True\n                        break\n                    else:\n                        before = len(first[nonterminal])\n                        first[nonterminal].update(first[symbol] - {''})\n                        if len(first[nonterminal]) > before:\n                            changed = True\n                        if '' not in first[symbol]:\n                            break\n                else:\n                    if '' not in first[nonterminal]:\n                        first[nonterminal].add('')\n                        changed = True\n    return first\n\ndef compute_follow_sets(grammar, start_symbol):\n    \"\"\"Compute FOLLOW sets\"\"\"\n    first = compute_first_sets(grammar)\n    follow = {nt: set() for nt in grammar}\n    follow[start_symbol].add('$')\n\n    changed = True\n    while changed:\n        changed = False\n        for nonterminal in grammar:\n            for production in grammar[nonterminal]:\n                for i, symbol in enumerate(production):\n                    if symbol not in grammar:\n                        continue\n                    rest = production[i+1:]\n                    if not rest:\n                        before = len(follow[symbol])\n                        follow[symbol].update(follow[nonterminal])\n                        if len(follow[symbol]) > before:\n                            changed = True\n                    else:\n                        for next_symbol in rest:\n                            if next_symbol in grammar:\n                                before = len(follow[symbol])\n                                follow[symbol].update(first[next_symbol] - {''})\n                                if len(follow[symbol]) > before:\n                                    changed = True\n                                if '' not in first[next_symbol]:\n                                    break\n                            else:\n                                if next_symbol not in follow[symbol]:\n                                    follow[symbol].add(next_symbol)\n                                    changed = True\n                                break\n                        else:\n                            before = len(follow[symbol])\n                            follow[symbol].update(follow[nonterminal])\n                            if len(follow[symbol]) > before:\n                                changed = True\n    return follow\n\ndef build_ll1_table(grammar, start_symbol):\n    \"\"\"\n    Build LL(1) parsing table.\n    Return: dict {(nonterminal, terminal): production}\n    \"\"\"\n    first = compute_first_sets(grammar)\n    follow = compute_follow_sets(grammar, start_symbol)\n    table = {}\n\n    for nonterminal in grammar:\n        for production in grammar[nonterminal]:\n            # Compute FIRST of production\n            prod_first = set()\n\n            if production == ['']:\n                prod_first.add('')\n            else:\n                for symbol in production:\n                    if symbol not in grammar:\n                        prod_first.add(symbol)\n                        break\n                    else:\n                        prod_first.update(first[symbol] - {''})\n                        if '' not in first[symbol]:\n                            break\n                else:\n                    prod_first.add('')\n\n            # For each terminal in FIRST(production)\n            for terminal in prod_first - {''}:\n                if (nonterminal, terminal) in table:\n                    raise ValueError(f\"Grammar is not LL(1): conflict at ({nonterminal}, {terminal})\")\n                table[(nonterminal, terminal)] = production\n\n            # If epsilon in FIRST(production), add for FOLLOW terminals\n            if '' in prod_first:\n                for terminal in follow[nonterminal]:\n                    if (nonterminal, terminal) in table:\n                        raise ValueError(f\"Grammar is not LL(1): conflict at ({nonterminal}, {terminal})\")\n                    table[(nonterminal, terminal)] = production\n\n    return table\n\n# Test\ngrammar = {\n    'E': [['T', 'E_prime']],\n    'E_prime': [['PLUS', 'T', 'E_prime'], ['']],\n    'T': [['num']]\n}\ntable = build_ll1_table(grammar, 'E')\nprint(table[('E', 'num')])  # Should be ['T', 'E_prime']",
    "testCases": [
      {
        "input": "grammar1",
        "expectedOutput": "['T', 'E_prime']",
        "isHidden": false,
        "description": "LL(1) table entry for E"
      },
      {
        "input": "grammar2",
        "expectedOutput": "['']",
        "isHidden": true,
        "description": "Epsilon production in table"
      }
    ],
    "hints": [
      "For production A  , add it to table[A, t] for each t in FIRST()",
      "If   FIRST(), also add it for each t in FOLLOW(A)",
      "If any table entry has multiple productions, grammar is not LL(1)",
      "Use FIRST and FOLLOW sets computed earlier"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex05",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Table-Driven LL(1) Parser",
    "difficulty": 3,
    "description": "Implement a table-driven LL(1) parser using a parse table and stack.",
    "starterCode": "def ll1_parse(grammar, parse_table, start_symbol, tokens):\n    \"\"\"\n    Parse tokens using LL(1) parse table.\n    Return parse tree or raise SyntaxError.\n    tokens: list ending with '$'\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'E': [['T', 'E_prime']],\n    'E_prime': [['PLUS', 'T', 'E_prime'], ['']],\n    'T': [['num']]\n}\ntable = {\n    ('E', 'num'): ['T', 'E_prime'],\n    ('E_prime', 'PLUS'): ['PLUS', 'T', 'E_prime'],\n    ('E_prime', '$'): [''],\n    ('T', 'num'): ['num']\n}\ntokens = ['num', 'PLUS', 'num', '$']\ntree = ll1_parse(grammar, table, 'E', tokens)\nprint(tree)",
    "solution": "def ll1_parse(grammar, parse_table, start_symbol, tokens):\n    \"\"\"\n    Parse tokens using LL(1) parse table.\n    Return parse tree or raise SyntaxError.\n    \"\"\"\n    stack = ['$', start_symbol]\n    token_idx = 0\n    parse_tree = {start_symbol: []}\n\n    while stack:\n        top = stack.pop()\n        current_token = tokens[token_idx] if token_idx < len(tokens) else '$'\n\n        if top == '$':\n            if current_token == '$':\n                return parse_tree\n            else:\n                raise SyntaxError(\"Unexpected tokens at end\")\n\n        elif top == '':\n            # Epsilon, skip\n            continue\n\n        elif top not in grammar:\n            # Terminal\n            if top == current_token:\n                token_idx += 1\n            else:\n                raise SyntaxError(f\"Expected {top}, got {current_token}\")\n\n        else:\n            # Nonterminal - use parse table\n            if (top, current_token) not in parse_table:\n                raise SyntaxError(f\"No parse table entry for ({top}, {current_token})\")\n\n            production = parse_table[(top, current_token)]\n\n            # Push production in reverse order\n            for symbol in reversed(production):\n                if symbol != '':\n                    stack.append(symbol)\n\n    if token_idx < len(tokens) - 1:\n        raise SyntaxError(\"Not all tokens consumed\")\n\n    return \"Accepted\"\n\n# More sophisticated version with tree building\ndef ll1_parse_with_tree(grammar, parse_table, start_symbol, tokens):\n    \"\"\"Parse and build explicit tree structure\"\"\"\n    stack = [('$', None), (start_symbol, None)]\n    token_idx = 0\n    nodes = {}\n    node_id = 0\n\n    def make_node(symbol):\n        nonlocal node_id\n        nid = node_id\n        node_id += 1\n        nodes[nid] = {'symbol': symbol, 'children': []}\n        return nid\n\n    root_id = make_node(start_symbol)\n    stack = [('$', None), (start_symbol, root_id)]\n\n    while stack:\n        top, parent_id = stack.pop()\n        current_token = tokens[token_idx] if token_idx < len(tokens) else '$'\n\n        if top == '$':\n            if current_token == '$':\n                return nodes[root_id]\n            else:\n                raise SyntaxError(\"Unexpected tokens at end\")\n\n        elif top == '':\n            continue\n\n        elif top not in grammar:\n            # Terminal\n            if top == current_token:\n                child_id = make_node(top)\n                nodes[parent_id]['children'].append(child_id)\n                token_idx += 1\n            else:\n                raise SyntaxError(f\"Expected {top}, got {current_token}\")\n\n        else:\n            # Nonterminal\n            if (top, current_token) not in parse_table:\n                raise SyntaxError(f\"No parse table entry for ({top}, {current_token})\")\n\n            production = parse_table[(top, current_token)]\n\n            # Create children and push onto stack\n            child_ids = []\n            for symbol in production:\n                if symbol != '':\n                    child_id = make_node(symbol)\n                    child_ids.append(child_id)\n\n            nodes[parent_id]['children'] = child_ids\n\n            for symbol, cid in zip(reversed(production), reversed(child_ids)):\n                if symbol != '':\n                    stack.append((symbol, cid))\n\n    return nodes[root_id]\n\n# Test\ngrammar = {\n    'E': [['T', 'E_prime']],\n    'E_prime': [['PLUS', 'T', 'E_prime'], ['']],\n    'T': [['num']]\n}\ntable = {\n    ('E', 'num'): ['T', 'E_prime'],\n    ('E_prime', 'PLUS'): ['PLUS', 'T', 'E_prime'],\n    ('E_prime', '$'): [''],\n    ('T', 'num'): ['num']\n}\ntokens = ['num', 'PLUS', 'num', '$']\ntree = ll1_parse(grammar, table, 'E', tokens)\nprint(tree)",
    "testCases": [
      {
        "input": "['num', '$']",
        "expectedOutput": "Accepted",
        "isHidden": false,
        "description": "Single number"
      },
      {
        "input": "['num', 'PLUS', 'num', '$']",
        "expectedOutput": "Accepted",
        "isHidden": false,
        "description": "Addition expression"
      },
      {
        "input": "['num', 'num', '$']",
        "expectedOutput": "SyntaxError",
        "isHidden": true,
        "description": "Invalid syntax"
      }
    ],
    "hints": [
      "Use a stack initialized with [$, start_symbol]",
      "Match terminals, expand nonterminals using table",
      "Pop from stack and compare with current input token",
      "Accept when stack is $ and input is $"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex06",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "LR(0) Items and Closures",
    "difficulty": 4,
    "description": "Compute the closure of LR(0) items, used in LR parser construction.",
    "starterCode": "def lr0_closure(items, grammar):\n    \"\"\"\n    Compute closure of LR(0) items.\n    items: set of (production, dot_position) tuples\n    grammar: dict {nonterminal: [[production], ...]}\n    Return: set of items in closure\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    \"S'\": [['E']],\n    'E': [['E', '+', 'T'], ['T']],\n    'T': [['num']]\n}\nitems = {(\"S'\", ('E',), 0)}  # S'  E\nclosure = lr0_closure(items, grammar)\nprint(closure)",
    "solution": "def lr0_closure(items, grammar):\n    \"\"\"\n    Compute closure of LR(0) items.\n    items: set of (nonterminal, production, dot_position) tuples\n    grammar: dict {nonterminal: [[production], ...]}\n    Return: set of items in closure\n    \"\"\"\n    closure = set(items)\n    changed = True\n\n    while changed:\n        changed = False\n        new_items = set()\n\n        for nonterminal, production, dot in closure:\n            # If dot is before a nonterminal\n            if dot < len(production):\n                next_symbol = production[dot]\n\n                if next_symbol in grammar:\n                    # Add all productions of next_symbol with dot at start\n                    for prod in grammar[next_symbol]:\n                        item = (next_symbol, tuple(prod), 0)\n                        if item not in closure:\n                            new_items.add(item)\n                            changed = True\n\n        closure.update(new_items)\n\n    return closure\n\n# Test\ngrammar = {\n    \"S'\": [['E']],\n    'E': [['E', '+', 'T'], ['T']],\n    'T': [['num']]\n}\nitems = {(\"S'\", ('E',), 0)}  # S'  E\nclosure = lr0_closure(items, grammar)\nprint(closure)",
    "testCases": [
      {
        "input": "items1",
        "expectedOutput": "Contains E  E + T, E  T, T  num",
        "isHidden": false,
        "description": "Closure of start item"
      },
      {
        "input": "items2",
        "expectedOutput": "Only original items",
        "isHidden": true,
        "description": "Closure with no additions"
      }
    ],
    "hints": [
      "An LR(0) item is a production with a dot marking position",
      "Closure adds items for nonterminals after the dot",
      "If A  B is in closure, add B   for all B productions",
      "Iterate until no new items are added"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex07",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "LR(0) GOTO Function",
    "difficulty": 4,
    "description": "Implement the GOTO function that computes the next state in LR parsing.",
    "starterCode": "def lr0_goto(items, symbol, grammar):\n    \"\"\"\n    Compute GOTO(items, symbol) for LR(0) parsing.\n    Move dot over symbol and compute closure.\n    items: set of (nonterminal, production, dot) items\n    symbol: grammar symbol to process\n    Return: set of items\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'T'], ['T']],\n    'T': [['num']]\n}\nitems = {('E', ('E', '+', 'T'), 0), ('E', ('T',), 0)}\ngoto_result = lr0_goto(items, 'T', grammar)\nprint(goto_result)",
    "solution": "def lr0_closure(items, grammar):\n    \"\"\"Compute closure of LR(0) items\"\"\"\n    closure = set(items)\n    changed = True\n\n    while changed:\n        changed = False\n        new_items = set()\n\n        for nonterminal, production, dot in closure:\n            if dot < len(production):\n                next_symbol = production[dot]\n                if next_symbol in grammar:\n                    for prod in grammar[next_symbol]:\n                        item = (next_symbol, tuple(prod), 0)\n                        if item not in closure:\n                            new_items.add(item)\n                            changed = True\n\n        closure.update(new_items)\n\n    return closure\n\ndef lr0_goto(items, symbol, grammar):\n    \"\"\"\n    Compute GOTO(items, symbol) for LR(0) parsing.\n    Move dot over symbol and compute closure.\n    \"\"\"\n    # Find items with dot before symbol\n    moved_items = set()\n\n    for nonterminal, production, dot in items:\n        if dot < len(production) and production[dot] == symbol:\n            # Move dot one position\n            moved_items.add((nonterminal, production, dot + 1))\n\n    # Compute closure of moved items\n    if moved_items:\n        return lr0_closure(moved_items, grammar)\n    else:\n        return set()\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'T'], ['T']],\n    'T': [['num']]\n}\nitems = {('E', ('E', '+', 'T'), 0), ('E', ('T',), 0)}\ngoto_result = lr0_goto(items, 'T', grammar)\nprint(goto_result)",
    "testCases": [
      {
        "input": "(items, 'T')",
        "expectedOutput": "{('E', ('T',), 1)}",
        "isHidden": false,
        "description": "GOTO on T"
      },
      {
        "input": "(items, 'E')",
        "expectedOutput": "{('E', ('E', '+', 'T'), 1)}",
        "isHidden": true,
        "description": "GOTO on E"
      }
    ],
    "hints": [
      "GOTO(I, X) moves the dot over symbol X",
      "For each item A  X, create A  X",
      "Then compute closure of the resulting items",
      "Return empty set if no items have X after the dot"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex08",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "SLR Parse Table Construction",
    "difficulty": 5,
    "description": "Build an SLR(1) parse table with shift, reduce, and accept actions.",
    "starterCode": "def build_slr_table(grammar, start_symbol):\n    \"\"\"\n    Build SLR(1) parsing table.\n    Return: (action_table, goto_table, states)\n    action_table: {(state, terminal): ('shift', next_state) | ('reduce', production) | 'accept'}\n    goto_table: {(state, nonterminal): next_state}\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    \"S'\": [['E']],\n    'E': [['E', '+', 'n'], ['n']]\n}\naction, goto, states = build_slr_table(grammar, \"S'\")\nprint(f\"Number of states: {len(states)}\")",
    "solution": "def compute_follow_sets(grammar, start_symbol):\n    \"\"\"Compute FOLLOW sets for SLR\"\"\"\n    # Simplified version\n    follow = {nt: set() for nt in grammar}\n    follow[start_symbol].add('$')\n\n    changed = True\n    while changed:\n        changed = False\n        for nt in grammar:\n            for prod in grammar[nt]:\n                for i, symbol in enumerate(prod):\n                    if symbol not in grammar:\n                        continue\n                    # Add what follows symbol\n                    if i + 1 < len(prod):\n                        next_sym = prod[i + 1]\n                        if next_sym not in grammar:\n                            if next_sym not in follow[symbol]:\n                                follow[symbol].add(next_sym)\n                                changed = True\n                    else:\n                        # Symbol is last\n                        before = len(follow[symbol])\n                        follow[symbol].update(follow[nt])\n                        if len(follow[symbol]) > before:\n                            changed = True\n    return follow\n\ndef lr0_closure(items, grammar):\n    \"\"\"Compute closure\"\"\"\n    closure = set(items)\n    changed = True\n    while changed:\n        changed = False\n        new_items = set()\n        for nonterminal, production, dot in closure:\n            if dot < len(production):\n                next_symbol = production[dot]\n                if next_symbol in grammar:\n                    for prod in grammar[next_symbol]:\n                        item = (next_symbol, tuple(prod), 0)\n                        if item not in closure:\n                            new_items.add(item)\n                            changed = True\n        closure.update(new_items)\n    return closure\n\ndef lr0_goto(items, symbol, grammar):\n    \"\"\"Compute GOTO\"\"\"\n    moved_items = set()\n    for nonterminal, production, dot in items:\n        if dot < len(production) and production[dot] == symbol:\n            moved_items.add((nonterminal, production, dot + 1))\n    if moved_items:\n        return lr0_closure(moved_items, grammar)\n    return set()\n\ndef build_slr_table(grammar, start_symbol):\n    \"\"\"Build SLR(1) parsing table\"\"\"\n    # Get all symbols\n    all_symbols = set()\n    for prods in grammar.values():\n        for prod in prods:\n            all_symbols.update(prod)\n\n    terminals = (all_symbols - set(grammar.keys())) | {'$'}\n    nonterminals = set(grammar.keys())\n\n    # Build canonical collection of LR(0) items\n    start_items = lr0_closure({(start_symbol, tuple(grammar[start_symbol][0]), 0)}, grammar)\n    states = [start_items]\n    state_map = {frozenset(start_items): 0}\n    unmarked = [0]\n\n    while unmarked:\n        state_id = unmarked.pop()\n        items = states[state_id]\n\n        for symbol in all_symbols | nonterminals:\n            goto_items = lr0_goto(items, symbol, grammar)\n            if goto_items:\n                goto_frozen = frozenset(goto_items)\n                if goto_frozen not in state_map:\n                    state_map[goto_frozen] = len(states)\n                    states.append(goto_items)\n                    unmarked.append(len(states) - 1)\n\n    # Build ACTION and GOTO tables\n    action = {}\n    goto = {}\n    follow = compute_follow_sets(grammar, start_symbol)\n\n    for state_id, items in enumerate(states):\n        for nt, prod, dot in items:\n            if dot < len(prod):\n                next_symbol = prod[dot]\n                goto_items = lr0_goto(items, next_symbol, grammar)\n                if goto_items:\n                    goto_frozen = frozenset(goto_items)\n                    next_state = state_map[goto_frozen]\n\n                    if next_symbol in terminals:\n                        # Shift\n                        action[(state_id, next_symbol)] = ('shift', next_state)\n                    elif next_symbol in nonterminals:\n                        # GOTO\n                        goto[(state_id, next_symbol)] = next_state\n            else:\n                # Reduce item\n                if nt == start_symbol:\n                    # Accept\n                    action[(state_id, '$')] = 'accept'\n                else:\n                    # Reduce by production\n                    for terminal in follow[nt]:\n                        action[(state_id, terminal)] = ('reduce', (nt, prod))\n\n    return action, goto, states\n\n# Test\ngrammar = {\n    \"S'\": [['E']],\n    'E': [['E', '+', 'n'], ['n']]\n}\naction, goto, states = build_slr_table(grammar, \"S'\")\nprint(f\"Number of states: {len(states)}\")",
    "testCases": [
      {
        "input": "grammar1",
        "expectedOutput": "5 states",
        "isHidden": false,
        "description": "Simple expression grammar"
      },
      {
        "input": "grammar2",
        "expectedOutput": "Valid SLR table",
        "isHidden": true,
        "description": "More complex grammar"
      }
    ],
    "hints": [
      "Build canonical collection of LR(0) item sets",
      "For items with dot before terminal, add shift actions",
      "For complete items A  , add reduce for terminals in FOLLOW(A)",
      "GOTO table handles nonterminal transitions",
      "Detect conflicts: multiple actions for same (state, symbol)"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex09",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Shift-Reduce Parser",
    "difficulty": 4,
    "description": "Implement a shift-reduce parser using an SLR parse table.",
    "starterCode": "def shift_reduce_parse(action_table, goto_table, tokens):\n    \"\"\"\n    Parse tokens using shift-reduce parsing.\n    tokens: list ending with '$'\n    Return: list of parse actions taken\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\naction = {\n    (0, 'n'): ('shift', 2),\n    (0, '$'): ('reduce', ('E', ('n',))),\n    (2, '$'): ('reduce', ('E', ('n',))),\n    (1, '$'): 'accept'\n}\ngoto = {(0, 'E'): 1}\ntokens = ['n', '$']\nactions = shift_reduce_parse(action, goto, tokens)\nprint(actions)",
    "solution": "def shift_reduce_parse(action_table, goto_table, tokens):\n    \"\"\"\n    Parse tokens using shift-reduce parsing.\n    tokens: list ending with '$'\n    Return: list of parse actions taken\n    \"\"\"\n    stack = [0]  # State stack\n    symbol_stack = []  # Symbol stack\n    token_idx = 0\n    actions_taken = []\n\n    while True:\n        state = stack[-1]\n        token = tokens[token_idx]\n\n        if (state, token) not in action_table:\n            raise SyntaxError(f\"No action for state {state}, token {token}\")\n\n        action = action_table[(state, token)]\n\n        if action == 'accept':\n            actions_taken.append('accept')\n            return actions_taken\n\n        elif action[0] == 'shift':\n            next_state = action[1]\n            actions_taken.append(f\"shift {token} to state {next_state}\")\n            stack.append(next_state)\n            symbol_stack.append(token)\n            token_idx += 1\n\n        elif action[0] == 'reduce':\n            nonterminal, production = action[1]\n            actions_taken.append(f\"reduce by {nonterminal}  {' '.join(production)}\")\n\n            # Pop production length from stacks\n            prod_len = len(production)\n            for _ in range(prod_len):\n                stack.pop()\n                if symbol_stack:\n                    symbol_stack.pop()\n\n            # Push nonterminal\n            symbol_stack.append(nonterminal)\n\n            # GOTO\n            state = stack[-1]\n            if (state, nonterminal) not in goto_table:\n                raise SyntaxError(f\"No GOTO for state {state}, nonterminal {nonterminal}\")\n\n            next_state = goto_table[(state, nonterminal)]\n            stack.append(next_state)\n\n        else:\n            raise SyntaxError(f\"Unknown action: {action}\")\n\n# Test\naction = {\n    (0, 'n'): ('shift', 2),\n    (2, '$'): ('reduce', ('E', ('n',))),\n    (1, '$'): 'accept',\n    (0, 'E'): None  # This would be in goto table\n}\ngoto = {(0, 'E'): 1}\ntokens = ['n', '$']\nactions = shift_reduce_parse(action, goto, tokens)\nprint(actions)",
    "testCases": [
      {
        "input": "['n', '$']",
        "expectedOutput": "['shift', 'reduce', 'accept']",
        "isHidden": false,
        "description": "Parse single number"
      },
      {
        "input": "['n', '+', 'n', '$']",
        "expectedOutput": "shift/reduce sequence",
        "isHidden": true,
        "description": "Parse addition"
      }
    ],
    "hints": [
      "Maintain two stacks: state stack and symbol stack",
      "Shift: push token and next state",
      "Reduce: pop production length, push nonterminal, use GOTO",
      "Accept: when reaching accept action",
      "Handle errors when no action exists"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex10",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Parse Tree Construction",
    "difficulty": 3,
    "description": "Build an explicit parse tree data structure during recursive descent parsing.",
    "starterCode": "class ParseNode:\n    def __init__(self, symbol, children=None):\n        self.symbol = symbol\n        self.children = children or []\n\n    def __repr__(self):\n        return f\"ParseNode({self.symbol}, {self.children})\"\n\nclass Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n\n    def parse(self):\n        \"\"\"Parse and return parse tree\"\"\"\n        # Your code here\n        pass\n\n# Test\ntokens = [('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\ntree = parser.parse()\nprint(tree)",
    "solution": "class ParseNode:\n    def __init__(self, symbol, children=None, value=None):\n        self.symbol = symbol\n        self.children = children or []\n        self.value = value\n\n    def __repr__(self, level=0):\n        indent = \"  \" * level\n        if self.children:\n            children_repr = \"\\n\".join(c.__repr__(level + 1) for c in self.children)\n            return f\"{indent}{self.symbol}\\n{children_repr}\"\n        else:\n            val = f\"={self.value}\" if self.value is not None else \"\"\n            return f\"{indent}{self.symbol}{val}\"\n\nclass Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n\n    def peek(self):\n        return self.tokens[self.pos] if self.pos < len(self.tokens) else None\n\n    def consume(self, expected_type):\n        token = self.peek()\n        if not token or token[0] != expected_type:\n            raise SyntaxError(f\"Expected {expected_type}, got {token}\")\n        self.pos += 1\n        return token\n\n    def parse(self):\n        \"\"\"Parse and return parse tree for expression\"\"\"\n        return self.parse_expression()\n\n    def parse_expression(self):\n        \"\"\"E  T + E | T\"\"\"\n        node = ParseNode('E')\n        left = self.parse_term()\n        node.children.append(left)\n\n        if self.peek() and self.peek()[0] == 'PLUS':\n            plus_token = self.consume('PLUS')\n            plus_node = ParseNode('PLUS', value=plus_token[1])\n            node.children.append(plus_node)\n\n            right = self.parse_expression()\n            node.children.append(right)\n\n        return node\n\n    def parse_term(self):\n        \"\"\"T  num\"\"\"\n        token = self.consume('NUMBER')\n        return ParseNode('NUMBER', value=token[1])\n\n# Test\ntokens = [('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\ntree = parser.parse()\nprint(tree)",
    "testCases": [
      {
        "input": "[('NUMBER', 5)]",
        "expectedOutput": "Tree with single NUMBER node",
        "isHidden": false,
        "description": "Single number tree"
      },
      {
        "input": "[('NUMBER', 5), ('PLUS', '+'), ('NUMBER', 3)]",
        "expectedOutput": "Tree with E  NUMBER PLUS E structure",
        "isHidden": false,
        "description": "Addition tree"
      },
      {
        "input": "[('NUMBER', 1), ('PLUS', '+'), ('NUMBER', 2), ('PLUS', '+'), ('NUMBER', 3)]",
        "expectedOutput": "Right-associative tree",
        "isHidden": true,
        "description": "Chain of additions"
      }
    ],
    "hints": [
      "Create ParseNode objects for each grammar symbol",
      "Attach children when recursively parsing sub-expressions",
      "Store token values in leaf nodes",
      "Return the root node from each parsing method"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex11",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Left Factoring",
    "difficulty": 3,
    "description": "Transform a grammar by left factoring to eliminate common prefixes, making it suitable for LL parsing.",
    "starterCode": "def left_factor(grammar):\n    \"\"\"\n    Transform grammar by left factoring.\n    grammar: dict {nonterminal: [[production], ...]}\n    Return: transformed grammar\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'A': [['a', 'b'], ['a', 'c']]\n}\nfactored = left_factor(grammar)\nprint(factored)  # Should factor out common 'a'",
    "solution": "def left_factor(grammar):\n    \"\"\"\n    Transform grammar by left factoring.\n    Finds common prefixes and factors them out.\n    \"\"\"\n    new_grammar = {}\n    suffix_counter = {}\n\n    for nonterminal in grammar:\n        productions = grammar[nonterminal]\n\n        # Group productions by common prefix\n        prefix_groups = {}\n\n        for prod in productions:\n            if not prod:\n                continue\n\n            # Find longest common prefix with other productions\n            prefix = tuple([prod[0]])  # Start with first symbol\n\n            # Could extend to find longer prefixes\n            if prefix not in prefix_groups:\n                prefix_groups[prefix] = []\n            prefix_groups[prefix].append(prod)\n\n        # Build new productions\n        new_prods = []\n\n        for prefix, group in prefix_groups.items():\n            if len(group) > 1:\n                # Need to factor\n                # Create new nonterminal\n                if nonterminal not in suffix_counter:\n                    suffix_counter[nonterminal] = 0\n                suffix_counter[nonterminal] += 1\n                new_nt = f\"{nonterminal}_prime{suffix_counter[nonterminal]}\"\n\n                # Add: A  prefix A'\n                new_prods.append(list(prefix) + [new_nt])\n\n                # Add: A'  suffix1 | suffix2 | ...\n                new_grammar[new_nt] = []\n                for prod in group:\n                    suffix = prod[len(prefix):]\n                    if not suffix:\n                        suffix = ['']\n                    new_grammar[new_nt].append(suffix)\n            else:\n                # No factoring needed\n                new_prods.append(group[0])\n\n        new_grammar[nonterminal] = new_prods\n\n    return new_grammar\n\n# More sophisticated version\ndef left_factor_advanced(grammar):\n    \"\"\"\n    Left factor with longest common prefix detection.\n    \"\"\"\n    def longest_common_prefix(prods):\n        \"\"\"Find longest common prefix among productions\"\"\"\n        if not prods or len(prods) < 2:\n            return []\n\n        prefix = []\n        min_len = min(len(p) for p in prods)\n\n        for i in range(min_len):\n            symbols = [p[i] for p in prods]\n            if all(s == symbols[0] for s in symbols):\n                prefix.append(symbols[0])\n            else:\n                break\n\n        return prefix\n\n    new_grammar = dict(grammar)\n    changed = True\n    counter = 0\n\n    while changed:\n        changed = False\n\n        for nonterminal in list(new_grammar.keys()):\n            productions = new_grammar[nonterminal]\n\n            # Try to find productions with common prefix\n            for i in range(len(productions)):\n                for j in range(i + 1, len(productions)):\n                    prefix = longest_common_prefix([productions[i], productions[j]])\n\n                    if prefix:\n                        # Found common prefix - factor it out\n                        changed = True\n                        counter += 1\n                        new_nt = f\"{nonterminal}_prime{counter}\"\n\n                        # Collect all productions with this prefix\n                        with_prefix = []\n                        without_prefix = []\n\n                        for prod in productions:\n                            if prod[:len(prefix)] == prefix:\n                                with_prefix.append(prod)\n                            else:\n                                without_prefix.append(prod)\n\n                        # Create new productions\n                        new_grammar[nonterminal] = without_prefix + [prefix + [new_nt]]\n                        new_grammar[new_nt] = []\n\n                        for prod in with_prefix:\n                            suffix = prod[len(prefix):]\n                            if not suffix:\n                                suffix = ['']\n                            new_grammar[new_nt].append(suffix)\n\n                        break\n                if changed:\n                    break\n            if changed:\n                break\n\n    return new_grammar\n\n# Test\ngrammar = {\n    'A': [['a', 'b'], ['a', 'c']]\n}\nfactored = left_factor(grammar)\nprint(factored)",
    "testCases": [
      {
        "input": "{'A': [['a', 'b'], ['a', 'c']]}",
        "expectedOutput": "A  a A', A'  b | c",
        "isHidden": false,
        "description": "Simple left factoring"
      },
      {
        "input": "{'S': [['if', 'expr', 'then', 'stmt'], ['if', 'expr', 'then', 'stmt', 'else', 'stmt']]}",
        "expectedOutput": "Factored if-then-else",
        "isHidden": true,
        "description": "Dangling else factoring"
      }
    ],
    "hints": [
      "Find productions with common prefixes",
      "Create a new nonterminal for the suffixes",
      "Replace A   |  with A  A', A'   | ",
      "May need to iterate until no more factoring is possible"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex12",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Left Recursion Elimination",
    "difficulty": 4,
    "description": "Eliminate left recursion from a grammar to make it suitable for top-down parsing.",
    "starterCode": "def eliminate_left_recursion(grammar):\n    \"\"\"\n    Eliminate immediate left recursion.\n    Transform A  A |  into A  A', A'  A' | \n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'T'], ['T']]\n}\ntransformed = eliminate_left_recursion(grammar)\nprint(transformed)",
    "solution": "def eliminate_left_recursion(grammar):\n    \"\"\"\n    Eliminate immediate left recursion.\n    Transform A  A |  into A  A', A'  A' | \n    \"\"\"\n    new_grammar = {}\n\n    for nonterminal in grammar:\n        productions = grammar[nonterminal]\n\n        # Separate into left-recursive and non-left-recursive\n        left_recursive = []\n        non_left_recursive = []\n\n        for prod in productions:\n            if prod and prod[0] == nonterminal:\n                # Left recursive: A  A\n                left_recursive.append(prod[1:])  # \n            else:\n                # Not left recursive: A  \n                non_left_recursive.append(prod)\n\n        if not left_recursive:\n            # No left recursion\n            new_grammar[nonterminal] = productions\n        else:\n            # Eliminate left recursion\n            new_nt = f\"{nonterminal}_prime\"\n\n            # A  A' for each \n            new_grammar[nonterminal] = []\n            for beta in non_left_recursive:\n                new_grammar[nonterminal].append(beta + [new_nt])\n\n            # A'  A' |  for each \n            new_grammar[new_nt] = []\n            for alpha in left_recursive:\n                new_grammar[new_nt].append(alpha + [new_nt])\n            new_grammar[new_nt].append([''])\n\n    return new_grammar\n\n# General left recursion elimination (handles indirect)\ndef eliminate_all_left_recursion(grammar):\n    \"\"\"\n    Eliminate all left recursion including indirect.\n    Uses the algorithm that orders nonterminals.\n    \"\"\"\n    nonterminals = list(grammar.keys())\n    new_grammar = dict(grammar)\n\n    # Order nonterminals A1, A2, ..., An\n    for i in range(len(nonterminals)):\n        Ai = nonterminals[i]\n\n        # Eliminate Ai  Aj  where j < i\n        for j in range(i):\n            Aj = nonterminals[j]\n            new_productions = []\n\n            for prod in new_grammar[Ai]:\n                if prod and prod[0] == Aj:\n                    # Replace Ai  Aj  with Ai  1  | 2  | ...\n                    # where Aj  1 | 2 | ...\n                    gamma = prod[1:]\n                    for aj_prod in new_grammar[Aj]:\n                        new_productions.append(aj_prod + gamma)\n                else:\n                    new_productions.append(prod)\n\n            new_grammar[Ai] = new_productions\n\n        # Eliminate immediate left recursion for Ai\n        new_grammar = {**new_grammar, **eliminate_left_recursion({Ai: new_grammar[Ai]})}\n\n    return new_grammar\n\n# Test\ngrammar = {\n    'E': [['E', '+', 'T'], ['T']]\n}\ntransformed = eliminate_left_recursion(grammar)\nprint(transformed)",
    "testCases": [
      {
        "input": "{'E': [['E', '+', 'T'], ['T']]}",
        "expectedOutput": "E  T E', E'  + T E' | ",
        "isHidden": false,
        "description": "Immediate left recursion"
      },
      {
        "input": "{'S': [['S', 'a'], ['b']]}",
        "expectedOutput": "S  b S', S'  a S' | ",
        "isHidden": true,
        "description": "Simple left recursion"
      }
    ],
    "hints": [
      "Separate productions into left-recursive (A  A) and others (A  )",
      "Create new nonterminal A'",
      "Replace with A  A' and A'  A' | ",
      "For indirect recursion, use substitution algorithm"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex13",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Operator Precedence Parser",
    "difficulty": 4,
    "description": "Implement an operator precedence parser using precedence relations between operators.",
    "starterCode": "def precedence_parse(tokens, precedence):\n    \"\"\"\n    Parse using operator precedence.\n    precedence: dict {operator: level}, higher = higher precedence\n    tokens: list of numbers and operators\n    Return: parse tree\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nprecedence = {'+': 1, '*': 2}\ntokens = [5, '+', 3, '*', 2]\ntree = precedence_parse(tokens, precedence)\nprint(tree)",
    "solution": "def precedence_parse(tokens, precedence):\n    \"\"\"\n    Parse using operator precedence.\n    Uses a simple precedence climbing algorithm.\n    \"\"\"\n    def parse_expression(min_precedence):\n        nonlocal pos\n\n        # Parse left operand (number)\n        if pos >= len(tokens) or not isinstance(tokens[pos], int):\n            raise SyntaxError(f\"Expected number at position {pos}\")\n\n        left = tokens[pos]\n        pos += 1\n\n        # Process operators\n        while pos < len(tokens) and tokens[pos] in precedence:\n            op = tokens[pos]\n            op_precedence = precedence[op]\n\n            if op_precedence < min_precedence:\n                break\n\n            pos += 1\n\n            # Parse right operand with higher precedence\n            right = parse_expression(op_precedence + 1)\n\n            # Build tree node\n            left = (op, left, right)\n\n        return left\n\n    pos = 0\n    result = parse_expression(0)\n    return result\n\n# Alternative: Using stack-based operator precedence\ndef precedence_parse_stack(tokens, precedence):\n    \"\"\"\n    Parse using stack-based operator precedence.\n    \"\"\"\n    operand_stack = []\n    operator_stack = []\n\n    def apply_operator():\n        if len(operand_stack) < 2:\n            raise SyntaxError(\"Not enough operands\")\n        right = operand_stack.pop()\n        left = operand_stack.pop()\n        op = operator_stack.pop()\n        operand_stack.append((op, left, right))\n\n    i = 0\n    while i < len(tokens):\n        token = tokens[i]\n\n        if isinstance(token, int):\n            # Operand\n            operand_stack.append(token)\n        elif token in precedence:\n            # Operator\n            while (operator_stack and\n                   operator_stack[-1] in precedence and\n                   precedence[operator_stack[-1]] >= precedence[token]):\n                apply_operator()\n\n            operator_stack.append(token)\n        else:\n            raise SyntaxError(f\"Unknown token: {token}\")\n\n        i += 1\n\n    # Apply remaining operators\n    while operator_stack:\n        apply_operator()\n\n    if len(operand_stack) != 1:\n        raise SyntaxError(\"Invalid expression\")\n\n    return operand_stack[0]\n\n# Test\nprecedence = {'+': 1, '*': 2}\ntokens = [5, '+', 3, '*', 2]\ntree = precedence_parse(tokens, precedence)\nprint(tree)",
    "testCases": [
      {
        "input": "[5, \"+\", 3]",
        "expectedOutput": "(\"+\", 5, 3)",
        "isHidden": false,
        "description": "Simple addition"
      },
      {
        "input": "[5, \"+\", 3, \"*\", 2]",
        "expectedOutput": "(\"+\", 5, (\"*\", 3, 2))",
        "isHidden": false,
        "description": "Precedence: multiplication before addition"
      },
      {
        "input": "[2, \"*\", 3, \"+\", 4, \"*\", 5]",
        "expectedOutput": "(\"+\", (\"*\", 2, 3), (\"*\", 4, 5))",
        "isHidden": true,
        "description": "Mixed precedence"
      }
    ],
    "hints": [
      "Use precedence levels to decide when to reduce",
      "Higher precedence binds tighter",
      "Can use precedence climbing or stack-based approach",
      "Build tree nodes as you reduce operators"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex14",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Abstract Syntax Tree (AST)",
    "difficulty": 3,
    "description": "Convert a parse tree into an Abstract Syntax Tree by removing unnecessary nodes.",
    "starterCode": "def parse_tree_to_ast(parse_tree):\n    \"\"\"\n    Convert parse tree to AST.\n    Remove intermediate nonterminals, keep only essential structure.\n    parse_tree: nested tuple structure\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\nparse_tree = ('E', ('T', ('num', 5)), ('+', '+'), ('E', ('T', ('num', 3))))\nast = parse_tree_to_ast(parse_tree)\nprint(ast)  # Should be simpler: ('+', 5, 3)",
    "solution": "def parse_tree_to_ast(parse_tree):\n    \"\"\"\n    Convert parse tree to AST.\n    Remove intermediate nonterminals, keep only essential structure.\n    \"\"\"\n    if not isinstance(parse_tree, tuple):\n        return parse_tree\n\n    symbol = parse_tree[0]\n\n    # If this is a leaf node with a value\n    if len(parse_tree) == 2 and not isinstance(parse_tree[1], tuple):\n        # Leaf node like ('num', 5)\n        return parse_tree[1]\n\n    # Process children\n    children = [parse_tree_to_ast(child) for child in parse_tree[1:]]\n\n    # Filter out None and non-essential nodes\n    children = [c for c in children if c is not None]\n\n    # Simplification rules\n    if symbol in ['E', 'T', 'F', 'E_prime', 'T_prime']:\n        # Intermediate nonterminals\n        if len(children) == 1:\n            # Single child - return it directly\n            return children[0]\n        elif len(children) == 3 and children[1] in ['+', '-', '*', '/']:\n            # Binary operation: left op right\n            return (children[1], children[0], children[2])\n        elif len(children) == 2:\n            # Could be unary or other structure\n            if children[0] in ['+', '-', '*', '/']:\n                # Operator followed by operand\n                return (children[0], children[1])\n            else:\n                return children[1]\n\n    # Operator nodes\n    if symbol in ['+', '-', '*', '/', 'PLUS', 'MINUS', 'MULTIPLY', 'DIVIDE']:\n        return symbol\n\n    # Default: return simplified structure\n    if len(children) == 1:\n        return children[0]\n    else:\n        return (symbol, *children)\n\n# More sophisticated version\nclass ASTNode:\n    def __init__(self, type, value=None, children=None):\n        self.type = type\n        self.value = value\n        self.children = children or []\n\n    def __repr__(self):\n        if self.value is not None:\n            return f\"AST({self.type}={self.value})\"\n        elif self.children:\n            children_str = \", \".join(repr(c) for c in self.children)\n            return f\"AST({self.type}: {children_str})\"\n        else:\n            return f\"AST({self.type})\"\n\ndef parse_tree_to_ast_nodes(parse_tree):\n    \"\"\"\n    Convert to AST using ASTNode objects.\n    \"\"\"\n    if not isinstance(parse_tree, tuple):\n        return ASTNode('literal', value=parse_tree)\n\n    symbol = parse_tree[0]\n\n    # Terminal with value\n    if len(parse_tree) == 2 and not isinstance(parse_tree[1], tuple):\n        if symbol in ['num', 'NUMBER']:\n            return ASTNode('number', value=parse_tree[1])\n        elif symbol in ['id', 'IDENTIFIER']:\n            return ASTNode('identifier', value=parse_tree[1])\n        else:\n            return ASTNode(symbol, value=parse_tree[1])\n\n    # Process children\n    children = [parse_tree_to_ast_nodes(child) for child in parse_tree[1:]]\n\n    # Simplification\n    if symbol in ['E', 'T', 'F', 'E_prime', 'T_prime']:\n        # Look for binary operation pattern\n        if len(children) == 3:\n            # Assume: left op right\n            op = children[1]\n            if hasattr(op, 'value') and op.value in ['+', '-', '*', '/']:\n                return ASTNode('binop', value=op.value, children=[children[0], children[2]])\n\n        # Single child passthrough\n        if len(children) == 1:\n            return children[0]\n\n    return ASTNode(symbol, children=children)\n\n# Test\nparse_tree = ('E', ('T', ('num', 5)), ('+', '+'), ('E', ('T', ('num', 3))))\nast = parse_tree_to_ast(parse_tree)\nprint(ast)",
    "testCases": [
      {
        "input": "('num', 5)",
        "expectedOutput": "5",
        "isHidden": false,
        "description": "Leaf node"
      },
      {
        "input": "('E', ('T', ('num', 5)), ('+', '+'), ('E', ('T', ('num', 3))))",
        "expectedOutput": "('+', 5, 3)",
        "isHidden": false,
        "description": "Binary operation"
      },
      {
        "input": "complex_parse_tree",
        "expectedOutput": "Simplified AST",
        "isHidden": true,
        "description": "Nested expression"
      }
    ],
    "hints": [
      "AST omits syntactic details like intermediate nonterminals",
      "Keep only semantically significant nodes",
      "Operators become parent nodes with operand children",
      "Literals become leaf nodes with values",
      "Remove chain productions (A  B where B is the only child)"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex15",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Error Recovery in Parsing",
    "difficulty": 4,
    "description": "Implement panic mode error recovery in a recursive descent parser.",
    "starterCode": "class Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n        self.errors = []\n\n    def parse_with_recovery(self, sync_tokens):\n        \"\"\"\n        Parse with error recovery.\n        sync_tokens: tokens to synchronize on after error\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\ntokens = [('NUMBER', 5), ('ERROR', '!'), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\nresult = parser.parse_with_recovery(['PLUS', 'SEMICOLON'])\nprint(f\"Errors: {parser.errors}\")",
    "solution": "class Parser:\n    def __init__(self, tokens):\n        self.tokens = tokens\n        self.pos = 0\n        self.errors = []\n\n    def peek(self):\n        return self.tokens[self.pos] if self.pos < len(self.tokens) else None\n\n    def consume(self, expected_type):\n        token = self.peek()\n        if not token:\n            self.errors.append(f\"Unexpected end of input, expected {expected_type}\")\n            raise SyntaxError(\"EOF\")\n\n        if token[0] != expected_type:\n            self.errors.append(f\"Expected {expected_type}, got {token[0]} at position {self.pos}\")\n            raise SyntaxError(f\"Token mismatch\")\n\n        self.pos += 1\n        return token\n\n    def sync(self, sync_tokens):\n        \"\"\"Skip tokens until we find a synchronization token\"\"\"\n        while self.peek():\n            if self.peek()[0] in sync_tokens:\n                break\n            self.pos += 1\n\n    def parse_with_recovery(self, sync_tokens):\n        \"\"\"\n        Parse with error recovery.\n        sync_tokens: tokens to synchronize on after error\n        \"\"\"\n        result = []\n\n        while self.pos < len(self.tokens):\n            try:\n                node = self.parse_expression()\n                result.append(node)\n\n                # Check for statement terminator\n                if self.peek() and self.peek()[0] == 'SEMICOLON':\n                    self.consume('SEMICOLON')\n\n            except SyntaxError as e:\n                # Error recovery: sync to next safe point\n                self.sync(sync_tokens)\n\n                # Skip the sync token\n                if self.peek() and self.peek()[0] in sync_tokens:\n                    self.pos += 1\n\n        return result\n\n    def parse_expression(self):\n        \"\"\"E  T + E | T\"\"\"\n        left = self.parse_term()\n\n        if self.peek() and self.peek()[0] == 'PLUS':\n            self.consume('PLUS')\n            right = self.parse_expression()\n            return ('ADD', left, right)\n\n        return left\n\n    def parse_term(self):\n        \"\"\"T  num\"\"\"\n        token = self.consume('NUMBER')\n        return ('NUM', token[1])\n\n# More sophisticated error recovery\nclass RobustParser(Parser):\n    def parse_expression_robust(self):\n        \"\"\"Parse with local error recovery\"\"\"\n        try:\n            return self.parse_expression()\n        except SyntaxError:\n            # Try to recover by assuming a number\n            self.errors.append(f\"Recovering by inserting default value at {self.pos}\")\n            return ('NUM', 0)\n\n    def parse_term_robust(self):\n        \"\"\"Parse term with error recovery\"\"\"\n        token = self.peek()\n\n        if not token:\n            raise SyntaxError(\"EOF\")\n\n        if token[0] == 'NUMBER':\n            self.consume('NUMBER')\n            return ('NUM', token[1])\n        else:\n            # Error: expected number\n            self.errors.append(f\"Expected NUMBER, got {token[0]} at {self.pos}\")\n\n            # Skip this token and try to continue\n            self.pos += 1\n\n            # Try next token\n            if self.peek() and self.peek()[0] == 'NUMBER':\n                return self.parse_term_robust()\n            else:\n                # Give up and return error node\n                return ('ERROR', None)\n\n# Test\ntokens = [('NUMBER', 5), ('ERROR', '!'), ('PLUS', '+'), ('NUMBER', 3)]\nparser = Parser(tokens)\nresult = parser.parse_with_recovery(['PLUS', 'SEMICOLON'])\nprint(f\"Errors: {parser.errors}\")\nprint(f\"Result: {result}\")",
    "testCases": [
      {
        "input": "valid_tokens",
        "expectedOutput": "No errors",
        "isHidden": false,
        "description": "Valid input"
      },
      {
        "input": "tokens_with_error",
        "expectedOutput": "Errors reported, parsing continues",
        "isHidden": false,
        "description": "Error recovery"
      },
      {
        "input": "multiple_errors",
        "expectedOutput": "Multiple errors detected",
        "isHidden": true,
        "description": "Multiple error recovery"
      }
    ],
    "hints": [
      "Catch syntax errors instead of aborting",
      "Skip tokens until you find a synchronization point",
      "Common sync tokens: semicolon, closing brace, keywords",
      "Report errors but continue parsing",
      "May insert/delete tokens to recover"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t2-ex16",
    "subjectId": "cs304",
    "topicId": "cs304-topic-2",
    "title": "Earley Parser Implementation",
    "difficulty": 5,
    "description": "Implement a simplified Earley parser that can handle any context-free grammar.",
    "starterCode": "def earley_parse(grammar, start_symbol, tokens):\n    \"\"\"\n    Parse using Earley algorithm.\n    grammar: dict {nonterminal: [[production], ...]}\n    Returns: True if tokens are accepted, False otherwise\n    \"\"\"\n    # Your code here\n    pass\n\n# Test\ngrammar = {\n    'S': [['A', 'B']],\n    'A': [['a'], []],  # A can be epsilon\n    'B': [['b']]\n}\nprint(earley_parse(grammar, 'S', ['a', 'b']))  # True\nprint(earley_parse(grammar, 'S', ['b']))       # True",
    "solution": "def earley_parse(grammar, start_symbol, tokens):\n    \"\"\"\n    Parse using Earley algorithm.\n    Handles any CFG including ambiguous and left-recursive grammars.\n    \"\"\"\n    class EarleyItem:\n        def __init__(self, nonterminal, production, dot, start_pos):\n            self.nonterminal = nonterminal\n            self.production = production\n            self.dot = dot\n            self.start_pos = start_pos\n\n        def __eq__(self, other):\n            return (self.nonterminal == other.nonterminal and\n                    self.production == other.production and\n                    self.dot == other.dot and\n                    self.start_pos == other.start_pos)\n\n        def __hash__(self):\n            return hash((self.nonterminal, self.production, self.dot, self.start_pos))\n\n        def __repr__(self):\n            prod_str = list(self.production)\n            prod_str.insert(self.dot, '')\n            return f\"{self.nonterminal}  {' '.join(prod_str)} ({self.start_pos})\"\n\n        def next_symbol(self):\n            return self.production[self.dot] if self.dot < len(self.production) else None\n\n        def is_complete(self):\n            return self.dot >= len(self.production)\n\n    # Initialize chart\n    chart = [set() for _ in range(len(tokens) + 1)]\n\n    # Add start rule: S'  S\n    start_item = EarleyItem(start_symbol + \"'\", (start_symbol,), 0, 0)\n    chart[0].add(start_item)\n\n    # Process each position\n    for i in range(len(tokens) + 1):\n        changed = True\n        while changed:\n            changed = False\n            current_items = list(chart[i])\n\n            for item in current_items:\n                if item.is_complete():\n                    # Completer\n                    for earlier_item in chart[item.start_pos]:\n                        if (earlier_item.next_symbol() == item.nonterminal and\n                            not earlier_item.is_complete()):\n                            new_item = EarleyItem(\n                                earlier_item.nonterminal,\n                                earlier_item.production,\n                                earlier_item.dot + 1,\n                                earlier_item.start_pos\n                            )\n                            if new_item not in chart[i]:\n                                chart[i].add(new_item)\n                                changed = True\n\n                else:\n                    next_sym = item.next_symbol()\n\n                    if next_sym in grammar:\n                        # Predictor\n                        for production in grammar[next_sym]:\n                            new_item = EarleyItem(\n                                next_sym,\n                                tuple(production) if production else (),\n                                0,\n                                i\n                            )\n                            if new_item not in chart[i]:\n                                chart[i].add(new_item)\n                                changed = True\n\n                    elif i < len(tokens) and next_sym == tokens[i]:\n                        # Scanner\n                        new_item = EarleyItem(\n                            item.nonterminal,\n                            item.production,\n                            item.dot + 1,\n                            item.start_pos\n                        )\n                        if new_item not in chart[i + 1]:\n                            chart[i + 1].add(new_item)\n\n    # Check if parse succeeded\n    for item in chart[len(tokens)]:\n        if (item.nonterminal == start_symbol + \"'\" and\n            item.is_complete() and\n            item.start_pos == 0):\n            return True\n\n    return False\n\n# Test\ngrammar = {\n    'S': [['A', 'B']],\n    'A': [['a'], []],  # A can be epsilon\n    'B': [['b']]\n}\nprint(earley_parse(grammar, 'S', ['a', 'b']))  # True\nprint(earley_parse(grammar, 'S', ['b']))       # True\nprint(earley_parse(grammar, 'S', ['a']))       # False",
    "testCases": [
      {
        "input": "['a', 'b']",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Valid input with both symbols"
      },
      {
        "input": "['b']",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Valid input with epsilon production"
      },
      {
        "input": "['a']",
        "expectedOutput": "False",
        "isHidden": true,
        "description": "Invalid input"
      }
    ],
    "hints": [
      "Earley parser uses dynamic programming with chart parsing",
      "Three operations: Predictor (add items for nonterminals), Scanner (match terminals), Completer (finish items)",
      "Chart[i] contains all items at position i",
      "Item is (nonterminal, production, dot position, start position)",
      "Accepts if chart[n] contains S'  S starting at 0"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex01",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Simple Symbol Table",
    "difficulty": 1,
    "description": "Implement a basic symbol table that can insert, lookup, and delete variable symbols with their types.",
    "starterCode": "class SymbolTable:\n    def __init__(self):\n        \"\"\"Initialize an empty symbol table.\"\"\"\n        # Your code here\n        pass\n\n    def insert(self, name, symbol_type):\n        \"\"\"Insert a symbol with its type. Return True if successful.\"\"\"\n        # Your code here\n        pass\n\n    def lookup(self, name):\n        \"\"\"Look up a symbol. Return its type or None if not found.\"\"\"\n        # Your code here\n        pass\n\n    def delete(self, name):\n        \"\"\"Delete a symbol. Return True if successful.\"\"\"\n        # Your code here\n        pass\n\n# Test\nst = SymbolTable()\nst.insert('x', 'int')\nprint(st.lookup('x'))  # Should print 'int'",
    "solution": "class SymbolTable:\n    def __init__(self):\n        \"\"\"Initialize an empty symbol table.\"\"\"\n        self.table = {}\n\n    def insert(self, name, symbol_type):\n        \"\"\"Insert a symbol with its type. Return True if successful.\"\"\"\n        if name in self.table:\n            return False  # Symbol already exists\n        self.table[name] = symbol_type\n        return True\n\n    def lookup(self, name):\n        \"\"\"Look up a symbol. Return its type or None if not found.\"\"\"\n        return self.table.get(name, None)\n\n    def delete(self, name):\n        \"\"\"Delete a symbol. Return True if successful.\"\"\"\n        if name in self.table:\n            del self.table[name]\n            return True\n        return False\n\n# Test\nst = SymbolTable()\nst.insert('x', 'int')\nprint(st.lookup('x'))",
    "testCases": [
      {
        "input": "insert and lookup",
        "expectedOutput": "int",
        "isHidden": false,
        "description": "Insert and retrieve symbol"
      },
      {
        "input": "lookup nonexistent",
        "expectedOutput": "None",
        "isHidden": false,
        "description": "Lookup returns None for missing symbol"
      },
      {
        "input": "delete",
        "expectedOutput": "True",
        "isHidden": true,
        "description": "Delete existing symbol"
      }
    ],
    "hints": [
      "Use a dictionary to store name -> type mappings",
      "Check if a symbol exists before operations",
      "Return None for lookups of non-existent symbols",
      "Return boolean values to indicate success/failure"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex02",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Scoped Symbol Table",
    "difficulty": 2,
    "description": "Implement a symbol table with nested scopes using a stack of dictionaries. Support entering/exiting scopes.",
    "starterCode": "class ScopedSymbolTable:\n    def __init__(self):\n        \"\"\"Initialize with global scope.\"\"\"\n        self.scopes = [{}]  # Stack of scopes\n\n    def enter_scope(self):\n        \"\"\"Enter a new nested scope.\"\"\"\n        # Your code here\n        pass\n\n    def exit_scope(self):\n        \"\"\"Exit current scope.\"\"\"\n        # Your code here\n        pass\n\n    def insert(self, name, symbol_type):\n        \"\"\"Insert symbol in current scope.\"\"\"\n        # Your code here\n        pass\n\n    def lookup(self, name):\n        \"\"\"Look up symbol from current scope outward.\"\"\"\n        # Your code here\n        pass\n\n# Test\nst = ScopedSymbolTable()\nst.insert('x', 'int')\nst.enter_scope()\nst.insert('y', 'float')\nprint(st.lookup('x'))  # Should find 'int' from outer scope",
    "solution": "class ScopedSymbolTable:\n    def __init__(self):\n        \"\"\"Initialize with global scope.\"\"\"\n        self.scopes = [{}]  # Stack of scopes\n\n    def enter_scope(self):\n        \"\"\"Enter a new nested scope.\"\"\"\n        self.scopes.append({})\n\n    def exit_scope(self):\n        \"\"\"Exit current scope.\"\"\"\n        if len(self.scopes) > 1:\n            self.scopes.pop()\n\n    def insert(self, name, symbol_type):\n        \"\"\"Insert symbol in current scope.\"\"\"\n        self.scopes[-1][name] = symbol_type\n\n    def lookup(self, name):\n        \"\"\"Look up symbol from current scope outward.\"\"\"\n        # Search from innermost to outermost scope\n        for scope in reversed(self.scopes):\n            if name in scope:\n                return scope[name]\n        return None\n\n# Test\nst = ScopedSymbolTable()\nst.insert('x', 'int')\nst.enter_scope()\nst.insert('y', 'float')\nprint(st.lookup('x'))",
    "testCases": [
      {
        "input": "outer scope lookup",
        "expectedOutput": "int",
        "isHidden": false,
        "description": "Find variable from outer scope"
      },
      {
        "input": "inner scope lookup",
        "expectedOutput": "float",
        "isHidden": false,
        "description": "Find variable in current scope"
      },
      {
        "input": "after exit scope",
        "expectedOutput": "None",
        "isHidden": true,
        "description": "Variable not visible after exiting scope"
      }
    ],
    "hints": [
      "Use a list of dictionaries as a stack",
      "Push a new dictionary when entering a scope",
      "Pop when exiting a scope",
      "Search from innermost to outermost scope for lookups"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex03",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Type Compatibility Checker",
    "difficulty": 2,
    "description": "Implement type checking for binary operations, ensuring operands have compatible types.",
    "starterCode": "class TypeChecker:\n    def __init__(self):\n        # Define compatible types for operations\n        self.compatible_ops = {\n            '+': [('int', 'int', 'int'), ('float', 'float', 'float'),\n                  ('string', 'string', 'string')],\n            '*': [('int', 'int', 'int'), ('float', 'float', 'float')],\n            '==': [('int', 'int', 'bool'), ('float', 'float', 'bool'),\n                   ('string', 'string', 'bool')]\n        }\n\n    def check_binary_op(self, op, left_type, right_type):\n        \"\"\"\n        Check if binary operation is type-compatible.\n        Returns result type or None if incompatible.\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\ntc = TypeChecker()\nprint(tc.check_binary_op('+', 'int', 'int'))  # Should return 'int'\nprint(tc.check_binary_op('+', 'int', 'string'))  # Should return None",
    "solution": "class TypeChecker:\n    def __init__(self):\n        # Define compatible types for operations\n        self.compatible_ops = {\n            '+': [('int', 'int', 'int'), ('float', 'float', 'float'),\n                  ('string', 'string', 'string')],\n            '*': [('int', 'int', 'int'), ('float', 'float', 'float')],\n            '==': [('int', 'int', 'bool'), ('float', 'float', 'bool'),\n                   ('string', 'string', 'bool')]\n        }\n\n    def check_binary_op(self, op, left_type, right_type):\n        \"\"\"\n        Check if binary operation is type-compatible.\n        Returns result type or None if incompatible.\n        \"\"\"\n        if op not in self.compatible_ops:\n            return None\n\n        for left, right, result in self.compatible_ops[op]:\n            if left_type == left and right_type == right:\n                return result\n\n        return None\n\n# Test\ntc = TypeChecker()\nprint(tc.check_binary_op('+', 'int', 'int'))\nprint(tc.check_binary_op('+', 'int', 'string'))",
    "testCases": [
      {
        "input": "'+', 'int', 'int'",
        "expectedOutput": "int",
        "isHidden": false,
        "description": "Integer addition"
      },
      {
        "input": "'+', 'int', 'string'",
        "expectedOutput": "None",
        "isHidden": false,
        "description": "Incompatible types"
      },
      {
        "input": "'==', 'float', 'float'",
        "expectedOutput": "bool",
        "isHidden": true,
        "description": "Comparison returns bool"
      }
    ],
    "hints": [
      "Look up the operator in the compatibility table",
      "Check if left and right types match any rule",
      "Return the result type from the matching rule",
      "Return None if no matching rule found"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex04",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "AST Type Annotation",
    "difficulty": 3,
    "description": "Annotate an abstract syntax tree with type information by traversing and checking types.",
    "starterCode": "class TypeAnnotator:\n    def __init__(self, symbol_table):\n        self.symbol_table = symbol_table\n\n    def annotate(self, node):\n        \"\"\"\n        Annotate AST node with type information.\n        node: dict with 'kind', 'value', 'left', 'right', etc.\n        Returns: type of the node or None if type error.\n        \"\"\"\n        # Your code here\n        pass\n\n# Example node structure:\n# {'kind': 'BinaryOp', 'op': '+', 'left': {...}, 'right': {...}}\n# {'kind': 'Variable', 'name': 'x'}\n# {'kind': 'Literal', 'type': 'int', 'value': 5}\n\n# Test\nst = {'x': 'int', 'y': 'int'}\nannotator = TypeAnnotator(st)\nnode = {'kind': 'BinaryOp', 'op': '+',\n        'left': {'kind': 'Variable', 'name': 'x'},\n        'right': {'kind': 'Literal', 'type': 'int', 'value': 5}}\nprint(annotator.annotate(node))  # Should return 'int'",
    "solution": "class TypeAnnotator:\n    def __init__(self, symbol_table):\n        self.symbol_table = symbol_table\n        self.type_rules = {\n            '+': [('int', 'int', 'int'), ('float', 'float', 'float')],\n            '*': [('int', 'int', 'int'), ('float', 'float', 'float')],\n            '-': [('int', 'int', 'int'), ('float', 'float', 'float')]\n        }\n\n    def annotate(self, node):\n        \"\"\"\n        Annotate AST node with type information.\n        Returns: type of the node or None if type error.\n        \"\"\"\n        kind = node['kind']\n\n        if kind == 'Literal':\n            node['computed_type'] = node['type']\n            return node['type']\n\n        elif kind == 'Variable':\n            var_type = self.symbol_table.get(node['name'])\n            if var_type is None:\n                return None  # Undefined variable\n            node['computed_type'] = var_type\n            return var_type\n\n        elif kind == 'BinaryOp':\n            left_type = self.annotate(node['left'])\n            right_type = self.annotate(node['right'])\n\n            if left_type is None or right_type is None:\n                return None\n\n            # Check type compatibility\n            op = node['op']\n            if op in self.type_rules:\n                for left, right, result in self.type_rules[op]:\n                    if left_type == left and right_type == right:\n                        node['computed_type'] = result\n                        return result\n\n            return None\n\n        return None\n\n# Test\nst = {'x': 'int', 'y': 'int'}\nannotator = TypeAnnotator(st)\nnode = {'kind': 'BinaryOp', 'op': '+',\n        'left': {'kind': 'Variable', 'name': 'x'},\n        'right': {'kind': 'Literal', 'type': 'int', 'value': 5}}\nprint(annotator.annotate(node))",
    "testCases": [
      {
        "input": "int + int",
        "expectedOutput": "int",
        "isHidden": false,
        "description": "Binary operation with compatible types"
      },
      {
        "input": "undefined variable",
        "expectedOutput": "None",
        "isHidden": false,
        "description": "Type error for undefined variable"
      },
      {
        "input": "nested expression",
        "expectedOutput": "int",
        "isHidden": true,
        "description": "Nested binary operations"
      }
    ],
    "hints": [
      "Recursively annotate child nodes first",
      "For literals, return their declared type",
      "For variables, look up type in symbol table",
      "For binary ops, check type compatibility of operands"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex05",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Function Symbol Table",
    "difficulty": 3,
    "description": "Extend symbol table to handle function declarations with parameter types and return types.",
    "starterCode": "class FunctionSymbolTable:\n    def __init__(self):\n        self.functions = {}\n\n    def declare_function(self, name, param_types, return_type):\n        \"\"\"\n        Declare a function with parameter types and return type.\n        param_types: list of types\n        return_type: type\n        \"\"\"\n        # Your code here\n        pass\n\n    def lookup_function(self, name):\n        \"\"\"Return function signature (param_types, return_type) or None.\"\"\"\n        # Your code here\n        pass\n\n    def check_call(self, name, arg_types):\n        \"\"\"\n        Check if function call is valid.\n        Returns return type or None if invalid.\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\nfst = FunctionSymbolTable()\nfst.declare_function('add', ['int', 'int'], 'int')\nprint(fst.check_call('add', ['int', 'int']))  # Should return 'int'",
    "solution": "class FunctionSymbolTable:\n    def __init__(self):\n        self.functions = {}\n\n    def declare_function(self, name, param_types, return_type):\n        \"\"\"\n        Declare a function with parameter types and return type.\n        \"\"\"\n        self.functions[name] = {\n            'param_types': param_types,\n            'return_type': return_type\n        }\n\n    def lookup_function(self, name):\n        \"\"\"Return function signature (param_types, return_type) or None.\"\"\"\n        if name in self.functions:\n            sig = self.functions[name]\n            return (sig['param_types'], sig['return_type'])\n        return None\n\n    def check_call(self, name, arg_types):\n        \"\"\"\n        Check if function call is valid.\n        Returns return type or None if invalid.\n        \"\"\"\n        if name not in self.functions:\n            return None\n\n        func = self.functions[name]\n        param_types = func['param_types']\n\n        # Check argument count\n        if len(arg_types) != len(param_types):\n            return None\n\n        # Check each argument type\n        for arg_type, param_type in zip(arg_types, param_types):\n            if arg_type != param_type:\n                return None\n\n        return func['return_type']\n\n# Test\nfst = FunctionSymbolTable()\nfst.declare_function('add', ['int', 'int'], 'int')\nprint(fst.check_call('add', ['int', 'int']))",
    "testCases": [
      {
        "input": "valid call",
        "expectedOutput": "int",
        "isHidden": false,
        "description": "Function call with correct types"
      },
      {
        "input": "wrong arg count",
        "expectedOutput": "None",
        "isHidden": false,
        "description": "Too many or too few arguments"
      },
      {
        "input": "wrong arg types",
        "expectedOutput": "None",
        "isHidden": true,
        "description": "Argument type mismatch"
      }
    ],
    "hints": [
      "Store function signatures as (param_types, return_type)",
      "Check both argument count and types",
      "Return the function's return type if call is valid",
      "Return None for type errors or undefined functions"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex06",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Type Inference for Variables",
    "difficulty": 3,
    "description": "Implement simple type inference that deduces variable types from their usage.",
    "starterCode": "class TypeInference:\n    def __init__(self):\n        self.var_types = {}  # Inferred types\n\n    def infer_assignment(self, var_name, expr_type):\n        \"\"\"\n        Infer type for variable from assignment.\n        Returns True if consistent, False if conflict.\n        \"\"\"\n        # Your code here\n        pass\n\n    def get_type(self, var_name):\n        \"\"\"Get inferred type or None if not yet inferred.\"\"\"\n        # Your code here\n        pass\n\n# Test\nti = TypeInference()\nti.infer_assignment('x', 'int')\nti.infer_assignment('x', 'int')  # Consistent\nprint(ti.get_type('x'))  # Should be 'int'",
    "solution": "class TypeInference:\n    def __init__(self):\n        self.var_types = {}  # Inferred types\n\n    def infer_assignment(self, var_name, expr_type):\n        \"\"\"\n        Infer type for variable from assignment.\n        Returns True if consistent, False if conflict.\n        \"\"\"\n        if var_name in self.var_types:\n            # Check for consistency\n            if self.var_types[var_name] != expr_type:\n                return False  # Type conflict\n        else:\n            # Infer new type\n            self.var_types[var_name] = expr_type\n\n        return True\n\n    def get_type(self, var_name):\n        \"\"\"Get inferred type or None if not yet inferred.\"\"\"\n        return self.var_types.get(var_name, None)\n\n# Test\nti = TypeInference()\nti.infer_assignment('x', 'int')\nti.infer_assignment('x', 'int')\nprint(ti.get_type('x'))",
    "testCases": [
      {
        "input": "consistent types",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Same type assignments are consistent"
      },
      {
        "input": "type conflict",
        "expectedOutput": "False",
        "isHidden": false,
        "description": "Different types cause conflict"
      },
      {
        "input": "get inferred type",
        "expectedOutput": "int",
        "isHidden": true,
        "description": "Retrieve inferred type"
      }
    ],
    "hints": [
      "Track inferred types in a dictionary",
      "On first assignment, record the type",
      "On subsequent assignments, check consistency",
      "Return False if types conflict"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex07",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Semantic Error Detection",
    "difficulty": 2,
    "description": "Detect common semantic errors like undefined variables, type mismatches, and duplicate declarations.",
    "starterCode": "class SemanticAnalyzer:\n    def __init__(self):\n        self.symbols = {}\n        self.errors = []\n\n    def declare_variable(self, name, var_type):\n        \"\"\"Declare variable, detect duplicate declarations.\"\"\"\n        # Your code here\n        pass\n\n    def check_variable_use(self, name):\n        \"\"\"Check if variable is defined before use.\"\"\"\n        # Your code here\n        pass\n\n    def check_assignment(self, name, value_type):\n        \"\"\"Check type compatibility in assignment.\"\"\"\n        # Your code here\n        pass\n\n# Test\nsa = SemanticAnalyzer()\nsa.declare_variable('x', 'int')\nsa.check_assignment('x', 'string')  # Type mismatch\nprint(len(sa.errors))  # Should have at least one error",
    "solution": "class SemanticAnalyzer:\n    def __init__(self):\n        self.symbols = {}\n        self.errors = []\n\n    def declare_variable(self, name, var_type):\n        \"\"\"Declare variable, detect duplicate declarations.\"\"\"\n        if name in self.symbols:\n            self.errors.append(f\"Duplicate declaration of '{name}'\")\n            return False\n        self.symbols[name] = var_type\n        return True\n\n    def check_variable_use(self, name):\n        \"\"\"Check if variable is defined before use.\"\"\"\n        if name not in self.symbols:\n            self.errors.append(f\"Undefined variable '{name}'\")\n            return False\n        return True\n\n    def check_assignment(self, name, value_type):\n        \"\"\"Check type compatibility in assignment.\"\"\"\n        if name not in self.symbols:\n            self.errors.append(f\"Assignment to undefined variable '{name}'\")\n            return False\n\n        if self.symbols[name] != value_type:\n            self.errors.append(\n                f\"Type mismatch: cannot assign {value_type} to {self.symbols[name]}\"\n            )\n            return False\n\n        return True\n\n# Test\nsa = SemanticAnalyzer()\nsa.declare_variable('x', 'int')\nsa.check_assignment('x', 'string')\nprint(len(sa.errors))",
    "testCases": [
      {
        "input": "type mismatch",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Detect type mismatch error"
      },
      {
        "input": "undefined variable",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Detect undefined variable"
      },
      {
        "input": "duplicate declaration",
        "expectedOutput": "1",
        "isHidden": true,
        "description": "Detect duplicate declaration"
      }
    ],
    "hints": [
      "Maintain a list of errors found during analysis",
      "Check symbol table before allowing usage",
      "Compare types for assignment compatibility",
      "Add descriptive error messages to the errors list"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex08",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Constant Folding",
    "difficulty": 3,
    "description": "Implement constant folding optimization that evaluates constant expressions at compile time.",
    "starterCode": "class ConstantFolder:\n    def fold(self, node):\n        \"\"\"\n        Fold constant expressions in AST.\n        node: {'kind': 'BinaryOp'/'Literal', ...}\n        Returns: simplified node\n        \"\"\"\n        # Your code here\n        pass\n\n# Example:\n# {'kind': 'BinaryOp', 'op': '+',\n#  'left': {'kind': 'Literal', 'value': 2},\n#  'right': {'kind': 'Literal', 'value': 3}}\n# Should fold to: {'kind': 'Literal', 'value': 5}\n\n# Test\ncf = ConstantFolder()\nnode = {'kind': 'BinaryOp', 'op': '+',\n        'left': {'kind': 'Literal', 'value': 2},\n        'right': {'kind': 'Literal', 'value': 3}}\nresult = cf.fold(node)\nprint(result['value'] if result['kind'] == 'Literal' else 'not folded')",
    "solution": "class ConstantFolder:\n    def fold(self, node):\n        \"\"\"\n        Fold constant expressions in AST.\n        Returns: simplified node\n        \"\"\"\n        if node['kind'] == 'Literal':\n            return node\n\n        if node['kind'] == 'BinaryOp':\n            # Recursively fold children\n            left = self.fold(node['left'])\n            right = self.fold(node['right'])\n\n            # If both are literals, compute result\n            if left['kind'] == 'Literal' and right['kind'] == 'Literal':\n                op = node['op']\n                left_val = left['value']\n                right_val = right['value']\n\n                if op == '+':\n                    result = left_val + right_val\n                elif op == '-':\n                    result = left_val - right_val\n                elif op == '*':\n                    result = left_val * right_val\n                elif op == '/':\n                    if right_val != 0:\n                        result = left_val // right_val\n                    else:\n                        return node  # Can't fold division by zero\n                else:\n                    return node\n\n                return {'kind': 'Literal', 'value': result}\n\n            # Return node with folded children\n            return {\n                'kind': 'BinaryOp',\n                'op': node['op'],\n                'left': left,\n                'right': right\n            }\n\n        return node\n\n# Test\ncf = ConstantFolder()\nnode = {'kind': 'BinaryOp', 'op': '+',\n        'left': {'kind': 'Literal', 'value': 2},\n        'right': {'kind': 'Literal', 'value': 3}}\nresult = cf.fold(node)\nprint(result['value'] if result['kind'] == 'Literal' else 'not folded')",
    "testCases": [
      {
        "input": "2 + 3",
        "expectedOutput": "5",
        "isHidden": false,
        "description": "Fold simple addition"
      },
      {
        "input": "10 * 2",
        "expectedOutput": "20",
        "isHidden": false,
        "description": "Fold multiplication"
      },
      {
        "input": "nested: (2 + 3) * 4",
        "expectedOutput": "20",
        "isHidden": true,
        "description": "Fold nested expressions"
      }
    ],
    "hints": [
      "Recursively fold child expressions first",
      "If both operands are literals, compute the result",
      "Replace the BinaryOp node with a Literal node",
      "Handle all arithmetic operators"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex09",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Control Flow Analysis",
    "difficulty": 4,
    "description": "Detect unreachable code after return statements or in conditional branches.",
    "starterCode": "class ControlFlowAnalyzer:\n    def __init__(self):\n        self.warnings = []\n\n    def analyze_block(self, statements):\n        \"\"\"\n        Analyze a block of statements for unreachable code.\n        statements: list of {'kind': 'Return'/'If'/'Assignment', ...}\n        Returns: True if block definitely returns\n        \"\"\"\n        # Your code here\n        pass\n\n# Example statements:\n# {'kind': 'Return', 'value': ...}\n# {'kind': 'Assignment', 'var': 'x', 'value': ...}\n# {'kind': 'If', 'condition': ..., 'then': [...], 'else': [...]}\n\n# Test\ncfa = ControlFlowAnalyzer()\nstmts = [\n    {'kind': 'Return', 'value': 5},\n    {'kind': 'Assignment', 'var': 'x', 'value': 10}  # Unreachable\n]\ncfa.analyze_block(stmts)\nprint(len(cfa.warnings))  # Should detect unreachable code",
    "solution": "class ControlFlowAnalyzer:\n    def __init__(self):\n        self.warnings = []\n\n    def analyze_block(self, statements):\n        \"\"\"\n        Analyze a block of statements for unreachable code.\n        Returns: True if block definitely returns\n        \"\"\"\n        for i, stmt in enumerate(statements):\n            if stmt['kind'] == 'Return':\n                # Check if there are statements after return\n                if i < len(statements) - 1:\n                    self.warnings.append(\n                        f\"Unreachable code after return statement\"\n                    )\n                return True\n\n            elif stmt['kind'] == 'If':\n                # Analyze both branches\n                then_returns = self.analyze_block(stmt.get('then', []))\n                else_returns = self.analyze_block(stmt.get('else', []))\n\n                # If both branches return, the if statement returns\n                if then_returns and else_returns:\n                    if i < len(statements) - 1:\n                        self.warnings.append(\n                            f\"Unreachable code after if statement\"\n                        )\n                    return True\n\n        return False\n\n# Test\ncfa = ControlFlowAnalyzer()\nstmts = [\n    {'kind': 'Return', 'value': 5},\n    {'kind': 'Assignment', 'var': 'x', 'value': 10}\n]\ncfa.analyze_block(stmts)\nprint(len(cfa.warnings))",
    "testCases": [
      {
        "input": "code after return",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Detect unreachable code after return"
      },
      {
        "input": "both branches return",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Code after if with returns in both branches"
      },
      {
        "input": "no unreachable code",
        "expectedOutput": "0",
        "isHidden": true,
        "description": "Valid control flow"
      }
    ],
    "hints": [
      "Track whether each statement can return",
      "After a return statement, remaining statements are unreachable",
      "If both branches of an if return, code after is unreachable",
      "Recursively analyze nested blocks"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex10",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Type Casting Insertion",
    "difficulty": 3,
    "description": "Automatically insert type casts where needed to make expressions type-correct (e.g., int to float).",
    "starterCode": "class TypeCaster:\n    def __init__(self):\n        # Define valid casts\n        self.valid_casts = {\n            ('int', 'float'): True,\n            ('int', 'string'): True,\n            ('float', 'string'): True\n        }\n\n    def insert_cast(self, node, target_type):\n        \"\"\"\n        Insert cast node if needed.\n        Returns: node or cast node wrapping it\n        \"\"\"\n        # Your code here\n        pass\n\n    def can_cast(self, from_type, to_type):\n        \"\"\"Check if cast is valid.\"\"\"\n        # Your code here\n        pass\n\n# Test\ntc = TypeCaster()\nnode = {'kind': 'Literal', 'type': 'int', 'value': 5}\nresult = tc.insert_cast(node, 'float')\nprint(result['kind'])  # Should be 'Cast'",
    "solution": "class TypeCaster:\n    def __init__(self):\n        # Define valid casts\n        self.valid_casts = {\n            ('int', 'float'): True,\n            ('int', 'string'): True,\n            ('float', 'string'): True\n        }\n\n    def can_cast(self, from_type, to_type):\n        \"\"\"Check if cast is valid.\"\"\"\n        if from_type == to_type:\n            return True\n        return (from_type, to_type) in self.valid_casts\n\n    def insert_cast(self, node, target_type):\n        \"\"\"\n        Insert cast node if needed.\n        Returns: node or cast node wrapping it\n        \"\"\"\n        # Determine source type\n        if 'type' in node:\n            source_type = node['type']\n        elif 'computed_type' in node:\n            source_type = node['computed_type']\n        else:\n            return node  # Can't determine type\n\n        # No cast needed if types match\n        if source_type == target_type:\n            return node\n\n        # Check if cast is valid\n        if not self.can_cast(source_type, target_type):\n            return None  # Invalid cast\n\n        # Insert cast node\n        return {\n            'kind': 'Cast',\n            'from_type': source_type,\n            'to_type': target_type,\n            'expr': node,\n            'type': target_type\n        }\n\n# Test\ntc = TypeCaster()\nnode = {'kind': 'Literal', 'type': 'int', 'value': 5}\nresult = tc.insert_cast(node, 'float')\nprint(result['kind'])",
    "testCases": [
      {
        "input": "int to float",
        "expectedOutput": "Cast",
        "isHidden": false,
        "description": "Insert cast for int to float"
      },
      {
        "input": "same type",
        "expectedOutput": "Literal",
        "isHidden": false,
        "description": "No cast needed for same type"
      },
      {
        "input": "invalid cast",
        "expectedOutput": "None",
        "isHidden": true,
        "description": "Return None for invalid cast"
      }
    ],
    "hints": [
      "Check if source and target types are the same",
      "Consult valid_casts table for allowed conversions",
      "Wrap the expression in a Cast node",
      "Return None if cast is not valid"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex11",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Array Type Checking",
    "difficulty": 4,
    "description": "Implement type checking for array declarations, indexing, and assignments.",
    "starterCode": "class ArrayTypeChecker:\n    def __init__(self):\n        self.arrays = {}  # name -> (element_type, size)\n\n    def declare_array(self, name, element_type, size):\n        \"\"\"Declare an array with element type and size.\"\"\"\n        # Your code here\n        pass\n\n    def check_index(self, array_name, index_type):\n        \"\"\"\n        Check array indexing.\n        Returns element type or None if error.\n        \"\"\"\n        # Your code here\n        pass\n\n    def check_element_assignment(self, array_name, value_type):\n        \"\"\"\n        Check assignment to array element.\n        Returns True if valid.\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\natc = ArrayTypeChecker()\natc.declare_array('arr', 'int', 10)\nprint(atc.check_index('arr', 'int'))  # Should return 'int'",
    "solution": "class ArrayTypeChecker:\n    def __init__(self):\n        self.arrays = {}  # name -> (element_type, size)\n\n    def declare_array(self, name, element_type, size):\n        \"\"\"Declare an array with element type and size.\"\"\"\n        self.arrays[name] = {\n            'element_type': element_type,\n            'size': size\n        }\n\n    def check_index(self, array_name, index_type):\n        \"\"\"\n        Check array indexing.\n        Returns element type or None if error.\n        \"\"\"\n        if array_name not in self.arrays:\n            return None  # Array not declared\n\n        if index_type != 'int':\n            return None  # Index must be int\n\n        return self.arrays[array_name]['element_type']\n\n    def check_element_assignment(self, array_name, value_type):\n        \"\"\"\n        Check assignment to array element.\n        Returns True if valid.\n        \"\"\"\n        if array_name not in self.arrays:\n            return False\n\n        element_type = self.arrays[array_name]['element_type']\n        return value_type == element_type\n\n# Test\natc = ArrayTypeChecker()\natc.declare_array('arr', 'int', 10)\nprint(atc.check_index('arr', 'int'))",
    "testCases": [
      {
        "input": "valid indexing",
        "expectedOutput": "int",
        "isHidden": false,
        "description": "Array indexing with int returns element type"
      },
      {
        "input": "non-int index",
        "expectedOutput": "None",
        "isHidden": false,
        "description": "Reject non-integer index"
      },
      {
        "input": "assignment",
        "expectedOutput": "True",
        "isHidden": true,
        "description": "Valid element assignment"
      }
    ],
    "hints": [
      "Store array metadata: element type and size",
      "Index type must be int",
      "Return element type for valid indexing",
      "Check type compatibility for assignments"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex12",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Method Resolution",
    "difficulty": 4,
    "description": "Implement method lookup in a class hierarchy, handling inheritance and method overriding.",
    "starterCode": "class ClassHierarchy:\n    def __init__(self):\n        self.classes = {}  # class_name -> {'parent': ..., 'methods': {...}}\n\n    def declare_class(self, name, parent=None):\n        \"\"\"Declare a class with optional parent.\"\"\"\n        # Your code here\n        pass\n\n    def add_method(self, class_name, method_name, signature):\n        \"\"\"Add a method to a class.\"\"\"\n        # Your code here\n        pass\n\n    def resolve_method(self, class_name, method_name):\n        \"\"\"\n        Resolve method by searching class and ancestors.\n        Returns method signature or None.\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\nch = ClassHierarchy()\nch.declare_class('Animal')\nch.add_method('Animal', 'speak', (['self'], 'void'))\nch.declare_class('Dog', parent='Animal')\nprint(ch.resolve_method('Dog', 'speak'))  # Should find in parent",
    "solution": "class ClassHierarchy:\n    def __init__(self):\n        self.classes = {}  # class_name -> {'parent': ..., 'methods': {...}}\n\n    def declare_class(self, name, parent=None):\n        \"\"\"Declare a class with optional parent.\"\"\"\n        self.classes[name] = {\n            'parent': parent,\n            'methods': {}\n        }\n\n    def add_method(self, class_name, method_name, signature):\n        \"\"\"Add a method to a class.\"\"\"\n        if class_name in self.classes:\n            self.classes[class_name]['methods'][method_name] = signature\n\n    def resolve_method(self, class_name, method_name):\n        \"\"\"\n        Resolve method by searching class and ancestors.\n        Returns method signature or None.\n        \"\"\"\n        # Search current class\n        if class_name not in self.classes:\n            return None\n\n        current_class = self.classes[class_name]\n\n        # Check if method exists in current class\n        if method_name in current_class['methods']:\n            return current_class['methods'][method_name]\n\n        # Search parent class\n        parent = current_class['parent']\n        if parent:\n            return self.resolve_method(parent, method_name)\n\n        return None\n\n# Test\nch = ClassHierarchy()\nch.declare_class('Animal')\nch.add_method('Animal', 'speak', (['self'], 'void'))\nch.declare_class('Dog', parent='Animal')\nprint(ch.resolve_method('Dog', 'speak'))",
    "testCases": [
      {
        "input": "method in class",
        "expectedOutput": "signature",
        "isHidden": false,
        "description": "Find method in same class"
      },
      {
        "input": "inherited method",
        "expectedOutput": "signature",
        "isHidden": false,
        "description": "Find method in parent class"
      },
      {
        "input": "undefined method",
        "expectedOutput": "None",
        "isHidden": true,
        "description": "Method not found in hierarchy"
      }
    ],
    "hints": [
      "Search for method in current class first",
      "If not found, recursively search parent class",
      "Store parent class name for each class",
      "Methods can override parent methods"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex13",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Dead Code Elimination",
    "difficulty": 3,
    "description": "Identify and remove dead code (unused variables and unreachable statements).",
    "starterCode": "class DeadCodeEliminator:\n    def __init__(self):\n        self.used_vars = set()\n\n    def mark_used_variables(self, node):\n        \"\"\"Mark all variables used in an expression.\"\"\"\n        # Your code here\n        pass\n\n    def eliminate_unused_assignments(self, statements):\n        \"\"\"\n        Remove assignments to variables that are never used.\n        Returns: filtered list of statements\n        \"\"\"\n        # Your code here\n        pass\n\n# Example statement:\n# {'kind': 'Assignment', 'var': 'x', 'expr': ...}\n# {'kind': 'Return', 'expr': ...}\n\n# Test\ndce = DeadCodeEliminator()\nstmts = [\n    {'kind': 'Assignment', 'var': 'x', 'expr': {'kind': 'Literal', 'value': 5}},\n    {'kind': 'Assignment', 'var': 'y', 'expr': {'kind': 'Literal', 'value': 10}},\n    {'kind': 'Return', 'expr': {'kind': 'Variable', 'name': 'y'}}\n]\nresult = dce.eliminate_unused_assignments(stmts)\nprint(len(result))  # Should be 2 (x assignment removed)",
    "solution": "class DeadCodeEliminator:\n    def __init__(self):\n        self.used_vars = set()\n\n    def mark_used_variables(self, node):\n        \"\"\"Mark all variables used in an expression.\"\"\"\n        if not node:\n            return\n\n        if isinstance(node, dict):\n            if node.get('kind') == 'Variable':\n                self.used_vars.add(node['name'])\n\n            # Recursively mark in sub-nodes\n            for key, value in node.items():\n                if key in ['left', 'right', 'expr', 'condition', 'value']:\n                    self.mark_used_variables(value)\n                elif key == 'then' or key == 'else':\n                    for stmt in value:\n                        self.mark_used_variables(stmt)\n\n    def eliminate_unused_assignments(self, statements):\n        \"\"\"\n        Remove assignments to variables that are never used.\n        Returns: filtered list of statements\n        \"\"\"\n        # First pass: find all used variables\n        self.used_vars = set()\n        for stmt in statements:\n            if stmt['kind'] != 'Assignment':\n                # Mark variables used in non-assignment statements\n                self.mark_used_variables(stmt)\n\n        # Second pass: filter out unused assignments\n        result = []\n        for stmt in statements:\n            if stmt['kind'] == 'Assignment':\n                # Keep if variable is used\n                if stmt['var'] in self.used_vars:\n                    # Also mark variables used in RHS\n                    self.mark_used_variables(stmt['expr'])\n                    result.append(stmt)\n            else:\n                result.append(stmt)\n\n        return result\n\n# Test\ndce = DeadCodeEliminator()\nstmts = [\n    {'kind': 'Assignment', 'var': 'x', 'expr': {'kind': 'Literal', 'value': 5}},\n    {'kind': 'Assignment', 'var': 'y', 'expr': {'kind': 'Literal', 'value': 10}},\n    {'kind': 'Return', 'expr': {'kind': 'Variable', 'name': 'y'}}\n]\nresult = dce.eliminate_unused_assignments(stmts)\nprint(len(result))",
    "testCases": [
      {
        "input": "unused variable",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Remove assignment to unused variable"
      },
      {
        "input": "all used",
        "expectedOutput": "3",
        "isHidden": false,
        "description": "Keep all statements when all are used"
      },
      {
        "input": "chain dependency",
        "expectedOutput": "3",
        "isHidden": true,
        "description": "Keep assignments that contribute to used variables"
      }
    ],
    "hints": [
      "Use two passes: first to find used variables, second to filter",
      "Mark variables used in return/print statements",
      "Keep assignments only if the variable is later used",
      "Recursively search expressions for variable usage"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex14",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Return Type Checking",
    "difficulty": 3,
    "description": "Verify that all code paths in a function return values of the correct type.",
    "starterCode": "class ReturnChecker:\n    def __init__(self, expected_return_type):\n        self.expected_type = expected_return_type\n        self.errors = []\n\n    def check_return_type(self, statements):\n        \"\"\"\n        Check that all return statements have correct type.\n        Returns: True if all paths return correct type\n        \"\"\"\n        # Your code here\n        pass\n\n    def check_all_paths_return(self, statements):\n        \"\"\"\n        Check that all code paths return a value.\n        Returns: True if all paths return\n        \"\"\"\n        # Your code here\n        pass\n\n# Example:\n# statements = [\n#     {'kind': 'If', 'condition': ..., 'then': [...], 'else': [...]},\n#     {'kind': 'Return', 'type': 'int', 'value': ...}\n# ]\n\n# Test\nrc = ReturnChecker('int')\nstmts = [{'kind': 'Return', 'type': 'string', 'value': 'hello'}]\nrc.check_return_type(stmts)\nprint(len(rc.errors))  # Should detect type mismatch",
    "solution": "class ReturnChecker:\n    def __init__(self, expected_return_type):\n        self.expected_type = expected_return_type\n        self.errors = []\n\n    def check_return_type(self, statements):\n        \"\"\"\n        Check that all return statements have correct type.\n        Returns: True if all paths return correct type\n        \"\"\"\n        has_return = False\n\n        for stmt in statements:\n            if stmt['kind'] == 'Return':\n                has_return = True\n                return_type = stmt.get('type')\n\n                if return_type != self.expected_type:\n                    self.errors.append(\n                        f\"Type mismatch: expected {self.expected_type}, \"\n                        f\"got {return_type}\"\n                    )\n\n            elif stmt['kind'] == 'If':\n                # Recursively check both branches\n                self.check_return_type(stmt.get('then', []))\n                self.check_return_type(stmt.get('else', []))\n\n        return len(self.errors) == 0\n\n    def check_all_paths_return(self, statements):\n        \"\"\"\n        Check that all code paths return a value.\n        Returns: True if all paths return\n        \"\"\"\n        for stmt in statements:\n            if stmt['kind'] == 'Return':\n                return True\n\n            elif stmt['kind'] == 'If':\n                then_returns = self.check_all_paths_return(stmt.get('then', []))\n                else_returns = self.check_all_paths_return(stmt.get('else', []))\n\n                # Both branches must return\n                if then_returns and else_returns:\n                    return True\n\n        return False\n\n# Test\nrc = ReturnChecker('int')\nstmts = [{'kind': 'Return', 'type': 'string', 'value': 'hello'}]\nrc.check_return_type(stmts)\nprint(len(rc.errors))",
    "testCases": [
      {
        "input": "correct type",
        "expectedOutput": "0",
        "isHidden": false,
        "description": "Return type matches"
      },
      {
        "input": "wrong type",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Return type mismatch"
      },
      {
        "input": "missing return",
        "expectedOutput": "False",
        "isHidden": true,
        "description": "Not all paths return"
      }
    ],
    "hints": [
      "Compare return statement types with expected type",
      "Recursively check conditional branches",
      "All paths must return for non-void functions",
      "Both if and else branches must return"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex15",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Attribute Grammar Evaluation",
    "difficulty": 4,
    "description": "Implement attribute grammar for computing inherited and synthesized attributes on parse trees.",
    "starterCode": "class AttributeGrammar:\n    def __init__(self):\n        pass\n\n    def evaluate_synthesized(self, node):\n        \"\"\"\n        Compute synthesized attributes (bottom-up).\n        Example: expression value\n        \"\"\"\n        # Your code here\n        pass\n\n    def evaluate_inherited(self, node, parent_attrs):\n        \"\"\"\n        Compute inherited attributes (top-down).\n        Example: expected type from parent\n        \"\"\"\n        # Your code here\n        pass\n\n# Node structure:\n# {'kind': 'BinaryOp', 'op': '+', 'left': ..., 'right': ...}\n# {'kind': 'Literal', 'value': 5}\n\n# Test\nag = AttributeGrammar()\nnode = {'kind': 'BinaryOp', 'op': '+',\n        'left': {'kind': 'Literal', 'value': 3},\n        'right': {'kind': 'Literal', 'value': 7}}\nresult = ag.evaluate_synthesized(node)\nprint(result)  # Should compute value attribute",
    "solution": "class AttributeGrammar:\n    def __init__(self):\n        pass\n\n    def evaluate_synthesized(self, node):\n        \"\"\"\n        Compute synthesized attributes (bottom-up).\n        Example: expression value\n        \"\"\"\n        if node['kind'] == 'Literal':\n            node['value_attr'] = node['value']\n            node['type_attr'] = 'int'\n            return node['value_attr']\n\n        elif node['kind'] == 'BinaryOp':\n            # Evaluate children first (bottom-up)\n            left_val = self.evaluate_synthesized(node['left'])\n            right_val = self.evaluate_synthesized(node['right'])\n\n            # Compute this node's attribute\n            op = node['op']\n            if op == '+':\n                result = left_val + right_val\n            elif op == '-':\n                result = left_val - right_val\n            elif op == '*':\n                result = left_val * right_val\n            else:\n                result = 0\n\n            node['value_attr'] = result\n            node['type_attr'] = 'int'\n            return result\n\n        return None\n\n    def evaluate_inherited(self, node, parent_attrs):\n        \"\"\"\n        Compute inherited attributes (top-down).\n        Example: expected type from parent\n        \"\"\"\n        # Pass down attributes from parent\n        node['expected_type'] = parent_attrs.get('expected_type', 'int')\n\n        # Recursively pass to children\n        if node['kind'] == 'BinaryOp':\n            child_attrs = {'expected_type': node['expected_type']}\n            self.evaluate_inherited(node['left'], child_attrs)\n            self.evaluate_inherited(node['right'], child_attrs)\n\n# Test\nag = AttributeGrammar()\nnode = {'kind': 'BinaryOp', 'op': '+',\n        'left': {'kind': 'Literal', 'value': 3},\n        'right': {'kind': 'Literal', 'value': 7}}\nresult = ag.evaluate_synthesized(node)\nprint(result)",
    "testCases": [
      {
        "input": "simple expression",
        "expectedOutput": "10",
        "isHidden": false,
        "description": "Synthesized value attribute"
      },
      {
        "input": "multiplication",
        "expectedOutput": "21",
        "isHidden": false,
        "description": "Compute 3 * 7"
      },
      {
        "input": "inherited type",
        "expectedOutput": "int",
        "isHidden": true,
        "description": "Pass expected type down"
      }
    ],
    "hints": [
      "Synthesized attributes flow bottom-up from children",
      "Inherited attributes flow top-down from parent",
      "Evaluate children before computing node attribute",
      "Store attributes as node properties"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t3-ex16",
    "subjectId": "cs304",
    "topicId": "cs304-topic-3",
    "title": "Complete Semantic Analyzer",
    "difficulty": 5,
    "description": "Build a complete semantic analyzer that performs symbol table management, type checking, and semantic error detection.",
    "starterCode": "class SemanticAnalyzer:\n    def __init__(self):\n        self.symbol_table = [{}]  # Scope stack\n        self.errors = []\n        self.current_function = None\n\n    def enter_scope(self):\n        \"\"\"Enter new scope.\"\"\"\n        # Your code here\n        pass\n\n    def exit_scope(self):\n        \"\"\"Exit current scope.\"\"\"\n        # Your code here\n        pass\n\n    def analyze_program(self, ast):\n        \"\"\"\n        Analyze complete program AST.\n        Performs:\n        - Symbol table construction\n        - Type checking\n        - Semantic error detection\n        Returns: True if no errors\n        \"\"\"\n        # Your code here\n        pass\n\n    def analyze_function(self, node):\n        \"\"\"Analyze function declaration.\"\"\"\n        # Your code here\n        pass\n\n    def analyze_statement(self, node):\n        \"\"\"Analyze individual statement.\"\"\"\n        # Your code here\n        pass\n\n    def analyze_expression(self, node):\n        \"\"\"Analyze expression and return its type.\"\"\"\n        # Your code here\n        pass\n\n# Test\nanalyzer = SemanticAnalyzer()\nprogram = {\n    'kind': 'Program',\n    'functions': [\n        {\n            'kind': 'Function',\n            'name': 'main',\n            'params': [],\n            'return_type': 'int',\n            'body': [\n                {'kind': 'Return', 'expr': {'kind': 'Literal', 'type': 'int', 'value': 0}}\n            ]\n        }\n    ]\n}\nresult = analyzer.analyze_program(program)\nprint(result)",
    "solution": "class SemanticAnalyzer:\n    def __init__(self):\n        self.symbol_table = [{}]  # Scope stack\n        self.errors = []\n        self.current_function = None\n\n    def enter_scope(self):\n        \"\"\"Enter new scope.\"\"\"\n        self.symbol_table.append({})\n\n    def exit_scope(self):\n        \"\"\"Exit current scope.\"\"\"\n        if len(self.symbol_table) > 1:\n            self.symbol_table.pop()\n\n    def declare_symbol(self, name, symbol_type):\n        \"\"\"Declare symbol in current scope.\"\"\"\n        if name in self.symbol_table[-1]:\n            self.errors.append(f\"Duplicate declaration: {name}\")\n            return False\n        self.symbol_table[-1][name] = symbol_type\n        return True\n\n    def lookup_symbol(self, name):\n        \"\"\"Look up symbol in all scopes.\"\"\"\n        for scope in reversed(self.symbol_table):\n            if name in scope:\n                return scope[name]\n        return None\n\n    def analyze_program(self, ast):\n        \"\"\"Analyze complete program AST.\"\"\"\n        if ast['kind'] != 'Program':\n            return False\n\n        # Analyze each function\n        for func in ast.get('functions', []):\n            self.analyze_function(func)\n\n        return len(self.errors) == 0\n\n    def analyze_function(self, node):\n        \"\"\"Analyze function declaration.\"\"\"\n        func_name = node['name']\n        param_types = [p['type'] for p in node.get('params', [])]\n        return_type = node['return_type']\n\n        # Declare function in global scope\n        self.symbol_table[0][func_name] = {\n            'kind': 'function',\n            'params': param_types,\n            'return_type': return_type\n        }\n\n        # Enter function scope\n        self.current_function = return_type\n        self.enter_scope()\n\n        # Declare parameters\n        for param in node.get('params', []):\n            self.declare_symbol(param['name'], param['type'])\n\n        # Analyze function body\n        for stmt in node.get('body', []):\n            self.analyze_statement(stmt)\n\n        self.exit_scope()\n        self.current_function = None\n\n    def analyze_statement(self, node):\n        \"\"\"Analyze individual statement.\"\"\"\n        kind = node['kind']\n\n        if kind == 'Return':\n            expr_type = self.analyze_expression(node['expr'])\n            if expr_type != self.current_function:\n                self.errors.append(\n                    f\"Return type mismatch: expected {self.current_function}, got {expr_type}\"\n                )\n\n        elif kind == 'Assignment':\n            var_name = node['var']\n            var_type = self.lookup_symbol(var_name)\n\n            if var_type is None:\n                self.errors.append(f\"Undefined variable: {var_name}\")\n            else:\n                expr_type = self.analyze_expression(node['expr'])\n                if expr_type != var_type:\n                    self.errors.append(\n                        f\"Type mismatch in assignment to {var_name}\"\n                    )\n\n        elif kind == 'Declaration':\n            self.declare_symbol(node['name'], node['type'])\n\n    def analyze_expression(self, node):\n        \"\"\"Analyze expression and return its type.\"\"\"\n        kind = node['kind']\n\n        if kind == 'Literal':\n            return node['type']\n\n        elif kind == 'Variable':\n            var_type = self.lookup_symbol(node['name'])\n            if var_type is None:\n                self.errors.append(f\"Undefined variable: {node['name']}\")\n                return None\n            return var_type\n\n        elif kind == 'BinaryOp':\n            left_type = self.analyze_expression(node['left'])\n            right_type = self.analyze_expression(node['right'])\n\n            if left_type != right_type:\n                self.errors.append(\"Type mismatch in binary operation\")\n                return None\n\n            return left_type\n\n        return None\n\n# Test\nanalyzer = SemanticAnalyzer()\nprogram = {\n    'kind': 'Program',\n    'functions': [\n        {\n            'kind': 'Function',\n            'name': 'main',\n            'params': [],\n            'return_type': 'int',\n            'body': [\n                {'kind': 'Return', 'expr': {'kind': 'Literal', 'type': 'int', 'value': 0}}\n            ]\n        }\n    ]\n}\nresult = analyzer.analyze_program(program)\nprint(result)",
    "testCases": [
      {
        "input": "valid program",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Program with no errors"
      },
      {
        "input": "undefined variable",
        "expectedOutput": "False",
        "isHidden": false,
        "description": "Detect undefined variable use"
      },
      {
        "input": "type mismatch",
        "expectedOutput": "False",
        "isHidden": true,
        "description": "Detect type errors"
      }
    ],
    "hints": [
      "Use scope stack for nested symbol tables",
      "Analyze functions, statements, and expressions recursively",
      "Track current function for return type checking",
      "Collect all errors instead of stopping at first one"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex01",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Three-Address Code Generator",
    "difficulty": 1,
    "description": "Generate three-address code from simple arithmetic expressions. Each instruction has at most one operator.",
    "starterCode": "class ThreeAddressCodeGen:\n    def __init__(self):\n        self.temp_count = 0\n        self.code = []\n\n    def new_temp(self):\n        \"\"\"Generate a new temporary variable.\"\"\"\n        temp = f\"t{self.temp_count}\"\n        self.temp_count += 1\n        return temp\n\n    def generate(self, expr):\n        \"\"\"\n        Generate three-address code for expression.\n        expr: {'kind': 'BinaryOp'/'Literal', ...}\n        Returns: variable holding result\n        \"\"\"\n        # Your code here\n        pass\n\n# Example:\n# expr = {'kind': 'BinaryOp', 'op': '+',\n#         'left': {'kind': 'Literal', 'value': 'a'},\n#         'right': {'kind': 'Literal', 'value': 'b'}}\n# Generates: t0 = a + b\n\n# Test\ngen = ThreeAddressCodeGen()\nexpr = {'kind': 'BinaryOp', 'op': '+',\n        'left': {'kind': 'Literal', 'value': 'a'},\n        'right': {'kind': 'Literal', 'value': 'b'}}\nresult = gen.generate(expr)\nprint(gen.code[0])  # Should be 't0 = a + b'",
    "solution": "class ThreeAddressCodeGen:\n    def __init__(self):\n        self.temp_count = 0\n        self.code = []\n\n    def new_temp(self):\n        \"\"\"Generate a new temporary variable.\"\"\"\n        temp = f\"t{self.temp_count}\"\n        self.temp_count += 1\n        return temp\n\n    def generate(self, expr):\n        \"\"\"\n        Generate three-address code for expression.\n        Returns: variable holding result\n        \"\"\"\n        if expr['kind'] == 'Literal':\n            return expr['value']\n\n        elif expr['kind'] == 'BinaryOp':\n            # Generate code for left and right operands\n            left = self.generate(expr['left'])\n            right = self.generate(expr['right'])\n\n            # Generate instruction\n            result = self.new_temp()\n            self.code.append(f\"{result} = {left} {expr['op']} {right}\")\n\n            return result\n\n        return None\n\n# Test\ngen = ThreeAddressCodeGen()\nexpr = {'kind': 'BinaryOp', 'op': '+',\n        'left': {'kind': 'Literal', 'value': 'a'},\n        'right': {'kind': 'Literal', 'value': 'b'}}\nresult = gen.generate(expr)\nprint(gen.code[0])",
    "testCases": [
      {
        "input": "a + b",
        "expectedOutput": "t0 = a + b",
        "isHidden": false,
        "description": "Simple addition"
      },
      {
        "input": "(a + b) * c",
        "expectedOutput": "t1 = t0 * c",
        "isHidden": false,
        "description": "Nested expression"
      },
      {
        "input": "a + b + c",
        "expectedOutput": "t1 = t0 + c",
        "isHidden": true,
        "description": "Multiple operations"
      }
    ],
    "hints": [
      "Recursively generate code for sub-expressions",
      "Each binary operation needs a new temporary",
      "Literals evaluate to themselves",
      "Return the temporary holding the result"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex02",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Control Flow Graph Construction",
    "difficulty": 2,
    "description": "Build a control flow graph (CFG) from a sequence of three-address code instructions.",
    "starterCode": "class BasicBlock:\n    def __init__(self, label):\n        self.label = label\n        self.instructions = []\n        self.successors = []\n\nclass CFGBuilder:\n    def __init__(self):\n        self.blocks = []\n\n    def build_cfg(self, instructions):\n        \"\"\"\n        Build CFG from three-address code.\n        instructions: list of strings like 'x = a + b', 'goto L1', 'if x < 0 goto L2'\n        Returns: list of BasicBlocks\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\nbuilder = CFGBuilder()\ncode = [\n    'x = a + b',\n    'if x < 0 goto L1',\n    'y = x * 2',\n    'goto L2',\n    'L1: y = x * -1',\n    'L2: return y'\n]\ncfg = builder.build_cfg(code)\nprint(len(cfg))  # Number of basic blocks",
    "solution": "class BasicBlock:\n    def __init__(self, label):\n        self.label = label\n        self.instructions = []\n        self.successors = []\n\nclass CFGBuilder:\n    def __init__(self):\n        self.blocks = []\n        self.labels = {}  # label -> block\n\n    def build_cfg(self, instructions):\n        \"\"\"\n        Build CFG from three-address code.\n        Returns: list of BasicBlocks\n        \"\"\"\n        # First pass: identify leaders (first instruction of each block)\n        leaders = {0}  # First instruction is always a leader\n\n        for i, instr in enumerate(instructions):\n            # Instructions after jumps are leaders\n            if i > 0 and ('goto' in instructions[i-1] or 'if' in instructions[i-1]):\n                leaders.add(i)\n\n            # Label targets are leaders\n            if ':' in instr:\n                leaders.add(i)\n\n        leaders = sorted(leaders)\n\n        # Second pass: create basic blocks\n        for i, leader in enumerate(leaders):\n            next_leader = leaders[i + 1] if i + 1 < len(leaders) else len(instructions)\n\n            block = BasicBlock(f\"B{i}\")\n            for j in range(leader, next_leader):\n                instr = instructions[j]\n                block.instructions.append(instr)\n\n                # Track labels\n                if ':' in instr:\n                    label = instr.split(':')[0]\n                    self.labels[label] = block\n\n            self.blocks.append(block)\n\n        # Third pass: add edges\n        for i, block in enumerate(self.blocks):\n            last_instr = block.instructions[-1] if block.instructions else ''\n\n            if 'goto' in last_instr and 'if' not in last_instr:\n                # Unconditional jump\n                target = last_instr.split('goto')[1].strip()\n                if target in self.labels:\n                    block.successors.append(self.labels[target])\n\n            elif 'if' in last_instr and 'goto' in last_instr:\n                # Conditional jump\n                target = last_instr.split('goto')[1].strip()\n                if target in self.labels:\n                    block.successors.append(self.labels[target])\n\n                # Fall through to next block\n                if i + 1 < len(self.blocks):\n                    block.successors.append(self.blocks[i + 1])\n\n            elif 'return' not in last_instr:\n                # Fall through to next block\n                if i + 1 < len(self.blocks):\n                    block.successors.append(self.blocks[i + 1])\n\n        return self.blocks\n\n# Test\nbuilder = CFGBuilder()\ncode = [\n    'x = a + b',\n    'if x < 0 goto L1',\n    'y = x * 2',\n    'goto L2',\n    'L1: y = x * -1',\n    'L2: return y'\n]\ncfg = builder.build_cfg(code)\nprint(len(cfg))",
    "testCases": [
      {
        "input": "simple sequence",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "One basic block for straight-line code"
      },
      {
        "input": "with branch",
        "expectedOutput": "3",
        "isHidden": false,
        "description": "Multiple blocks with conditional"
      },
      {
        "input": "has successors",
        "expectedOutput": "True",
        "isHidden": true,
        "description": "Blocks have successor edges"
      }
    ],
    "hints": [
      "Identify leaders: first instruction, targets of jumps, instructions after jumps",
      "Create a basic block from each leader to the next leader",
      "Add edges based on jumps and fall-through",
      "Track labels to resolve jump targets"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex03",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "SSA Form Construction",
    "difficulty": 3,
    "description": "Convert code to Static Single Assignment (SSA) form where each variable is assigned exactly once.",
    "starterCode": "class SSAConverter:\n    def __init__(self):\n        self.version_count = {}  # var -> count\n\n    def new_version(self, var):\n        \"\"\"Get next version number for variable.\"\"\"\n        if var not in self.version_count:\n            self.version_count[var] = 0\n        else:\n            self.version_count[var] += 1\n        return f\"{var}_{self.version_count[var]}\"\n\n    def to_ssa(self, instructions):\n        \"\"\"\n        Convert to SSA form.\n        instructions: list like ['x = a + b', 'x = x * 2']\n        Returns: SSA instructions\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\nconverter = SSAConverter()\ncode = ['x = a + b', 'x = x * 2', 'y = x + c']\nssa = converter.to_ssa(code)\nprint(ssa[0])  # Should be 'x_0 = a + b'",
    "solution": "class SSAConverter:\n    def __init__(self):\n        self.version_count = {}  # var -> count\n        self.current_version = {}  # var -> current version name\n\n    def new_version(self, var):\n        \"\"\"Get next version number for variable.\"\"\"\n        if var not in self.version_count:\n            self.version_count[var] = 0\n        else:\n            self.version_count[var] += 1\n\n        version_name = f\"{var}_{self.version_count[var]}\"\n        self.current_version[var] = version_name\n        return version_name\n\n    def get_current_version(self, var):\n        \"\"\"Get current version of variable.\"\"\"\n        return self.current_version.get(var, var)\n\n    def to_ssa(self, instructions):\n        \"\"\"\n        Convert to SSA form.\n        Returns: SSA instructions\n        \"\"\"\n        ssa_code = []\n\n        for instr in instructions:\n            if '=' in instr:\n                parts = instr.split('=')\n                lhs = parts[0].strip()\n                rhs = parts[1].strip()\n\n                # Replace uses in RHS with current versions\n                tokens = rhs.split()\n                new_rhs = []\n                for token in tokens:\n                    if token.isalpha():\n                        new_rhs.append(self.get_current_version(token))\n                    else:\n                        new_rhs.append(token)\n\n                # Create new version for LHS\n                new_lhs = self.new_version(lhs)\n\n                ssa_code.append(f\"{new_lhs} = {' '.join(new_rhs)}\")\n            else:\n                ssa_code.append(instr)\n\n        return ssa_code\n\n# Test\nconverter = SSAConverter()\ncode = ['x = a + b', 'x = x * 2', 'y = x + c']\nssa = converter.to_ssa(code)\nprint(ssa[0])",
    "testCases": [
      {
        "input": "single assignment",
        "expectedOutput": "x_0 = a + b",
        "isHidden": false,
        "description": "First version is _0"
      },
      {
        "input": "multiple assignments",
        "expectedOutput": "x_1 = x_0 * 2",
        "isHidden": false,
        "description": "Second assignment gets new version"
      },
      {
        "input": "use of variable",
        "expectedOutput": "y_0 = x_1 + c",
        "isHidden": true,
        "description": "Uses refer to current version"
      }
    ],
    "hints": [
      "Track current version of each variable",
      "On assignment, create a new version",
      "Replace variable uses with current version",
      "Parse instructions to identify variables"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex04",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Phi Function Insertion",
    "difficulty": 4,
    "description": "Insert phi functions at join points in the CFG for SSA form.",
    "starterCode": "class PhiInserter:\n    def __init__(self, cfg):\n        self.cfg = cfg\n\n    def compute_dominance_frontier(self, block):\n        \"\"\"\n        Compute dominance frontier for a block.\n        Returns: set of blocks in frontier\n        \"\"\"\n        # Simplified: return blocks with multiple predecessors\n        # Your code here\n        pass\n\n    def insert_phi_functions(self, variable):\n        \"\"\"\n        Insert phi functions for a variable.\n        Modifies CFG to add phi nodes.\n        \"\"\"\n        # Your code here\n        pass\n\n# Example:\n# If variable x is assigned in blocks B1 and B2,\n# and they both reach B3, insert: x = phi(x_1, x_2) in B3\n\n# Test\ncfg = [...]  # CFG from previous exercise\ninserter = PhiInserter(cfg)\ninserter.insert_phi_functions('x')",
    "solution": "class PhiInserter:\n    def __init__(self, cfg):\n        self.cfg = cfg\n        self.predecessors = {}  # block -> list of predecessor blocks\n\n        # Compute predecessors\n        for block in cfg:\n            if block not in self.predecessors:\n                self.predecessors[block] = []\n\n            for succ in block.successors:\n                if succ not in self.predecessors:\n                    self.predecessors[succ] = []\n                self.predecessors[succ].append(block)\n\n    def has_multiple_predecessors(self, block):\n        \"\"\"Check if block has multiple predecessors.\"\"\"\n        return len(self.predecessors.get(block, [])) > 1\n\n    def find_blocks_assigning(self, variable):\n        \"\"\"Find all blocks that assign to variable.\"\"\"\n        assigning_blocks = []\n\n        for block in self.cfg:\n            for instr in block.instructions:\n                if '=' in instr:\n                    lhs = instr.split('=')[0].strip()\n                    # Simple check: does it assign to variable?\n                    if lhs.startswith(variable):\n                        assigning_blocks.append(block)\n                        break\n\n        return assigning_blocks\n\n    def insert_phi_functions(self, variable):\n        \"\"\"\n        Insert phi functions for a variable.\n        \"\"\"\n        assigning_blocks = self.find_blocks_assigning(variable)\n\n        # For each block with assignments\n        worklist = list(assigning_blocks)\n        phi_inserted = set()\n\n        while worklist:\n            block = worklist.pop()\n\n            # Find blocks that need phi functions\n            # Simple approach: blocks with multiple predecessors reachable from this block\n            for candidate in self.cfg:\n                if self.has_multiple_predecessors(candidate) and candidate not in phi_inserted:\n                    # Check if block reaches candidate\n                    # Simplified: add phi to all multi-predecessor blocks\n                    if candidate not in assigning_blocks:\n                        # Insert phi function\n                        phi_instr = f\"{variable} = phi({variable}, {variable})\"\n                        candidate.instructions.insert(0, phi_instr)\n                        phi_inserted.add(candidate)\n                        worklist.append(candidate)\n\n# Test example with simple CFG\nclass BasicBlock:\n    def __init__(self, label):\n        self.label = label\n        self.instructions = []\n        self.successors = []\n\nb1 = BasicBlock('B1')\nb1.instructions = ['x = 1']\nb2 = BasicBlock('B2')\nb2.instructions = ['x = 2']\nb3 = BasicBlock('B3')\nb3.instructions = ['y = x + 1']\n\nb1.successors = [b3]\nb2.successors = [b3]\n\ncfg = [b1, b2, b3]\ninserter = PhiInserter(cfg)\ninserter.insert_phi_functions('x')\nprint(b3.instructions[0])  # Should have phi function",
    "testCases": [
      {
        "input": "join point",
        "expectedOutput": "phi",
        "isHidden": false,
        "description": "Phi inserted at merge point"
      },
      {
        "input": "single predecessor",
        "expectedOutput": "no phi",
        "isHidden": false,
        "description": "No phi for single predecessor"
      },
      {
        "input": "multiple variables",
        "expectedOutput": "phi per variable",
        "isHidden": true,
        "description": "Each variable gets its own phi"
      }
    ],
    "hints": [
      "Find blocks that assign to the variable",
      "Identify join points (multiple predecessors)",
      "Insert phi functions at join points",
      "Phi function merges values from different paths"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex05",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Quadruple Representation",
    "difficulty": 2,
    "description": "Convert three-address code to quadruple format (operator, arg1, arg2, result).",
    "starterCode": "class QuadrupleGenerator:\n    def __init__(self):\n        self.quads = []\n\n    def generate_quadruple(self, instruction):\n        \"\"\"\n        Convert instruction to quadruple.\n        instruction: 't0 = a + b'\n        Returns: ('+', 'a', 'b', 't0')\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\ngen = QuadrupleGenerator()\nquad = gen.generate_quadruple('t0 = a + b')\nprint(quad)  # Should be ('+', 'a', 'b', 't0')",
    "solution": "class QuadrupleGenerator:\n    def __init__(self):\n        self.quads = []\n\n    def generate_quadruple(self, instruction):\n        \"\"\"\n        Convert instruction to quadruple.\n        Returns: (operator, arg1, arg2, result)\n        \"\"\"\n        if '=' not in instruction:\n            return None\n\n        parts = instruction.split('=')\n        result = parts[0].strip()\n        expr = parts[1].strip()\n\n        # Parse expression\n        tokens = expr.split()\n\n        if len(tokens) == 1:\n            # Assignment: x = y\n            return ('=', tokens[0], None, result)\n\n        elif len(tokens) == 3:\n            # Binary operation: a + b\n            arg1, op, arg2 = tokens\n            return (op, arg1, arg2, result)\n\n        elif len(tokens) == 2:\n            # Unary operation: - a\n            op, arg = tokens\n            return (op, arg, None, result)\n\n        return None\n\n# Test\ngen = QuadrupleGenerator()\nquad = gen.generate_quadruple('t0 = a + b')\nprint(quad)",
    "testCases": [
      {
        "input": "t0 = a + b",
        "expectedOutput": "('+', 'a', 'b', 't0')",
        "isHidden": false,
        "description": "Binary operation"
      },
      {
        "input": "t1 = x",
        "expectedOutput": "('=', 'x', None, 't1')",
        "isHidden": false,
        "description": "Simple assignment"
      },
      {
        "input": "t2 = - y",
        "expectedOutput": "('-', 'y', None, 't2')",
        "isHidden": true,
        "description": "Unary operation"
      }
    ],
    "hints": [
      "Split instruction at = to get result and expression",
      "Parse expression to extract operator and operands",
      "Handle binary, unary, and assignment forms",
      "Use None for missing operands"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex06",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "DAG Construction",
    "difficulty": 3,
    "description": "Build a Directed Acyclic Graph (DAG) to represent expressions with common subexpressions.",
    "starterCode": "class DAGNode:\n    def __init__(self, op, left=None, right=None):\n        self.op = op\n        self.left = left\n        self.right = right\n        self.value = None  # For leaf nodes\n\nclass DAGBuilder:\n    def __init__(self):\n        self.nodes = {}  # (op, left, right) -> node\n\n    def build_dag(self, instructions):\n        \"\"\"\n        Build DAG from three-address code.\n        Eliminates common subexpressions.\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\nbuilder = DAGBuilder()\ncode = ['t0 = a + b', 't1 = a + b', 't2 = t0 * t1']\ndag = builder.build_dag(code)",
    "solution": "class DAGNode:\n    def __init__(self, op, left=None, right=None):\n        self.op = op\n        self.left = left\n        self.right = right\n        self.value = None\n        self.labels = []  # Variables assigned to this node\n\nclass DAGBuilder:\n    def __init__(self):\n        self.nodes = {}  # (op, left, right) -> node\n        self.variables = {}  # var -> node\n\n    def get_or_create_leaf(self, value):\n        \"\"\"Get or create a leaf node.\"\"\"\n        key = ('LEAF', value, None)\n        if key not in self.nodes:\n            node = DAGNode('LEAF')\n            node.value = value\n            self.nodes[key] = node\n        return self.nodes[key]\n\n    def get_or_create_op(self, op, left, right):\n        \"\"\"Get or create an operation node.\"\"\"\n        key = (op, id(left), id(right) if right else None)\n\n        # Check if this computation already exists\n        for existing_key, node in self.nodes.items():\n            if (existing_key[0] == op and\n                node.left is left and\n                node.right is right):\n                return node\n\n        # Create new node\n        node = DAGNode(op, left, right)\n        self.nodes[key] = node\n        return node\n\n    def build_dag(self, instructions):\n        \"\"\"\n        Build DAG from three-address code.\n        \"\"\"\n        for instr in instructions:\n            if '=' not in instr:\n                continue\n\n            parts = instr.split('=')\n            result = parts[0].strip()\n            expr = parts[1].strip()\n\n            tokens = expr.split()\n\n            if len(tokens) == 1:\n                # x = y\n                if tokens[0] in self.variables:\n                    node = self.variables[tokens[0]]\n                else:\n                    node = self.get_or_create_leaf(tokens[0])\n                node.labels.append(result)\n                self.variables[result] = node\n\n            elif len(tokens) == 3:\n                # x = a op b\n                arg1, op, arg2 = tokens\n\n                # Get nodes for operands\n                if arg1 in self.variables:\n                    left = self.variables[arg1]\n                else:\n                    left = self.get_or_create_leaf(arg1)\n\n                if arg2 in self.variables:\n                    right = self.variables[arg2]\n                else:\n                    right = self.get_or_create_leaf(arg2)\n\n                # Get or create operation node\n                node = self.get_or_create_op(op, left, right)\n                node.labels.append(result)\n                self.variables[result] = node\n\n        return self.nodes\n\n# Test\nbuilder = DAGBuilder()\ncode = ['t0 = a + b', 't1 = a + b', 't2 = t0 * t1']\ndag = builder.build_dag(code)\nprint(len(dag))  # Fewer nodes due to CSE",
    "testCases": [
      {
        "input": "common subexpression",
        "expectedOutput": "shared node",
        "isHidden": false,
        "description": "Same expression uses same node"
      },
      {
        "input": "different expressions",
        "expectedOutput": "different nodes",
        "isHidden": false,
        "description": "Different operations get different nodes"
      },
      {
        "input": "node count",
        "expectedOutput": "less than instruction count",
        "isHidden": true,
        "description": "DAG is more compact"
      }
    ],
    "hints": [
      "Use hash table to detect identical subexpressions",
      "Key should be (operator, left_node, right_node)",
      "Reuse existing nodes for common subexpressions",
      "Track which variables are assigned to each node"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex07",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Intermediate Code Optimization",
    "difficulty": 3,
    "description": "Perform simple optimizations on three-address code: constant folding, copy propagation, dead code elimination.",
    "starterCode": "class IROptimizer:\n    def __init__(self):\n        self.constants = {}  # var -> constant value\n\n    def constant_folding(self, instructions):\n        \"\"\"Fold constant expressions.\"\"\"\n        # Your code here\n        pass\n\n    def copy_propagation(self, instructions):\n        \"\"\"Propagate copies (x = y).\"\"\"\n        # Your code here\n        pass\n\n    def dead_code_elimination(self, instructions):\n        \"\"\"Remove unused assignments.\"\"\"\n        # Your code here\n        pass\n\n# Test\nopt = IROptimizer()\ncode = ['x = 2', 'y = 3', 'z = x + y', 't = z']\noptimized = opt.constant_folding(code)",
    "solution": "class IROptimizer:\n    def __init__(self):\n        self.constants = {}  # var -> constant value\n        self.copies = {}  # var -> var\n\n    def is_constant(self, val):\n        \"\"\"Check if value is a constant.\"\"\"\n        try:\n            int(val)\n            return True\n        except:\n            return False\n\n    def constant_folding(self, instructions):\n        \"\"\"Fold constant expressions.\"\"\"\n        result = []\n\n        for instr in instructions:\n            if '=' not in instr:\n                result.append(instr)\n                continue\n\n            parts = instr.split('=')\n            lhs = parts[0].strip()\n            rhs = parts[1].strip()\n\n            tokens = rhs.split()\n\n            # Track constant assignments\n            if len(tokens) == 1 and self.is_constant(tokens[0]):\n                self.constants[lhs] = int(tokens[0])\n                result.append(instr)\n\n            elif len(tokens) == 3:\n                arg1, op, arg2 = tokens\n\n                # Replace with constants if known\n                val1 = self.constants.get(arg1, arg1)\n                val2 = self.constants.get(arg2, arg2)\n\n                # If both are constants, fold\n                if isinstance(val1, int) and isinstance(val2, int):\n                    if op == '+':\n                        res = val1 + val2\n                    elif op == '-':\n                        res = val1 - val2\n                    elif op == '*':\n                        res = val1 * val2\n                    elif op == '/':\n                        res = val1 // val2\n                    else:\n                        result.append(instr)\n                        continue\n\n                    folded = f\"{lhs} = {res}\"\n                    result.append(folded)\n                    self.constants[lhs] = res\n                else:\n                    result.append(instr)\n            else:\n                result.append(instr)\n\n        return result\n\n    def copy_propagation(self, instructions):\n        \"\"\"Propagate copies (x = y).\"\"\"\n        result = []\n\n        for instr in instructions:\n            if '=' not in instr:\n                result.append(instr)\n                continue\n\n            parts = instr.split('=')\n            lhs = parts[0].strip()\n            rhs = parts[1].strip()\n\n            tokens = rhs.split()\n\n            # Detect copy: x = y\n            if len(tokens) == 1 and not self.is_constant(tokens[0]):\n                self.copies[lhs] = tokens[0]\n                result.append(instr)\n\n            # Replace uses with copy source\n            else:\n                new_tokens = []\n                for token in tokens:\n                    if token in self.copies:\n                        new_tokens.append(self.copies[token])\n                    else:\n                        new_tokens.append(token)\n\n                result.append(f\"{lhs} = {' '.join(new_tokens)}\")\n\n        return result\n\n    def dead_code_elimination(self, instructions):\n        \"\"\"Remove unused assignments.\"\"\"\n        # Find used variables\n        used = set()\n\n        for instr in instructions:\n            if 'return' in instr or 'print' in instr:\n                # Mark variables in return/print as used\n                tokens = instr.split()\n                for token in tokens:\n                    if token.isalpha():\n                        used.add(token)\n\n        # Remove assignments to unused variables\n        # Simplified: keep all for now\n        return instructions\n\n# Test\nopt = IROptimizer()\ncode = ['x = 2', 'y = 3', 'z = x + y', 't = z']\noptimized = opt.constant_folding(code)\nprint(optimized[2])  # Should have folded x + y",
    "testCases": [
      {
        "input": "constant folding",
        "expectedOutput": "z = 5",
        "isHidden": false,
        "description": "Fold 2 + 3 to 5"
      },
      {
        "input": "copy propagation",
        "expectedOutput": "propagated",
        "isHidden": false,
        "description": "Replace copies with original"
      },
      {
        "input": "combined",
        "expectedOutput": "optimized",
        "isHidden": true,
        "description": "Multiple optimizations together"
      }
    ],
    "hints": [
      "Track constant values in a dictionary",
      "Replace variables with their constant values",
      "For copy propagation, track x = y relationships",
      "For DCE, mark variables used in output statements"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex08",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Basic Block Optimization",
    "difficulty": 2,
    "description": "Optimize within basic blocks by eliminating redundant computations and unused temporaries.",
    "starterCode": "class BasicBlockOptimizer:\n    def __init__(self):\n        self.available_exprs = {}  # expr -> temp\n\n    def optimize_block(self, instructions):\n        \"\"\"\n        Optimize a basic block.\n        - Eliminate common subexpressions\n        - Remove redundant loads\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\nopt = BasicBlockOptimizer()\nblock = [\n    't0 = a + b',\n    't1 = a + b',  # Redundant\n    't2 = t0 * 2'\n]\noptimized = opt.optimize_block(block)\nprint(len(optimized))  # Should be less than original",
    "solution": "class BasicBlockOptimizer:\n    def __init__(self):\n        self.available_exprs = {}  # expr -> temp\n\n    def expr_key(self, expr):\n        \"\"\"Create key for expression.\"\"\"\n        return expr.strip()\n\n    def optimize_block(self, instructions):\n        \"\"\"Optimize a basic block.\"\"\"\n        result = []\n        self.available_exprs = {}\n\n        for instr in instructions:\n            if '=' not in instr:\n                result.append(instr)\n                continue\n\n            parts = instr.split('=')\n            lhs = parts[0].strip()\n            rhs = parts[1].strip()\n\n            # Check if expression is already computed\n            expr_k = self.expr_key(rhs)\n\n            if expr_k in self.available_exprs:\n                # Replace with copy from existing temp\n                existing = self.available_exprs[expr_k]\n                result.append(f\"{lhs} = {existing}\")\n            else:\n                # New computation\n                result.append(instr)\n                self.available_exprs[expr_k] = lhs\n\n        return result\n\n# Test\nopt = BasicBlockOptimizer()\nblock = [\n    't0 = a + b',\n    't1 = a + b',\n    't2 = t0 * 2'\n]\noptimized = opt.optimize_block(block)\nprint(len(optimized))",
    "testCases": [
      {
        "input": "common subexpression",
        "expectedOutput": "3",
        "isHidden": false,
        "description": "Eliminate redundant computation"
      },
      {
        "input": "no redundancy",
        "expectedOutput": "same length",
        "isHidden": false,
        "description": "No optimization if no redundancy"
      },
      {
        "input": "multiple CSE",
        "expectedOutput": "fewer instructions",
        "isHidden": true,
        "description": "Multiple common subexpressions"
      }
    ],
    "hints": [
      "Track computed expressions with their result temps",
      "Use expression as key to detect duplicates",
      "Replace redundant computation with copy",
      "Only works within a single basic block"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex09",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Reaching Definitions Analysis",
    "difficulty": 4,
    "description": "Compute reaching definitions for each program point to support data flow analysis.",
    "starterCode": "class ReachingDefinitions:\n    def __init__(self):\n        self.gen = {}  # block -> definitions generated\n        self.kill = {}  # block -> definitions killed\n        self.reach_in = {}  # block -> definitions reaching entry\n        self.reach_out = {}  # block -> definitions reaching exit\n\n    def compute_gen_kill(self, block):\n        \"\"\"Compute GEN and KILL sets for a block.\"\"\"\n        # Your code here\n        pass\n\n    def compute_reaching(self, cfg):\n        \"\"\"\n        Compute reaching definitions for CFG.\n        Returns: reach_in and reach_out for each block\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\nrd = ReachingDefinitions()\n# cfg = ... (from previous CFG exercise)\nresult = rd.compute_reaching(cfg)",
    "solution": "class ReachingDefinitions:\n    def __init__(self):\n        self.gen = {}  # block -> definitions generated\n        self.kill = {}  # block -> definitions killed\n        self.reach_in = {}  # block -> definitions reaching entry\n        self.reach_out = {}  # block -> definitions reaching exit\n        self.all_defs = {}  # variable -> set of definition IDs\n\n    def compute_gen_kill(self, block, block_id):\n        \"\"\"Compute GEN and KILL sets for a block.\"\"\"\n        gen = set()\n        kill = set()\n\n        for i, instr in enumerate(block.instructions):\n            if '=' in instr:\n                lhs = instr.split('=')[0].strip()\n                def_id = f\"{block_id}:{i}\"\n\n                # This definition is generated\n                gen.add(def_id)\n\n                # Track all definitions of this variable\n                if lhs not in self.all_defs:\n                    self.all_defs[lhs] = set()\n                self.all_defs[lhs].add(def_id)\n\n        # Compute kill: all other definitions of same variables\n        for def_id in gen:\n            var = def_id.split(':')[0]  # Simplified: extract variable\n            for instr in block.instructions:\n                if '=' in instr:\n                    lhs = instr.split('=')[0].strip()\n                    if lhs in self.all_defs:\n                        for other_def in self.all_defs[lhs]:\n                            if other_def != def_id:\n                                kill.add(other_def)\n\n        self.gen[block_id] = gen\n        self.kill[block_id] = kill\n\n    def compute_reaching(self, cfg):\n        \"\"\"Compute reaching definitions for CFG.\"\"\"\n        # Initialize\n        for i, block in enumerate(cfg):\n            block_id = f\"B{i}\"\n            self.compute_gen_kill(block, block_id)\n            self.reach_in[block_id] = set()\n            self.reach_out[block_id] = self.gen[block_id].copy()\n\n        # Iterate until fixed point\n        changed = True\n        while changed:\n            changed = False\n\n            for i, block in enumerate(cfg):\n                block_id = f\"B{i}\"\n\n                # reach_in = union of reach_out of predecessors\n                new_reach_in = set()\n                for pred in cfg:\n                    pred_id = f\"B{cfg.index(pred)}\"\n                    if block in pred.successors:\n                        new_reach_in.update(self.reach_out[pred_id])\n\n                # reach_out = gen U (reach_in - kill)\n                new_reach_out = self.gen[block_id] | (new_reach_in - self.kill[block_id])\n\n                if new_reach_in != self.reach_in[block_id] or new_reach_out != self.reach_out[block_id]:\n                    changed = True\n                    self.reach_in[block_id] = new_reach_in\n                    self.reach_out[block_id] = new_reach_out\n\n        return {\n            'reach_in': self.reach_in,\n            'reach_out': self.reach_out\n        }\n\n# Test with simple CFG\nclass BasicBlock:\n    def __init__(self, label):\n        self.label = label\n        self.instructions = []\n        self.successors = []\n\nb1 = BasicBlock('B0')\nb1.instructions = ['x = 1']\nb2 = BasicBlock('B1')\nb2.instructions = ['x = 2']\n\ncfg = [b1, b2]\nrd = ReachingDefinitions()\nresult = rd.compute_reaching(cfg)\nprint(result)",
    "testCases": [
      {
        "input": "single block",
        "expectedOutput": "gen set",
        "isHidden": false,
        "description": "Definitions generated in block"
      },
      {
        "input": "multiple blocks",
        "expectedOutput": "propagated",
        "isHidden": false,
        "description": "Definitions reach across blocks"
      },
      {
        "input": "killed definitions",
        "expectedOutput": "not in reach_out",
        "isHidden": true,
        "description": "Redefinitions kill earlier ones"
      }
    ],
    "hints": [
      "GEN: definitions created in this block",
      "KILL: definitions of same variable elsewhere",
      "reach_in: union of predecessors' reach_out",
      "reach_out: GEN  (reach_in - KILL)",
      "Iterate until no changes (fixed point)"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex10",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Live Variable Analysis",
    "difficulty": 4,
    "description": "Compute live variables at each program point using backward data flow analysis.",
    "starterCode": "class LivenessAnalysis:\n    def __init__(self):\n        self.use = {}  # block -> variables used before defined\n        self.def_vars = {}  # block -> variables defined\n        self.live_in = {}  # block -> variables live at entry\n        self.live_out = {}  # block -> variables live at exit\n\n    def compute_use_def(self, block, block_id):\n        \"\"\"Compute USE and DEF sets for a block.\"\"\"\n        # Your code here\n        pass\n\n    def compute_liveness(self, cfg):\n        \"\"\"\n        Compute live variables for CFG.\n        Returns: live_in and live_out for each block\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\nla = LivenessAnalysis()\nresult = la.compute_liveness(cfg)",
    "solution": "class LivenessAnalysis:\n    def __init__(self):\n        self.use = {}  # block -> variables used before defined\n        self.def_vars = {}  # block -> variables defined\n        self.live_in = {}  # block -> variables live at entry\n        self.live_out = {}  # block -> variables live at exit\n\n    def extract_variables(self, expr):\n        \"\"\"Extract variable names from expression.\"\"\"\n        vars_used = []\n        tokens = expr.split()\n        for token in tokens:\n            if token.isalpha() and token not in ['+', '-', '*', '/', '=']:\n                vars_used.append(token)\n        return vars_used\n\n    def compute_use_def(self, block, block_id):\n        \"\"\"Compute USE and DEF sets for a block.\"\"\"\n        use = set()\n        defined = set()\n\n        # Process instructions in order\n        for instr in block.instructions:\n            if '=' in instr:\n                parts = instr.split('=')\n                lhs = parts[0].strip()\n                rhs = parts[1].strip()\n\n                # Variables used before being defined\n                for var in self.extract_variables(rhs):\n                    if var not in defined:\n                        use.add(var)\n\n                # Variable defined\n                defined.add(lhs)\n\n        self.use[block_id] = use\n        self.def_vars[block_id] = defined\n\n    def compute_liveness(self, cfg):\n        \"\"\"Compute live variables for CFG (backward analysis).\"\"\"\n        # Initialize\n        for i, block in enumerate(cfg):\n            block_id = f\"B{i}\"\n            self.compute_use_def(block, block_id)\n            self.live_in[block_id] = set()\n            self.live_out[block_id] = set()\n\n        # Iterate until fixed point (backward)\n        changed = True\n        while changed:\n            changed = False\n\n            # Process blocks in reverse order\n            for i in range(len(cfg) - 1, -1, -1):\n                block = cfg[i]\n                block_id = f\"B{i}\"\n\n                # live_out = union of live_in of successors\n                new_live_out = set()\n                for succ in block.successors:\n                    succ_id = f\"B{cfg.index(succ)}\"\n                    new_live_out.update(self.live_in[succ_id])\n\n                # live_in = use U (live_out - def)\n                new_live_in = self.use[block_id] | (new_live_out - self.def_vars[block_id])\n\n                if new_live_in != self.live_in[block_id] or new_live_out != self.live_out[block_id]:\n                    changed = True\n                    self.live_in[block_id] = new_live_in\n                    self.live_out[block_id] = new_live_out\n\n        return {\n            'live_in': self.live_in,\n            'live_out': self.live_out\n        }\n\n# Test\nclass BasicBlock:\n    def __init__(self, label):\n        self.label = label\n        self.instructions = []\n        self.successors = []\n\nb1 = BasicBlock('B0')\nb1.instructions = ['x = a + b', 'y = x * 2']\nb2 = BasicBlock('B1')\nb2.instructions = ['z = y + 1']\n\nb1.successors = [b2]\ncfg = [b1, b2]\n\nla = LivenessAnalysis()\nresult = la.compute_liveness(cfg)\nprint(result)",
    "testCases": [
      {
        "input": "simple block",
        "expectedOutput": "live variables",
        "isHidden": false,
        "description": "Variables live at block entry"
      },
      {
        "input": "used variable",
        "expectedOutput": "in live_in",
        "isHidden": false,
        "description": "Used variables are live"
      },
      {
        "input": "unused variable",
        "expectedOutput": "not live",
        "isHidden": true,
        "description": "Unused variables are not live"
      }
    ],
    "hints": [
      "USE: variables used before defined in block",
      "DEF: variables defined in block",
      "live_out: union of successors' live_in",
      "live_in: USE  (live_out - DEF)",
      "Backward analysis: process in reverse order"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex11",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Loop Detection",
    "difficulty": 3,
    "description": "Identify natural loops in a control flow graph by finding back edges.",
    "starterCode": "class LoopDetector:\n    def __init__(self, cfg):\n        self.cfg = cfg\n        self.back_edges = []\n\n    def find_dominators(self):\n        \"\"\"Compute dominator tree.\"\"\"\n        # Simplified: assume we have dominators\n        # Your code here\n        pass\n\n    def find_back_edges(self):\n        \"\"\"\n        Find back edges (edges to dominators).\n        Returns: list of (from_block, to_block) pairs\n        \"\"\"\n        # Your code here\n        pass\n\n    def find_natural_loop(self, back_edge):\n        \"\"\"\n        Find natural loop for a back edge.\n        Returns: set of blocks in the loop\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\ndetector = LoopDetector(cfg)\nback_edges = detector.find_back_edges()\nprint(len(back_edges))",
    "solution": "class LoopDetector:\n    def __init__(self, cfg):\n        self.cfg = cfg\n        self.back_edges = []\n        self.visited = set()\n        self.on_stack = set()\n\n    def dfs_find_back_edges(self, block, path):\n        \"\"\"DFS to find back edges.\"\"\"\n        self.visited.add(block)\n        self.on_stack.add(block)\n\n        for succ in block.successors:\n            if succ in self.on_stack:\n                # Back edge detected\n                self.back_edges.append((block, succ))\n            elif succ not in self.visited:\n                self.dfs_find_back_edges(succ, path + [block])\n\n        self.on_stack.remove(block)\n\n    def find_back_edges(self):\n        \"\"\"Find back edges (edges to ancestors in DFS tree).\"\"\"\n        if not self.cfg:\n            return []\n\n        self.visited = set()\n        self.on_stack = set()\n        self.back_edges = []\n\n        # Start DFS from entry block\n        self.dfs_find_back_edges(self.cfg[0], [])\n\n        return self.back_edges\n\n    def find_natural_loop(self, back_edge):\n        \"\"\"\n        Find natural loop for a back edge.\n        Returns: set of blocks in the loop\n        \"\"\"\n        from_block, to_block = back_edge\n\n        # Loop includes header (to_block) and all blocks\n        # that can reach from_block without going through to_block\n        loop = {to_block, from_block}\n        worklist = [from_block]\n\n        while worklist:\n            block = worklist.pop()\n\n            # Find predecessors of block\n            for pred_block in self.cfg:\n                if block in pred_block.successors:\n                    if pred_block not in loop:\n                        loop.add(pred_block)\n                        if pred_block != to_block:\n                            worklist.append(pred_block)\n\n        return loop\n\n# Test\nclass BasicBlock:\n    def __init__(self, label):\n        self.label = label\n        self.instructions = []\n        self.successors = []\n\n# Create a simple loop\nb1 = BasicBlock('B0')\nb2 = BasicBlock('B1')\nb3 = BasicBlock('B2')\n\nb1.successors = [b2]\nb2.successors = [b3]\nb3.successors = [b2]  # Back edge\n\ncfg = [b1, b2, b3]\ndetector = LoopDetector(cfg)\nback_edges = detector.find_back_edges()\nprint(len(back_edges))",
    "testCases": [
      {
        "input": "has loop",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Detect back edge in loop"
      },
      {
        "input": "no loop",
        "expectedOutput": "0",
        "isHidden": false,
        "description": "No back edges in straight-line code"
      },
      {
        "input": "nested loops",
        "expectedOutput": "multiple",
        "isHidden": true,
        "description": "Detect multiple loops"
      }
    ],
    "hints": [
      "Use DFS to find back edges",
      "Back edge: edge to an ancestor in DFS tree",
      "Natural loop: all blocks that can reach back edge source",
      "Loop header: target of back edge"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex12",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Code Motion Out of Loops",
    "difficulty": 4,
    "description": "Identify loop-invariant computations and move them outside loops.",
    "starterCode": "class LoopOptimizer:\n    def __init__(self):\n        pass\n\n    def is_loop_invariant(self, instruction, loop_blocks, defs_in_loop):\n        \"\"\"\n        Check if instruction is loop-invariant.\n        (All operands are constant or defined outside loop)\n        \"\"\"\n        # Your code here\n        pass\n\n    def hoist_invariants(self, loop_blocks):\n        \"\"\"\n        Move loop-invariant code to preheader.\n        Returns: list of hoisted instructions\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\nopt = LoopOptimizer()\n# Define loop blocks...\nhoisted = opt.hoist_invariants(loop_blocks)",
    "solution": "class LoopOptimizer:\n    def __init__(self):\n        pass\n\n    def extract_variables(self, expr):\n        \"\"\"Extract variables from expression.\"\"\"\n        vars_used = []\n        tokens = expr.split()\n        for token in tokens:\n            if token.isalpha():\n                vars_used.append(token)\n        return vars_used\n\n    def get_definitions(self, blocks):\n        \"\"\"Get all variables defined in blocks.\"\"\"\n        defs = set()\n        for block in blocks:\n            for instr in block.instructions:\n                if '=' in instr:\n                    lhs = instr.split('=')[0].strip()\n                    defs.add(lhs)\n        return defs\n\n    def is_loop_invariant(self, instruction, loop_blocks, defs_in_loop):\n        \"\"\"\n        Check if instruction is loop-invariant.\n        \"\"\"\n        if '=' not in instruction:\n            return False\n\n        parts = instruction.split('=')\n        rhs = parts[1].strip()\n\n        # Check all variables used in RHS\n        for var in self.extract_variables(rhs):\n            # If variable is defined in loop, not invariant\n            if var in defs_in_loop:\n                return False\n\n        return True\n\n    def hoist_invariants(self, loop_blocks):\n        \"\"\"\n        Move loop-invariant code to preheader.\n        Returns: list of hoisted instructions\n        \"\"\"\n        hoisted = []\n        defs_in_loop = self.get_definitions(loop_blocks)\n\n        # Check each instruction in loop\n        for block in loop_blocks:\n            to_remove = []\n\n            for i, instr in enumerate(block.instructions):\n                if self.is_loop_invariant(instr, loop_blocks, defs_in_loop):\n                    hoisted.append(instr)\n                    to_remove.append(i)\n\n            # Remove hoisted instructions\n            for i in reversed(to_remove):\n                block.instructions.pop(i)\n\n        return hoisted\n\n# Test\nclass BasicBlock:\n    def __init__(self, label):\n        self.label = label\n        self.instructions = []\n        self.successors = []\n\nb1 = BasicBlock('B0')\nb1.instructions = ['x = a + b', 'y = x * c']  # x = a + b is invariant if a, b not in loop\n\nloop_blocks = [b1]\nopt = LoopOptimizer()\n# Assume a, b defined outside\nhoisted = opt.hoist_invariants(loop_blocks)\nprint(hoisted)",
    "testCases": [
      {
        "input": "invariant computation",
        "expectedOutput": "hoisted",
        "isHidden": false,
        "description": "Move invariant out of loop"
      },
      {
        "input": "variant computation",
        "expectedOutput": "not hoisted",
        "isHidden": false,
        "description": "Keep variant inside loop"
      },
      {
        "input": "multiple invariants",
        "expectedOutput": "all hoisted",
        "isHidden": true,
        "description": "Hoist multiple invariants"
      }
    ],
    "hints": [
      "Instruction is invariant if operands are not modified in loop",
      "Check if all variables used are defined outside loop",
      "Move invariant instructions to loop preheader",
      "Update definitions after moving code"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex13",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Strength Reduction",
    "difficulty": 3,
    "description": "Replace expensive operations in loops with cheaper equivalent operations (e.g., multiplication with addition).",
    "starterCode": "class StrengthReducer:\n    def __init__(self):\n        pass\n\n    def reduce_multiplication_in_loop(self, loop_blocks, induction_var):\n        \"\"\"\n        Replace i * c with repeated addition.\n        i is the induction variable, c is loop-invariant.\n        \"\"\"\n        # Your code here\n        pass\n\n# Example: i * 4 in loop becomes t = t + 4 each iteration\n# Test\nreducer = StrengthReducer()\n# Define loop...",
    "solution": "class StrengthReducer:\n    def __init__(self):\n        pass\n\n    def find_induction_variables(self, loop_blocks):\n        \"\"\"Find basic induction variables (i = i + c).\"\"\"\n        induction_vars = {}\n\n        for block in loop_blocks:\n            for instr in block.instructions:\n                if '=' in instr:\n                    parts = instr.split('=')\n                    lhs = parts[0].strip()\n                    rhs = parts[1].strip()\n\n                    # Check for i = i + c pattern\n                    tokens = rhs.split()\n                    if len(tokens) == 3 and tokens[1] == '+':\n                        if tokens[0] == lhs:\n                            try:\n                                increment = int(tokens[2])\n                                induction_vars[lhs] = increment\n                            except:\n                                pass\n\n        return induction_vars\n\n    def reduce_multiplication_in_loop(self, loop_blocks, induction_var, increment):\n        \"\"\"\n        Replace i * c with repeated addition.\n        \"\"\"\n        reduced = []\n\n        for block in loop_blocks:\n            new_instrs = []\n\n            for instr in block.instructions:\n                if '=' in instr:\n                    parts = instr.split('=')\n                    lhs = parts[0].strip()\n                    rhs = parts[1].strip()\n\n                    tokens = rhs.split()\n\n                    # Look for i * c pattern\n                    if (len(tokens) == 3 and tokens[1] == '*' and\n                        tokens[0] == induction_var):\n\n                        try:\n                            multiplier = int(tokens[2])\n                            # Replace with addition\n                            # New temp: t = t + (increment * multiplier)\n                            step = increment * multiplier\n\n                            # Generate: t = t + step\n                            new_temp = f\"{lhs}_reduced\"\n                            reduced.append({\n                                'original': instr,\n                                'reduced': f\"{new_temp} = {new_temp} + {step}\",\n                                'init': f\"{new_temp} = 0\"\n                            })\n\n                            new_instrs.append(f\"{lhs} = {new_temp}\")\n                        except:\n                            new_instrs.append(instr)\n                    else:\n                        new_instrs.append(instr)\n                else:\n                    new_instrs.append(instr)\n\n            block.instructions = new_instrs\n\n        return reduced\n\n# Test\nclass BasicBlock:\n    def __init__(self, label):\n        self.label = label\n        self.instructions = []\n\nb1 = BasicBlock('B0')\nb1.instructions = ['i = i + 1', 't = i * 4']\n\nloop_blocks = [b1]\nreducer = StrengthReducer()\nreduced = reducer.reduce_multiplication_in_loop(loop_blocks, 'i', 1)\nprint(reduced)",
    "testCases": [
      {
        "input": "i * c in loop",
        "expectedOutput": "reduced to addition",
        "isHidden": false,
        "description": "Replace multiplication with addition"
      },
      {
        "input": "no multiplication",
        "expectedOutput": "no change",
        "isHidden": false,
        "description": "No reduction if no multiplication"
      },
      {
        "input": "multiple reductions",
        "expectedOutput": "all reduced",
        "isHidden": true,
        "description": "Reduce multiple multiplications"
      }
    ],
    "hints": [
      "Identify induction variables (i = i + c)",
      "Find multiplications involving induction variable",
      "Replace i * k with temp = temp + (c * k)",
      "Initialize temp before loop"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex14",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Array Access Optimization",
    "difficulty": 4,
    "description": "Optimize array accesses in loops by computing address increments instead of full index calculations.",
    "starterCode": "class ArrayOptimizer:\n    def __init__(self):\n        pass\n\n    def optimize_array_access(self, loop_blocks, array_name, induction_var):\n        \"\"\"\n        Optimize array[i] in loop to pointer arithmetic.\n        Instead of: array[i]\n        Use: ptr = ptr + element_size\n        \"\"\"\n        # Your code here\n        pass\n\n# Example:\n# for i in range(n):\n#     x = array[i]\n# Becomes:\n# ptr = &array[0]\n# for i in range(n):\n#     x = *ptr\n#     ptr = ptr + 4",
    "solution": "class ArrayOptimizer:\n    def __init__(self):\n        self.element_size = 4  # Assume 4 bytes per element\n\n    def optimize_array_access(self, loop_blocks, array_name, induction_var):\n        \"\"\"\n        Optimize array[i] to pointer arithmetic.\n        \"\"\"\n        optimizations = []\n\n        for block in loop_blocks:\n            new_instrs = []\n\n            for instr in block.instructions:\n                # Look for array[i] pattern\n                if '[' in instr and ']' in instr:\n                    # Extract array access\n                    if array_name in instr and induction_var in instr:\n                        # Replace array[i] with pointer dereference\n                        ptr_name = f\"{array_name}_ptr\"\n\n                        # Original: x = array[i]\n                        # Becomes: x = *ptr\n                        parts = instr.split('=')\n                        lhs = parts[0].strip()\n\n                        new_instr = f\"{lhs} = *{ptr_name}\"\n                        new_instrs.append(new_instr)\n\n                        optimizations.append({\n                            'original': instr,\n                            'optimized': new_instr,\n                            'init': f\"{ptr_name} = &{array_name}[0]\",\n                            'increment': f\"{ptr_name} = {ptr_name} + {self.element_size}\"\n                        })\n                    else:\n                        new_instrs.append(instr)\n                else:\n                    new_instrs.append(instr)\n\n            block.instructions = new_instrs\n\n        return optimizations\n\n# Test\nclass BasicBlock:\n    def __init__(self, label):\n        self.label = label\n        self.instructions = []\n\nb1 = BasicBlock('B0')\nb1.instructions = ['i = i + 1', 'x = array[i]']\n\nloop_blocks = [b1]\nopt = ArrayOptimizer()\nresult = opt.optimize_array_access(loop_blocks, 'array', 'i')\nprint(result)",
    "testCases": [
      {
        "input": "array[i]",
        "expectedOutput": "pointer arithmetic",
        "isHidden": false,
        "description": "Convert to pointer increment"
      },
      {
        "input": "no array access",
        "expectedOutput": "no change",
        "isHidden": false,
        "description": "No optimization without array access"
      },
      {
        "input": "multiple arrays",
        "expectedOutput": "all optimized",
        "isHidden": true,
        "description": "Optimize multiple array accesses"
      }
    ],
    "hints": [
      "Detect array[i] pattern in loop",
      "Initialize pointer to array base before loop",
      "Replace array[i] with pointer dereference",
      "Increment pointer by element size each iteration"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex15",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Partial Redundancy Elimination",
    "difficulty": 5,
    "description": "Eliminate partial redundancies by moving computations to points where they are fully redundant.",
    "starterCode": "class PRE:\n    def __init__(self):\n        self.anticipated = {}  # Expressions anticipated at each point\n        self.available = {}   # Expressions available at each point\n        self.earliest = {}    # Earliest point to compute expression\n        self.latest = {}      # Latest point to compute expression\n\n    def compute_anticipated(self, cfg):\n        \"\"\"Compute anticipated expressions (backward).\"\"\"\n        # Your code here\n        pass\n\n    def compute_available(self, cfg):\n        \"\"\"Compute available expressions (forward).\"\"\"\n        # Your code here\n        pass\n\n    def insert_computations(self, cfg):\n        \"\"\"Insert computations at optimal points.\"\"\"\n        # Your code here\n        pass\n\n# Test\npre = PRE()\n# Build CFG...\npre.compute_anticipated(cfg)\npre.compute_available(cfg)\ninsertions = pre.insert_computations(cfg)",
    "solution": "class PRE:\n    def __init__(self):\n        self.anticipated = {}\n        self.available = {}\n        self.earliest = {}\n        self.latest = {}\n\n    def extract_expressions(self, block):\n        \"\"\"Extract all expressions computed in block.\"\"\"\n        exprs = set()\n\n        for instr in block.instructions:\n            if '=' in instr:\n                rhs = instr.split('=')[1].strip()\n                # Simplified: just use RHS as expression\n                if any(op in rhs for op in ['+', '-', '*', '/']):\n                    exprs.add(rhs)\n\n        return exprs\n\n    def compute_anticipated(self, cfg):\n        \"\"\"\n        Compute anticipated expressions (backward).\n        An expression is anticipated if it will be used before being killed.\n        \"\"\"\n        # Initialize\n        for i, block in enumerate(cfg):\n            block_id = f\"B{i}\"\n            self.anticipated[block_id] = set()\n\n        # Iterate backward\n        changed = True\n        while changed:\n            changed = False\n\n            for i in range(len(cfg) - 1, -1, -1):\n                block = cfg[i]\n                block_id = f\"B{i}\"\n\n                # Expressions used in this block\n                used = self.extract_expressions(block)\n\n                # Union of successors' anticipated\n                succ_ant = set()\n                for succ in block.successors:\n                    succ_id = f\"B{cfg.index(succ)}\"\n                    succ_ant.update(self.anticipated[succ_id])\n\n                # Anticipated = used U (succ_ant - killed)\n                new_ant = used | succ_ant\n\n                if new_ant != self.anticipated[block_id]:\n                    self.anticipated[block_id] = new_ant\n                    changed = True\n\n    def compute_available(self, cfg):\n        \"\"\"\n        Compute available expressions (forward).\n        \"\"\"\n        # Initialize\n        for i, block in enumerate(cfg):\n            block_id = f\"B{i}\"\n            self.available[block_id] = set()\n\n        # Iterate forward\n        changed = True\n        while changed:\n            changed = False\n\n            for i, block in enumerate(cfg):\n                block_id = f\"B{i}\"\n\n                # Expressions computed in this block\n                computed = self.extract_expressions(block)\n\n                # Intersection of predecessors' available\n                # (Simplified: assume entry has nothing available)\n                new_avail = computed\n\n                if new_avail != self.available[block_id]:\n                    self.available[block_id] = new_avail\n                    changed = True\n\n    def insert_computations(self, cfg):\n        \"\"\"\n        Insert computations at optimal points.\n        Insert where expression is anticipated but not available.\n        \"\"\"\n        insertions = []\n\n        for i, block in enumerate(cfg):\n            block_id = f\"B{i}\"\n\n            # Insert expressions that are anticipated but not available\n            to_insert = self.anticipated[block_id] - self.available[block_id]\n\n            for expr in to_insert:\n                insertions.append({\n                    'block': block_id,\n                    'expression': expr\n                })\n\n        return insertions\n\n# Test\nclass BasicBlock:\n    def __init__(self, label):\n        self.label = label\n        self.instructions = []\n        self.successors = []\n\nb1 = BasicBlock('B0')\nb1.instructions = ['x = a + b']\nb2 = BasicBlock('B1')\nb2.instructions = ['y = a + b']  # Partial redundancy\n\ncfg = [b1, b2]\npre = PRE()\npre.compute_anticipated(cfg)\npre.compute_available(cfg)\ninsertions = pre.insert_computations(cfg)\nprint(insertions)",
    "testCases": [
      {
        "input": "partial redundancy",
        "expectedOutput": "inserted",
        "isHidden": false,
        "description": "Insert computation to eliminate redundancy"
      },
      {
        "input": "fully available",
        "expectedOutput": "no insertion",
        "isHidden": false,
        "description": "No insertion if already available"
      },
      {
        "input": "complex CFG",
        "expectedOutput": "optimal insertions",
        "isHidden": true,
        "description": "Multiple optimal insertion points"
      }
    ],
    "hints": [
      "Anticipated: expression will be used on all paths",
      "Available: expression has been computed on all paths",
      "Insert where anticipated but not available",
      "Use data flow analysis: backward for anticipated, forward for available"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t4-ex16",
    "subjectId": "cs304",
    "topicId": "cs304-topic-4",
    "title": "Complete IR Optimizer",
    "difficulty": 5,
    "description": "Build a complete intermediate representation optimizer that applies multiple optimization passes in sequence.",
    "starterCode": "class CompleteOptimizer:\n    def __init__(self):\n        self.cfg = None\n\n    def build_cfg(self, instructions):\n        \"\"\"Build control flow graph.\"\"\"\n        # Your code here (use previous CFG builder)\n        pass\n\n    def optimize(self, instructions):\n        \"\"\"\n        Apply optimization passes:\n        1. Build CFG\n        2. Constant folding\n        3. Copy propagation\n        4. Dead code elimination\n        5. Common subexpression elimination\n        6. Loop optimizations\n        Returns: optimized code\n        \"\"\"\n        # Your code here\n        pass\n\n# Test\noptimizer = CompleteOptimizer()\ncode = [\n    'x = 2',\n    'y = 3',\n    'z = x + y',  # Can fold to z = 5\n    'a = z',      # Copy propagation\n    'b = x + y',  # CSE with z\n    'unused = 10' # Dead code\n]\noptimized = optimizer.optimize(code)\nprint(optimized)",
    "solution": "class CompleteOptimizer:\n    def __init__(self):\n        self.cfg = None\n        self.constants = {}\n\n    def constant_fold_pass(self, instructions):\n        \"\"\"Constant folding pass.\"\"\"\n        result = []\n\n        for instr in instructions:\n            if '=' not in instr:\n                result.append(instr)\n                continue\n\n            parts = instr.split('=')\n            lhs = parts[0].strip()\n            rhs = parts[1].strip()\n\n            tokens = rhs.split()\n\n            # Track constants\n            if len(tokens) == 1:\n                try:\n                    val = int(tokens[0])\n                    self.constants[lhs] = val\n                    result.append(instr)\n                except:\n                    result.append(instr)\n\n            elif len(tokens) == 3:\n                arg1, op, arg2 = tokens\n\n                # Replace with constants\n                val1 = self.constants.get(arg1, arg1)\n                val2 = self.constants.get(arg2, arg2)\n\n                # Fold if both constant\n                if isinstance(val1, int) and isinstance(val2, int):\n                    if op == '+':\n                        res = val1 + val2\n                    elif op == '-':\n                        res = val1 - val2\n                    elif op == '*':\n                        res = val1 * val2\n                    else:\n                        result.append(instr)\n                        continue\n\n                    result.append(f\"{lhs} = {res}\")\n                    self.constants[lhs] = res\n                else:\n                    result.append(instr)\n            else:\n                result.append(instr)\n\n        return result\n\n    def copy_propagation_pass(self, instructions):\n        \"\"\"Copy propagation pass.\"\"\"\n        copies = {}\n        result = []\n\n        for instr in instructions:\n            if '=' not in instr:\n                result.append(instr)\n                continue\n\n            parts = instr.split('=')\n            lhs = parts[0].strip()\n            rhs = parts[1].strip()\n\n            tokens = rhs.split()\n\n            # Track copies\n            if len(tokens) == 1 and tokens[0].isalpha():\n                copies[lhs] = tokens[0]\n                result.append(instr)\n\n            else:\n                # Substitute copies\n                new_tokens = []\n                for token in tokens:\n                    new_tokens.append(copies.get(token, token))\n\n                result.append(f\"{lhs} = {' '.join(new_tokens)}\")\n\n        return result\n\n    def dead_code_elimination_pass(self, instructions):\n        \"\"\"Dead code elimination pass.\"\"\"\n        # Find used variables\n        used = set()\n\n        for instr in instructions:\n            if 'return' in instr:\n                tokens = instr.split()\n                for token in tokens:\n                    if token.isalpha():\n                        used.add(token)\n\n        # Remove unused assignments (simplified)\n        result = []\n        for instr in instructions:\n            if '=' in instr:\n                lhs = instr.split('=')[0].strip()\n                # Keep if used or is a return\n                result.append(instr)\n            else:\n                result.append(instr)\n\n        return result\n\n    def cse_pass(self, instructions):\n        \"\"\"Common subexpression elimination.\"\"\"\n        expr_map = {}\n        result = []\n\n        for instr in instructions:\n            if '=' not in instr:\n                result.append(instr)\n                continue\n\n            parts = instr.split('=')\n            lhs = parts[0].strip()\n            rhs = parts[1].strip()\n\n            # Check if expression already computed\n            if rhs in expr_map:\n                result.append(f\"{lhs} = {expr_map[rhs]}\")\n            else:\n                result.append(instr)\n                expr_map[rhs] = lhs\n\n        return result\n\n    def optimize(self, instructions):\n        \"\"\"Apply all optimization passes.\"\"\"\n        code = instructions\n\n        # Multiple passes\n        for _ in range(2):  # Iterate to fixed point\n            code = self.constant_fold_pass(code)\n            code = self.copy_propagation_pass(code)\n            code = self.cse_pass(code)\n            code = self.dead_code_elimination_pass(code)\n\n        return code\n\n# Test\noptimizer = CompleteOptimizer()\ncode = [\n    'x = 2',\n    'y = 3',\n    'z = x + y',\n    'a = z',\n    'b = x + y',\n    'return a'\n]\noptimized = optimizer.optimize(code)\nprint(optimized)",
    "testCases": [
      {
        "input": "multiple optimizations",
        "expectedOutput": "optimized code",
        "isHidden": false,
        "description": "Apply all passes"
      },
      {
        "input": "constant folding",
        "expectedOutput": "constants folded",
        "isHidden": false,
        "description": "Constants are computed"
      },
      {
        "input": "CSE",
        "expectedOutput": "subexpressions eliminated",
        "isHidden": true,
        "description": "Common subexpressions removed"
      }
    ],
    "hints": [
      "Apply passes in sequence",
      "Iterate until no more changes (fixed point)",
      "Each pass should preserve semantics",
      "Combine multiple simple optimizations for best results"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex01",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Simple Expression Code Generator",
    "difficulty": 1,
    "description": "Implement a basic code generator that converts arithmetic expressions into three-address code instructions. Given an expression tree, generate a sequence of instructions.",
    "starterCode": "class CodeGenerator:\n    def __init__(self):\n        self.temp_count = 0\n        self.instructions = []\n\n    def new_temp(self):\n        \"\"\"Generate a new temporary variable name.\"\"\"\n        temp = f\"t{self.temp_count}\"\n        self.temp_count += 1\n        return temp\n\n    def generate(self, expr):\n        \"\"\"\n        Generate code for an expression.\n        expr is a dict with 'op' and 'left'/'right' for binary ops,\n        or 'value' for constants.\n        Returns the temporary variable holding the result.\n        \"\"\"\n        # TODO: Implement code generation\n        pass\n\n# Example usage:\n# gen = CodeGenerator()\n# expr = {'op': '+', 'left': {'value': 5}, 'right': {'value': 3}}\n# result = gen.generate(expr)\n# print(gen.instructions)",
    "solution": "class CodeGenerator:\n    def __init__(self):\n        self.temp_count = 0\n        self.instructions = []\n\n    def new_temp(self):\n        \"\"\"Generate a new temporary variable name.\"\"\"\n        temp = f\"t{self.temp_count}\"\n        self.temp_count += 1\n        return temp\n\n    def generate(self, expr):\n        \"\"\"\n        Generate code for an expression.\n        expr is a dict with 'op' and 'left'/'right' for binary ops,\n        or 'value' for constants.\n        Returns the temporary variable holding the result.\n        \"\"\"\n        if 'value' in expr:\n            # Constant value\n            return str(expr['value'])\n\n        # Binary operation\n        left_result = self.generate(expr['left'])\n        right_result = self.generate(expr['right'])\n        temp = self.new_temp()\n\n        self.instructions.append(f\"{temp} = {left_result} {expr['op']} {right_result}\")\n        return temp",
    "testCases": [
      {
        "input": "gen = CodeGenerator()\nexpr = {'op': '+', 'left': {'value': 5}, 'right': {'value': 3}}\nresult = gen.generate(expr)\nprint(','.join(gen.instructions))",
        "expectedOutput": "t0 = 5 + 3",
        "isHidden": false,
        "description": "Simple addition"
      },
      {
        "input": "gen = CodeGenerator()\nexpr = {'op': '*', 'left': {'op': '+', 'left': {'value': 2}, 'right': {'value': 3}}, 'right': {'value': 4}}\nresult = gen.generate(expr)\nprint(','.join(gen.instructions))",
        "expectedOutput": "t0 = 2 + 3,t1 = t0 * 4",
        "isHidden": false,
        "description": "Nested expression (2 + 3) * 4"
      },
      {
        "input": "gen = CodeGenerator()\nexpr = {'op': '-', 'left': {'op': '*', 'left': {'value': 5}, 'right': {'value': 6}}, 'right': {'op': '+', 'left': {'value': 2}, 'right': {'value': 1}}}\nresult = gen.generate(expr)\nprint(','.join(gen.instructions))",
        "isHidden": true,
        "description": "Complex expression (5 * 6) - (2 + 1)"
      }
    ],
    "hints": [
      "Use recursion to handle nested expressions",
      "Generate code for left and right operands first",
      "Create a new temporary for each operation result",
      "For constants, return the value directly without creating a temporary"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex02",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Instruction Selection with Costs",
    "difficulty": 2,
    "description": "Implement an instruction selector that chooses between multiple instruction patterns based on cost. Select the cheapest instruction sequence to implement operations.",
    "starterCode": "class InstructionSelector:\n    def __init__(self):\n        self.instructions = []\n        # Cost table: operation -> (instruction_template, cost)\n        self.patterns = {\n            'add_imm': ('ADD {dest}, {src}, #{imm}', 1),  # Add immediate\n            'add_reg': ('ADD {dest}, {src1}, {src2}', 1),  # Add registers\n            'load_imm': ('MOV {dest}, #{imm}', 1),  # Load immediate\n            'load_add': ('LDR {dest}, [#{addr}]', 2),  # Load from memory then add\n        }\n\n    def select_add(self, dest, left, right):\n        \"\"\"\n        Select best instruction(s) for addition.\n        left and right can be registers or immediate values (dict with 'imm' key).\n        Returns total cost.\n        \"\"\"\n        # TODO: Implement instruction selection\n        pass",
    "solution": "class InstructionSelector:\n    def __init__(self):\n        self.instructions = []\n        # Cost table: operation -> (instruction_template, cost)\n        self.patterns = {\n            'add_imm': ('ADD {dest}, {src}, #{imm}', 1),  # Add immediate\n            'add_reg': ('ADD {dest}, {src1}, {src2}', 1),  # Add registers\n            'load_imm': ('MOV {dest}, #{imm}', 1),  # Load immediate\n            'load_add': ('LDR {dest}, [#{addr}]', 2),  # Load from memory then add\n        }\n\n    def select_add(self, dest, left, right):\n        \"\"\"\n        Select best instruction(s) for addition.\n        left and right can be registers or immediate values (dict with 'imm' key).\n        Returns total cost.\n        \"\"\"\n        total_cost = 0\n\n        # Both are registers\n        if isinstance(left, str) and isinstance(right, str):\n            template, cost = self.patterns['add_reg']\n            self.instructions.append(template.format(dest=dest, src1=left, src2=right))\n            total_cost = cost\n\n        # Right is immediate\n        elif isinstance(left, str) and isinstance(right, dict) and 'imm' in right:\n            template, cost = self.patterns['add_imm']\n            self.instructions.append(template.format(dest=dest, src=left, imm=right['imm']))\n            total_cost = cost\n\n        # Left is immediate\n        elif isinstance(left, dict) and 'imm' in left and isinstance(right, str):\n            template, cost = self.patterns['add_imm']\n            self.instructions.append(template.format(dest=dest, src=right, imm=left['imm']))\n            total_cost = cost\n\n        # Both are immediates - need to load one first\n        elif isinstance(left, dict) and isinstance(right, dict):\n            template, cost = self.patterns['load_imm']\n            temp = 'r_temp'\n            self.instructions.append(template.format(dest=temp, imm=left['imm']))\n            total_cost += cost\n\n            template, cost = self.patterns['add_imm']\n            self.instructions.append(template.format(dest=dest, src=temp, imm=right['imm']))\n            total_cost += cost\n\n        return total_cost",
    "testCases": [
      {
        "input": "sel = InstructionSelector()\ncost = sel.select_add('r0', 'r1', {'imm': 5})\nprint(cost)\nprint(sel.instructions[0])",
        "expectedOutput": "1\nADD r0, r1, #5",
        "isHidden": false,
        "description": "Register + immediate"
      },
      {
        "input": "sel = InstructionSelector()\ncost = sel.select_add('r0', 'r1', 'r2')\nprint(cost)\nprint(sel.instructions[0])",
        "expectedOutput": "1\nADD r0, r1, r2",
        "isHidden": false,
        "description": "Register + register"
      },
      {
        "input": "sel = InstructionSelector()\ncost = sel.select_add('r0', {'imm': 10}, {'imm': 20})\nprint(cost)\nprint(len(sel.instructions))",
        "isHidden": true,
        "description": "Two immediates (requires load first)"
      }
    ],
    "hints": [
      "Check the types of operands to determine which pattern to use",
      "Immediate values are represented as dicts with an \"imm\" key",
      "When both operands are immediates, you need to load one into a register first",
      "Return the sum of costs for all instructions generated"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex03",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Basic Register Allocator",
    "difficulty": 3,
    "description": "Implement a simple register allocator that assigns registers to variables using a linear scan approach. Handle register spilling when registers run out.",
    "starterCode": "class RegisterAllocator:\n    def __init__(self, num_registers=4):\n        self.num_registers = num_registers\n        self.allocation = {}  # variable -> register\n        self.free_registers = [f\"r{i}\" for i in range(num_registers)]\n        self.spilled = []  # variables that had to be spilled\n\n    def allocate(self, variable, live_ranges):\n        \"\"\"\n        Allocate a register for a variable.\n        live_ranges: dict mapping variable -> (start, end) positions\n        Returns the allocated register or 'SPILL' if no registers available.\n        \"\"\"\n        # TODO: Implement register allocation\n        pass\n\n    def free(self, variable):\n        \"\"\"Free the register used by a variable.\"\"\"\n        # TODO: Implement register freeing\n        pass",
    "solution": "class RegisterAllocator:\n    def __init__(self, num_registers=4):\n        self.num_registers = num_registers\n        self.allocation = {}  # variable -> register\n        self.free_registers = [f\"r{i}\" for i in range(num_registers)]\n        self.spilled = []  # variables that had to be spilled\n\n    def allocate(self, variable, live_ranges):\n        \"\"\"\n        Allocate a register for a variable.\n        live_ranges: dict mapping variable -> (start, end) positions\n        Returns the allocated register or 'SPILL' if no registers available.\n        \"\"\"\n        if variable in self.allocation:\n            return self.allocation[variable]\n\n        # Try to allocate a free register\n        if self.free_registers:\n            reg = self.free_registers.pop(0)\n            self.allocation[variable] = reg\n            return reg\n\n        # No free registers - need to spill\n        # Find a variable to spill (choose one with earliest end time that hasn't ended yet)\n        current_pos = live_ranges[variable][0]\n        spill_candidate = None\n        earliest_end = float('inf')\n\n        for var, reg in self.allocation.items():\n            var_start, var_end = live_ranges.get(var, (0, float('inf')))\n            if var_end < current_pos:\n                # This variable's live range has ended, we can reuse its register\n                spill_candidate = var\n                break\n            elif var_end < earliest_end:\n                earliest_end = var_end\n                spill_candidate = var\n\n        if spill_candidate:\n            # Spill the candidate and reuse its register\n            reg = self.allocation[spill_candidate]\n            del self.allocation[spill_candidate]\n            self.spilled.append(spill_candidate)\n            self.allocation[variable] = reg\n            return reg\n\n        # All registers in use with longer live ranges\n        self.spilled.append(variable)\n        return 'SPILL'\n\n    def free(self, variable):\n        \"\"\"Free the register used by a variable.\"\"\"\n        if variable in self.allocation:\n            reg = self.allocation[variable]\n            del self.allocation[variable]\n            self.free_registers.append(reg)",
    "testCases": [
      {
        "input": "alloc = RegisterAllocator(num_registers=2)\nlive_ranges = {'a': (0, 5), 'b': (1, 3), 'c': (4, 8)}\nr1 = alloc.allocate('a', live_ranges)\nr2 = alloc.allocate('b', live_ranges)\nprint(f\"{r1},{r2}\")",
        "expectedOutput": "r0,r1",
        "isHidden": false,
        "description": "Simple allocation with available registers"
      },
      {
        "input": "alloc = RegisterAllocator(num_registers=2)\nlive_ranges = {'a': (0, 5), 'b': (1, 3), 'c': (2, 8)}\nr1 = alloc.allocate('a', live_ranges)\nr2 = alloc.allocate('b', live_ranges)\nr3 = alloc.allocate('c', live_ranges)\nprint(f\"{r3}\" if r3 == 'SPILL' else r3)",
        "isHidden": false,
        "description": "Allocation requiring spilling"
      },
      {
        "input": "alloc = RegisterAllocator(num_registers=2)\nlive_ranges = {'a': (0, 2), 'b': (3, 5), 'c': (6, 8)}\nr1 = alloc.allocate('a', live_ranges)\nalloc.free('a')\nr2 = alloc.allocate('b', live_ranges)\nprint(f\"{r1},{r2}\")",
        "isHidden": true,
        "description": "Register reuse after freeing"
      }
    ],
    "hints": [
      "Keep track of which registers are free and which are allocated",
      "When all registers are in use, choose a variable to spill",
      "A good spilling heuristic is to spill the variable with the earliest end time",
      "Check if any allocated variables have already ended their live range"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex04",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Live Range Analysis",
    "difficulty": 2,
    "description": "Implement live range analysis for variables in a sequence of three-address code instructions. Determine where each variable is live (defined and used).",
    "starterCode": "def compute_live_ranges(instructions):\n    \"\"\"\n    Compute live ranges for variables in three-address code.\n    instructions: list of strings like \"t0 = a + b\"\n    Returns: dict mapping variable -> (first_use, last_use) line numbers\n    \"\"\"\n    # TODO: Implement live range analysis\n    pass\n\n# Example:\n# instructions = [\"t0 = a + b\", \"t1 = t0 * c\", \"d = t1 + t0\"]\n# Returns: {'a': (0, 0), 'b': (0, 0), 't0': (0, 2), 'c': (1, 1), 't1': (1, 2), 'd': (2, 2)}",
    "solution": "def compute_live_ranges(instructions):\n    \"\"\"\n    Compute live ranges for variables in three-address code.\n    instructions: list of strings like \"t0 = a + b\"\n    Returns: dict mapping variable -> (first_use, last_use) line numbers\n    \"\"\"\n    live_ranges = {}\n\n    for i, instr in enumerate(instructions):\n        # Parse instruction: \"dest = operand1 op operand2\" or \"dest = operand\"\n        parts = instr.split('=')\n        if len(parts) != 2:\n            continue\n\n        dest = parts[0].strip()\n        expr = parts[1].strip()\n\n        # Update destination variable\n        if dest not in live_ranges:\n            live_ranges[dest] = (i, i)\n        else:\n            live_ranges[dest] = (live_ranges[dest][0], i)\n\n        # Extract and update operand variables\n        # Simple tokenization: split by operators and spaces\n        tokens = expr.replace('+', ' ').replace('-', ' ').replace('*', ' ').replace('/', ' ').split()\n\n        for token in tokens:\n            token = token.strip()\n            # Check if it's a variable (not a number)\n            if token and not token.isdigit():\n                if token not in live_ranges:\n                    live_ranges[token] = (i, i)\n                else:\n                    live_ranges[token] = (live_ranges[token][0], i)\n\n    return live_ranges",
    "testCases": [
      {
        "input": "instructions = [\"t0 = a + b\", \"t1 = t0 * c\", \"d = t1 + t0\"]\nranges = compute_live_ranges(instructions)\nprint(f\"{ranges['t0'][0]},{ranges['t0'][1]}\")",
        "expectedOutput": "0,2",
        "isHidden": false,
        "description": "Variable t0 used from line 0 to 2"
      },
      {
        "input": "instructions = [\"x = 5 + 3\", \"y = x * 2\", \"z = y + x\"]\nranges = compute_live_ranges(instructions)\nprint(len(ranges))",
        "expectedOutput": "3",
        "isHidden": false,
        "description": "Count of variables"
      },
      {
        "input": "instructions = [\"a = b + c\", \"d = a + e\", \"f = d - a\"]\nranges = compute_live_ranges(instructions)\nprint(f\"{ranges['a'][0]},{ranges['a'][1]}\")",
        "isHidden": true,
        "description": "Variable a live range"
      }
    ],
    "hints": [
      "Track both definitions (left side of =) and uses (right side)",
      "For each variable, record the first and last line where it appears",
      "Parse instructions by splitting on operators to find all variables",
      "Numbers are not variables and should be ignored"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex05",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Graph Coloring Register Allocation",
    "difficulty": 4,
    "description": "Implement register allocation using graph coloring. Build an interference graph and color it with K colors representing K registers.",
    "starterCode": "class GraphColoringAllocator:\n    def __init__(self, num_registers):\n        self.num_registers = num_registers\n        self.graph = {}  # adjacency list: variable -> set of interfering variables\n        self.colors = {}  # variable -> register number\n        self.spilled = []\n\n    def add_interference(self, var1, var2):\n        \"\"\"Add an interference edge between two variables.\"\"\"\n        # TODO: Implement\n        pass\n\n    def color_graph(self):\n        \"\"\"\n        Color the interference graph using greedy coloring.\n        Returns dict mapping variable -> register number (0 to num_registers-1).\n        Variables that can't be colored are added to self.spilled.\n        \"\"\"\n        # TODO: Implement graph coloring\n        pass",
    "solution": "class GraphColoringAllocator:\n    def __init__(self, num_registers):\n        self.num_registers = num_registers\n        self.graph = {}  # adjacency list: variable -> set of interfering variables\n        self.colors = {}  # variable -> register number\n        self.spilled = []\n\n    def add_interference(self, var1, var2):\n        \"\"\"Add an interference edge between two variables.\"\"\"\n        if var1 not in self.graph:\n            self.graph[var1] = set()\n        if var2 not in self.graph:\n            self.graph[var2] = set()\n\n        self.graph[var1].add(var2)\n        self.graph[var2].add(var1)\n\n    def color_graph(self):\n        \"\"\"\n        Color the interference graph using greedy coloring.\n        Returns dict mapping variable -> register number (0 to num_registers-1).\n        Variables that can't be colored are added to self.spilled.\n        \"\"\"\n        # Sort variables by degree (most constrained first)\n        variables = sorted(self.graph.keys(),\n                         key=lambda v: len(self.graph[v]),\n                         reverse=True)\n\n        for var in variables:\n            # Find colors used by neighbors\n            used_colors = set()\n            for neighbor in self.graph[var]:\n                if neighbor in self.colors:\n                    used_colors.add(self.colors[neighbor])\n\n            # Try to find an available color\n            available = None\n            for color in range(self.num_registers):\n                if color not in used_colors:\n                    available = color\n                    break\n\n            if available is not None:\n                self.colors[var] = available\n            else:\n                # Can't color this variable - spill it\n                self.spilled.append(var)\n\n        return self.colors",
    "testCases": [
      {
        "input": "alloc = GraphColoringAllocator(num_registers=3)\nalloc.add_interference('a', 'b')\nalloc.add_interference('b', 'c')\nalloc.add_interference('a', 'c')\ncolors = alloc.color_graph()\nprint(len(set(colors.values())))",
        "expectedOutput": "3",
        "isHidden": false,
        "description": "Triangle graph needs 3 colors"
      },
      {
        "input": "alloc = GraphColoringAllocator(num_registers=2)\nalloc.add_interference('a', 'b')\nalloc.add_interference('c', 'd')\ncolors = alloc.color_graph()\nprint(len(colors))",
        "expectedOutput": "4",
        "isHidden": false,
        "description": "Two independent edges need 2 colors"
      },
      {
        "input": "alloc = GraphColoringAllocator(num_registers=2)\nalloc.add_interference('a', 'b')\nalloc.add_interference('b', 'c')\nalloc.add_interference('c', 'a')\ncolors = alloc.color_graph()\nprint(len(alloc.spilled))",
        "isHidden": true,
        "description": "Triangle with only 2 registers requires spilling"
      }
    ],
    "hints": [
      "Build an adjacency list representation of the interference graph",
      "Use a greedy coloring algorithm: assign the lowest available color to each node",
      "Sort variables by degree (number of interferences) to improve coloring",
      "If no color is available for a variable, it must be spilled"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex06",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Instruction Scheduling with Dependencies",
    "difficulty": 3,
    "description": "Implement instruction scheduling that reorders instructions to minimize pipeline stalls while respecting data dependencies.",
    "starterCode": "class InstructionScheduler:\n    def __init__(self):\n        self.dependencies = {}  # instruction_id -> list of dependency instruction_ids\n\n    def add_dependency(self, instr_id, depends_on):\n        \"\"\"Add a dependency: instr_id depends on depends_on.\"\"\"\n        if instr_id not in self.dependencies:\n            self.dependencies[instr_id] = []\n        self.dependencies[instr_id].append(depends_on)\n\n    def schedule(self, instructions):\n        \"\"\"\n        Schedule instructions respecting dependencies.\n        instructions: list of instruction IDs\n        Returns: list of instruction IDs in scheduled order\n        \"\"\"\n        # TODO: Implement topological sort for scheduling\n        pass",
    "solution": "class InstructionScheduler:\n    def __init__(self):\n        self.dependencies = {}  # instruction_id -> list of dependency instruction_ids\n\n    def add_dependency(self, instr_id, depends_on):\n        \"\"\"Add a dependency: instr_id depends on depends_on.\"\"\"\n        if instr_id not in self.dependencies:\n            self.dependencies[instr_id] = []\n        self.dependencies[instr_id].append(depends_on)\n\n    def schedule(self, instructions):\n        \"\"\"\n        Schedule instructions respecting dependencies.\n        instructions: list of instruction IDs\n        Returns: list of instruction IDs in scheduled order\n        \"\"\"\n        # Initialize all instructions with empty dependencies if not present\n        for instr in instructions:\n            if instr not in self.dependencies:\n                self.dependencies[instr] = []\n\n        # Topological sort using Kahn's algorithm\n        # Count incoming edges\n        in_degree = {instr: 0 for instr in instructions}\n        for instr in instructions:\n            for dep in self.dependencies[instr]:\n                if dep in in_degree:\n                    in_degree[instr] += 1\n\n        # Queue of instructions with no dependencies\n        ready = [instr for instr in instructions if in_degree[instr] == 0]\n        scheduled = []\n\n        while ready:\n            # Pick instruction with no dependencies\n            current = ready.pop(0)\n            scheduled.append(current)\n\n            # Update in-degrees for instructions that depend on current\n            for instr in instructions:\n                if current in self.dependencies[instr]:\n                    in_degree[instr] -= 1\n                    if in_degree[instr] == 0 and instr not in scheduled:\n                        ready.append(instr)\n\n        return scheduled",
    "testCases": [
      {
        "input": "scheduler = InstructionScheduler()\nscheduler.add_dependency('i2', 'i1')\nscheduler.add_dependency('i3', 'i1')\nscheduled = scheduler.schedule(['i1', 'i2', 'i3'])\nprint(scheduled[0])",
        "expectedOutput": "i1",
        "isHidden": false,
        "description": "i1 must come first"
      },
      {
        "input": "scheduler = InstructionScheduler()\nscheduler.add_dependency('i2', 'i1')\nscheduler.add_dependency('i3', 'i2')\nscheduled = scheduler.schedule(['i1', 'i2', 'i3'])\nprint(','.join(scheduled))",
        "expectedOutput": "i1,i2,i3",
        "isHidden": false,
        "description": "Linear dependency chain"
      },
      {
        "input": "scheduler = InstructionScheduler()\nscheduler.add_dependency('i3', 'i1')\nscheduler.add_dependency('i3', 'i2')\nscheduled = scheduler.schedule(['i1', 'i2', 'i3'])\nprint(scheduled[2])",
        "isHidden": true,
        "description": "i3 depends on both i1 and i2"
      }
    ],
    "hints": [
      "Use topological sorting to order instructions",
      "Kahn's algorithm works by repeatedly selecting nodes with no incoming edges",
      "Track the in-degree (number of dependencies) for each instruction",
      "Instructions with no dependencies can be scheduled first"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex07",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Stack Frame Layout Generator",
    "difficulty": 2,
    "description": "Generate stack frame layout for a function, including space for local variables, parameters, and saved registers.",
    "starterCode": "class StackFrameGenerator:\n    def __init__(self, word_size=4):\n        self.word_size = word_size  # bytes per word\n\n    def generate_layout(self, num_params, local_vars, saved_regs):\n        \"\"\"\n        Generate stack frame layout.\n        num_params: number of parameters\n        local_vars: list of (name, size_in_words) tuples\n        saved_regs: list of register names to save\n\n        Returns: dict with 'total_size' and 'offsets' (dict of name->offset from FP)\n        \"\"\"\n        # TODO: Implement stack frame layout\n        # Layout (growing downward):\n        # - Parameters (above frame pointer)\n        # - Saved registers\n        # - Local variables\n        pass",
    "solution": "class StackFrameGenerator:\n    def __init__(self, word_size=4):\n        self.word_size = word_size  # bytes per word\n\n    def generate_layout(self, num_params, local_vars, saved_regs):\n        \"\"\"\n        Generate stack frame layout.\n        num_params: number of parameters\n        local_vars: list of (name, size_in_words) tuples\n        saved_regs: list of register names to save\n\n        Returns: dict with 'total_size' and 'offsets' (dict of name->offset from FP)\n        \"\"\"\n        offsets = {}\n        current_offset = 0\n\n        # Parameters are at positive offsets (above FP)\n        for i in range(num_params):\n            param_name = f\"param{i}\"\n            offsets[param_name] = (i + 1) * self.word_size\n\n        # Saved registers at negative offsets (below FP)\n        for i, reg in enumerate(saved_regs):\n            current_offset -= self.word_size\n            offsets[reg] = current_offset\n\n        # Local variables below saved registers\n        for name, size_words in local_vars:\n            current_offset -= size_words * self.word_size\n            offsets[name] = current_offset\n\n        # Total frame size is absolute value of most negative offset\n        total_size = abs(current_offset)\n\n        return {\n            'total_size': total_size,\n            'offsets': offsets\n        }",
    "testCases": [
      {
        "input": "gen = StackFrameGenerator(word_size=4)\nlayout = gen.generate_layout(2, [('x', 1), ('y', 1)], ['r1', 'r2'])\nprint(layout['total_size'])",
        "expectedOutput": "16",
        "isHidden": false,
        "description": "2 saved regs + 2 locals = 16 bytes"
      },
      {
        "input": "gen = StackFrameGenerator(word_size=4)\nlayout = gen.generate_layout(1, [('arr', 4)], ['r1'])\nprint(layout['offsets']['arr'])",
        "expectedOutput": "-20",
        "isHidden": false,
        "description": "Array offset below saved register"
      },
      {
        "input": "gen = StackFrameGenerator(word_size=4)\nlayout = gen.generate_layout(3, [], [])\nprint(layout['offsets']['param1'])",
        "isHidden": true,
        "description": "Parameter offset above frame pointer"
      }
    ],
    "hints": [
      "Parameters are at positive offsets from the frame pointer",
      "Saved registers and local variables are at negative offsets",
      "Allocate space in order: saved registers first, then local variables",
      "Total frame size is the sum of all space needed below the frame pointer"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex08",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Calling Convention Implementation",
    "difficulty": 3,
    "description": "Implement code generation for function calls following a specific calling convention (caller-save vs callee-save registers).",
    "starterCode": "class CallingConvention:\n    def __init__(self):\n        self.caller_save = ['r0', 'r1', 'r2']  # Caller must save these\n        self.callee_save = ['r3', 'r4', 'r5']  # Callee must save these\n        self.instructions = []\n\n    def generate_call(self, function_name, args, live_regs):\n        \"\"\"\n        Generate code for a function call.\n        args: list of argument values\n        live_regs: set of registers that are live across the call\n        \"\"\"\n        # TODO: Generate caller-side code\n        # 1. Save caller-save registers that are live\n        # 2. Move arguments to parameter registers\n        # 3. Call function\n        # 4. Restore caller-save registers\n        pass\n\n    def generate_prologue(self, used_callee_save):\n        \"\"\"Generate function prologue saving callee-save registers.\"\"\"\n        # TODO: Save registers that the function will use\n        pass\n\n    def generate_epilogue(self, used_callee_save):\n        \"\"\"Generate function epilogue restoring callee-save registers.\"\"\"\n        # TODO: Restore saved registers\n        pass",
    "solution": "class CallingConvention:\n    def __init__(self):\n        self.caller_save = ['r0', 'r1', 'r2']  # Caller must save these\n        self.callee_save = ['r3', 'r4', 'r5']  # Callee must save these\n        self.instructions = []\n\n    def generate_call(self, function_name, args, live_regs):\n        \"\"\"\n        Generate code for a function call.\n        args: list of argument values\n        live_regs: set of registers that are live across the call\n        \"\"\"\n        # Save caller-save registers that are live\n        saved = []\n        for reg in self.caller_save:\n            if reg in live_regs:\n                self.instructions.append(f\"PUSH {reg}\")\n                saved.append(reg)\n\n        # Move arguments to parameter registers\n        for i, arg in enumerate(args[:len(self.caller_save)]):\n            self.instructions.append(f\"MOV r{i}, {arg}\")\n\n        # Call function\n        self.instructions.append(f\"CALL {function_name}\")\n\n        # Restore caller-save registers in reverse order\n        for reg in reversed(saved):\n            self.instructions.append(f\"POP {reg}\")\n\n    def generate_prologue(self, used_callee_save):\n        \"\"\"Generate function prologue saving callee-save registers.\"\"\"\n        for reg in used_callee_save:\n            if reg in self.callee_save:\n                self.instructions.append(f\"PUSH {reg}\")\n\n    def generate_epilogue(self, used_callee_save):\n        \"\"\"Generate function epilogue restoring callee-save registers.\"\"\"\n        for reg in reversed(used_callee_save):\n            if reg in self.callee_save:\n                self.instructions.append(f\"POP {reg}\")",
    "testCases": [
      {
        "input": "cc = CallingConvention()\ncc.generate_call('foo', ['5', '10'], {'r0', 'r1'})\nprint(cc.instructions[0])",
        "expectedOutput": "PUSH r0",
        "isHidden": false,
        "description": "Save live caller-save registers"
      },
      {
        "input": "cc = CallingConvention()\ncc.generate_prologue(['r3', 'r4'])\nprint(len(cc.instructions))",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Prologue saves 2 callee-save registers"
      },
      {
        "input": "cc = CallingConvention()\ncc.generate_call('bar', ['1', '2', '3'], {'r1'})\ncount = sum(1 for i in cc.instructions if 'MOV' in i)\nprint(count)",
        "isHidden": true,
        "description": "Count MOV instructions for arguments"
      }
    ],
    "hints": [
      "Caller-save registers must be saved by the caller before the call",
      "Only save registers that are actually live across the call",
      "Use PUSH/POP to save/restore registers on the stack",
      "Restore registers in reverse order of saving"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex09",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Peephole Optimizer",
    "difficulty": 2,
    "description": "Implement a peephole optimizer that applies local optimizations to a sequence of instructions (e.g., removing redundant loads/stores).",
    "starterCode": "class PeepholeOptimizer:\n    def optimize(self, instructions):\n        \"\"\"\n        Apply peephole optimizations to instruction sequence.\n        Optimizations:\n        1. Remove redundant MOV: MOV r1, r1 -> (removed)\n        2. Combine ADD+ADD: ADD r1, r1, #1; ADD r1, r1, #2 -> ADD r1, r1, #3\n        3. Remove dead store: MOV r1, #5; MOV r1, #10 -> MOV r1, #10\n\n        Returns: optimized instruction list\n        \"\"\"\n        # TODO: Implement peephole optimizations\n        pass",
    "solution": "class PeepholeOptimizer:\n    def optimize(self, instructions):\n        \"\"\"\n        Apply peephole optimizations to instruction sequence.\n        Optimizations:\n        1. Remove redundant MOV: MOV r1, r1 -> (removed)\n        2. Combine ADD+ADD: ADD r1, r1, #1; ADD r1, r1, #2 -> ADD r1, r1, #3\n        3. Remove dead store: MOV r1, #5; MOV r1, #10 -> MOV r1, #10\n\n        Returns: optimized instruction list\n        \"\"\"\n        optimized = []\n        i = 0\n\n        while i < len(instructions):\n            instr = instructions[i]\n\n            # Check for redundant MOV r, r\n            if instr.startswith('MOV'):\n                parts = instr.split(',')\n                if len(parts) == 2:\n                    dest = parts[0].replace('MOV', '').strip()\n                    src = parts[1].strip()\n                    if dest == src:\n                        i += 1\n                        continue  # Skip this instruction\n\n            # Check for consecutive ADD to same register with immediates\n            if i + 1 < len(instructions) and instr.startswith('ADD'):\n                next_instr = instructions[i + 1]\n                if next_instr.startswith('ADD'):\n                    # Parse: ADD r1, r1, #N\n                    parts1 = instr.split(',')\n                    parts2 = next_instr.split(',')\n\n                    if len(parts1) == 3 and len(parts2) == 3:\n                        dest1 = parts1[0].replace('ADD', '').strip()\n                        src1 = parts1[1].strip()\n                        imm1 = parts1[2].strip()\n\n                        dest2 = parts2[0].replace('ADD', '').strip()\n                        src2 = parts2[1].strip()\n                        imm2 = parts2[2].strip()\n\n                        if (dest1 == dest2 == src1 == src2 and\n                            imm1.startswith('#') and imm2.startswith('#')):\n                            val1 = int(imm1[1:])\n                            val2 = int(imm2[1:])\n                            combined = f\"ADD {dest1}, {src1}, #{val1 + val2}\"\n                            optimized.append(combined)\n                            i += 2\n                            continue\n\n            # Check for dead store (consecutive MOV to same register)\n            if i + 1 < len(instructions) and instr.startswith('MOV'):\n                next_instr = instructions[i + 1]\n                if next_instr.startswith('MOV'):\n                    parts1 = instr.split(',')\n                    parts2 = next_instr.split(',')\n\n                    if len(parts1) == 2 and len(parts2) == 2:\n                        dest1 = parts1[0].replace('MOV', '').strip()\n                        dest2 = parts2[0].replace('MOV', '').strip()\n\n                        if dest1 == dest2:\n                            # Skip first MOV, keep second\n                            i += 1\n                            continue\n\n            optimized.append(instr)\n            i += 1\n\n        return optimized",
    "testCases": [
      {
        "input": "opt = PeepholeOptimizer()\nresult = opt.optimize(['MOV r1, r1', 'ADD r2, r3, #5'])\nprint(len(result))",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Remove redundant MOV"
      },
      {
        "input": "opt = PeepholeOptimizer()\nresult = opt.optimize(['ADD r1, r1, #5', 'ADD r1, r1, #3'])\nprint(result[0])",
        "expectedOutput": "ADD r1, r1, #8",
        "isHidden": false,
        "description": "Combine consecutive ADDs"
      },
      {
        "input": "opt = PeepholeOptimizer()\nresult = opt.optimize(['MOV r1, #5', 'MOV r1, #10', 'ADD r1, r1, #1'])\nprint(len(result))",
        "isHidden": true,
        "description": "Remove dead store"
      }
    ],
    "hints": [
      "Process instructions in sequence, looking for patterns",
      "For redundant MOV, check if source and destination are the same",
      "For ADD combining, check that both instructions use the same register",
      "For dead stores, check if consecutive instructions write to the same register"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex10",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Spill Code Generator",
    "difficulty": 3,
    "description": "Generate spill code to save and restore variables to/from memory when registers are exhausted.",
    "starterCode": "class SpillCodeGenerator:\n    def __init__(self):\n        self.spill_offset = 0  # Current offset in spill area\n        self.spill_map = {}  # variable -> memory offset\n\n    def allocate_spill_slot(self, variable):\n        \"\"\"Allocate a spill slot for a variable. Returns memory offset.\"\"\"\n        # TODO: Implement spill slot allocation\n        pass\n\n    def generate_spill(self, variable, register):\n        \"\"\"Generate code to spill variable from register to memory.\"\"\"\n        # TODO: Generate STORE instruction\n        pass\n\n    def generate_reload(self, variable, register):\n        \"\"\"Generate code to reload variable from memory to register.\"\"\"\n        # TODO: Generate LOAD instruction\n        pass",
    "solution": "class SpillCodeGenerator:\n    def __init__(self):\n        self.spill_offset = 0  # Current offset in spill area\n        self.spill_map = {}  # variable -> memory offset\n\n    def allocate_spill_slot(self, variable):\n        \"\"\"Allocate a spill slot for a variable. Returns memory offset.\"\"\"\n        if variable not in self.spill_map:\n            self.spill_map[variable] = self.spill_offset\n            self.spill_offset += 4  # Assume 4-byte slots\n        return self.spill_map[variable]\n\n    def generate_spill(self, variable, register):\n        \"\"\"Generate code to spill variable from register to memory.\"\"\"\n        offset = self.allocate_spill_slot(variable)\n        return f\"STORE {register}, [SP + {offset}]\"\n\n    def generate_reload(self, variable, register):\n        \"\"\"Generate code to reload variable from memory to register.\"\"\"\n        if variable not in self.spill_map:\n            raise ValueError(f\"Variable {variable} has not been spilled\")\n        offset = self.spill_map[variable]\n        return f\"LOAD {register}, [SP + {offset}]\"",
    "testCases": [
      {
        "input": "gen = SpillCodeGenerator()\ncode = gen.generate_spill('x', 'r1')\nprint(code)",
        "expectedOutput": "STORE r1, [SP + 0]",
        "isHidden": false,
        "description": "First spill at offset 0"
      },
      {
        "input": "gen = SpillCodeGenerator()\ngen.generate_spill('x', 'r1')\ngen.generate_spill('y', 'r2')\ncode = gen.generate_reload('x', 'r3')\nprint(code)",
        "expectedOutput": "LOAD r3, [SP + 0]",
        "isHidden": false,
        "description": "Reload previously spilled variable"
      },
      {
        "input": "gen = SpillCodeGenerator()\ngen.generate_spill('a', 'r1')\ngen.generate_spill('b', 'r2')\noffset_b = gen.spill_map['b']\nprint(offset_b)",
        "isHidden": true,
        "description": "Second variable at offset 4"
      }
    ],
    "hints": [
      "Maintain a mapping from variables to their spill locations",
      "Allocate spill slots sequentially with a fixed size (e.g., 4 bytes)",
      "Use stack pointer (SP) relative addressing for spill locations",
      "Generate STORE instructions to save and LOAD instructions to reload"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex11",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Target-Specific Instruction Mapper",
    "difficulty": 3,
    "description": "Map generic IR operations to target-specific machine instructions, handling different addressing modes and instruction variants.",
    "starterCode": "class InstructionMapper:\n    def __init__(self):\n        # Target machine has these instruction formats:\n        # ADD reg, reg, reg\n        # ADD reg, reg, #imm\n        # LOAD reg, [reg + #offset]\n        # STORE reg, [reg + #offset]\n        pass\n\n    def map_binary_op(self, op, dest, left, right):\n        \"\"\"\n        Map a binary operation to target instructions.\n        Operands can be: {'reg': 'r0'}, {'imm': 5}, or {'mem': addr}\n        Returns list of instructions.\n        \"\"\"\n        # TODO: Implement mapping logic\n        pass",
    "solution": "class InstructionMapper:\n    def __init__(self):\n        # Target machine has these instruction formats:\n        # ADD reg, reg, reg\n        # ADD reg, reg, #imm\n        # LOAD reg, [reg + #offset]\n        # STORE reg, [reg + #offset]\n        pass\n\n    def map_binary_op(self, op, dest, left, right):\n        \"\"\"\n        Map a binary operation to target instructions.\n        Operands can be: {'reg': 'r0'}, {'imm': 5}, or {'mem': addr}\n        Returns list of instructions.\n        \"\"\"\n        instructions = []\n\n        # Handle different operand types\n        left_reg = None\n        right_reg = None\n\n        # Load left operand\n        if 'reg' in left:\n            left_reg = left['reg']\n        elif 'imm' in left:\n            left_reg = 'temp0'\n            instructions.append(f\"MOV {left_reg}, #{left['imm']}\")\n        elif 'mem' in left:\n            left_reg = 'temp0'\n            instructions.append(f\"LOAD {left_reg}, [{left['mem']}]\")\n\n        # Load right operand\n        if 'reg' in right:\n            right_reg = right['reg']\n        elif 'imm' in right:\n            # Can use immediate addressing mode\n            instructions.append(f\"{op.upper()} {dest}, {left_reg}, #{right['imm']}\")\n            return instructions\n        elif 'mem' in right:\n            right_reg = 'temp1'\n            instructions.append(f\"LOAD {right_reg}, [{right['mem']}]\")\n\n        # Generate the operation\n        instructions.append(f\"{op.upper()} {dest}, {left_reg}, {right_reg}\")\n\n        return instructions",
    "testCases": [
      {
        "input": "mapper = InstructionMapper()\ninstrs = mapper.map_binary_op('add', 'r0', {'reg': 'r1'}, {'imm': 5})\nprint(instrs[-1])",
        "expectedOutput": "ADD r0, r1, #5",
        "isHidden": false,
        "description": "Register + immediate"
      },
      {
        "input": "mapper = InstructionMapper()\ninstrs = mapper.map_binary_op('add', 'r0', {'imm': 10}, {'reg': 'r2'})\nprint(len(instrs))",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Immediate needs to be loaded first"
      },
      {
        "input": "mapper = InstructionMapper()\ninstrs = mapper.map_binary_op('add', 'r0', {'reg': 'r1'}, {'reg': 'r2'})\nprint(instrs[0])",
        "isHidden": true,
        "description": "Register + register"
      }
    ],
    "hints": [
      "Check the type of each operand (register, immediate, or memory)",
      "Immediates can often be used directly in arithmetic instructions",
      "Memory operands need to be loaded into temporary registers first",
      "Build the instruction sequence step by step"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex12",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Basic Block Code Generator",
    "difficulty": 4,
    "description": "Generate optimized code for a basic block by performing instruction selection and basic register allocation within the block.",
    "starterCode": "class BasicBlockCodeGen:\n    def __init__(self, num_registers=4):\n        self.num_registers = num_registers\n        self.instructions = []\n        self.register_map = {}  # temp var -> register\n        self.next_reg = 0\n\n    def get_register(self, temp):\n        \"\"\"Allocate or retrieve register for a temporary variable.\"\"\"\n        # TODO: Implement register allocation within block\n        pass\n\n    def generate_code(self, three_address_code):\n        \"\"\"\n        Generate machine code for a basic block.\n        three_address_code: list of (dest, op, left, right) tuples\n        \"\"\"\n        # TODO: Generate code with register allocation\n        pass",
    "solution": "class BasicBlockCodeGen:\n    def __init__(self, num_registers=4):\n        self.num_registers = num_registers\n        self.instructions = []\n        self.register_map = {}  # temp var -> register\n        self.next_reg = 0\n\n    def get_register(self, temp):\n        \"\"\"Allocate or retrieve register for a temporary variable.\"\"\"\n        if temp not in self.register_map:\n            if self.next_reg < self.num_registers:\n                self.register_map[temp] = f\"r{self.next_reg}\"\n                self.next_reg += 1\n            else:\n                # Simple strategy: reuse r0 when out of registers\n                self.register_map[temp] = \"r0\"\n        return self.register_map[temp]\n\n    def generate_code(self, three_address_code):\n        \"\"\"\n        Generate machine code for a basic block.\n        three_address_code: list of (dest, op, left, right) tuples\n        \"\"\"\n        for dest, op, left, right in three_address_code:\n            # Get or allocate registers for operands\n            if isinstance(left, str) and left.startswith('t'):\n                left_reg = self.get_register(left)\n            else:\n                left_reg = str(left)\n\n            if isinstance(right, str) and right.startswith('t'):\n                right_reg = self.get_register(right)\n            else:\n                right_reg = str(right)\n\n            # Allocate register for destination\n            dest_reg = self.get_register(dest)\n\n            # Generate instruction\n            if str(right_reg).isdigit():\n                # Immediate operand\n                self.instructions.append(f\"{op.upper()} {dest_reg}, {left_reg}, #{right_reg}\")\n            else:\n                # Register operand\n                self.instructions.append(f\"{op.upper()} {dest_reg}, {left_reg}, {right_reg}\")\n\n        return self.instructions",
    "testCases": [
      {
        "input": "gen = BasicBlockCodeGen(num_registers=4)\ncode = [('t0', 'add', 5, 3), ('t1', 'mul', 't0', 2)]\ninstrs = gen.generate_code(code)\nprint(len(instrs))",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Two instructions generated"
      },
      {
        "input": "gen = BasicBlockCodeGen(num_registers=4)\ncode = [('t0', 'add', 10, 20)]\ninstrs = gen.generate_code(code)\nprint(gen.register_map['t0'])",
        "expectedOutput": "r0",
        "isHidden": false,
        "description": "t0 allocated to r0"
      },
      {
        "input": "gen = BasicBlockCodeGen(num_registers=2)\ncode = [('t0', 'add', 1, 2), ('t1', 'add', 3, 4), ('t2', 'add', 't0', 't1')]\ninstrs = gen.generate_code(code)\nprint(len(instrs))",
        "isHidden": true,
        "description": "Multiple temporaries with limited registers"
      }
    ],
    "hints": [
      "Maintain a mapping from temporary variables to registers",
      "Allocate registers sequentially until you run out",
      "Check if operands are temporaries or immediate values",
      "Use different instruction formats for immediate vs register operands"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex13",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Branch Optimization",
    "difficulty": 2,
    "description": "Optimize conditional branches by inverting conditions and eliminating unnecessary jumps.",
    "starterCode": "class BranchOptimizer:\n    def optimize_branch_chain(self, instructions):\n        \"\"\"\n        Optimize branch instructions.\n        - Remove branches to next instruction\n        - Invert conditions to eliminate jumps\n\n        Instructions format: list of (label, instruction) tuples\n        \"\"\"\n        # TODO: Implement branch optimizations\n        pass",
    "solution": "class BranchOptimizer:\n    def optimize_branch_chain(self, instructions):\n        \"\"\"\n        Optimize branch instructions.\n        - Remove branches to next instruction\n        - Invert conditions to eliminate jumps\n\n        Instructions format: list of (label, instruction) tuples\n        \"\"\"\n        optimized = []\n\n        for i, (label, instr) in enumerate(instructions):\n            skip = False\n\n            # Check for branch to next instruction\n            if instr.startswith('JMP') or instr.startswith('BEQ') or instr.startswith('BNE'):\n                parts = instr.split()\n                if len(parts) == 2:\n                    target = parts[1]\n\n                    # Check if target is the next instruction\n                    if i + 1 < len(instructions):\n                        next_label = instructions[i + 1][0]\n                        if target == next_label:\n                            # Branch to next instruction - remove it\n                            skip = True\n\n            if not skip:\n                optimized.append((label, instr))\n\n        return optimized",
    "testCases": [
      {
        "input": "opt = BranchOptimizer()\ninstrs = [('L1', 'ADD r0, r1, #1'), ('L2', 'JMP L3'), ('L3', 'MOV r2, r0')]\nresult = opt.optimize_branch_chain(instrs)\nprint(len(result))",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Remove jump to next instruction"
      },
      {
        "input": "opt = BranchOptimizer()\ninstrs = [('L1', 'BEQ L2'), ('L2', 'ADD r0, r1, #1')]\nresult = opt.optimize_branch_chain(instrs)\nprint(len(result))",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Remove conditional branch to next"
      },
      {
        "input": "opt = BranchOptimizer()\ninstrs = [('L1', 'JMP L5'), ('L2', 'ADD r0, #1'), ('L5', 'MOV r1, r0')]\nresult = opt.optimize_branch_chain(instrs)\nprint(len(result))",
        "isHidden": true,
        "description": "Keep jump to non-adjacent label"
      }
    ],
    "hints": [
      "Check if a branch target is the immediately following instruction",
      "Compare the target label with the label of the next instruction",
      "Remove branches to the next instruction as they are redundant",
      "Preserve other branches that jump to non-adjacent locations"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex14",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Constant Pool Generator",
    "difficulty": 2,
    "description": "Generate a constant pool for large immediate values that cannot be encoded directly in instructions.",
    "starterCode": "class ConstantPoolGenerator:\n    def __init__(self, max_immediate=255):\n        self.max_immediate = max_immediate\n        self.pool = {}  # value -> label\n        self.pool_counter = 0\n\n    def add_constant(self, value):\n        \"\"\"Add a constant to the pool if it's too large. Returns label or None.\"\"\"\n        # TODO: Check if value needs to go in pool\n        # Return pool label if needed, None otherwise\n        pass\n\n    def generate_load(self, reg, value):\n        \"\"\"Generate instruction to load a value into a register.\"\"\"\n        # TODO: Use immediate or pool load based on value size\n        pass",
    "solution": "class ConstantPoolGenerator:\n    def __init__(self, max_immediate=255):\n        self.max_immediate = max_immediate\n        self.pool = {}  # value -> label\n        self.pool_counter = 0\n\n    def add_constant(self, value):\n        \"\"\"Add a constant to the pool if it's too large. Returns label or None.\"\"\"\n        if abs(value) <= self.max_immediate:\n            return None  # Can use immediate encoding\n\n        if value not in self.pool:\n            label = f\"CONST_{self.pool_counter}\"\n            self.pool[value] = label\n            self.pool_counter += 1\n\n        return self.pool[value]\n\n    def generate_load(self, reg, value):\n        \"\"\"Generate instruction to load a value into a register.\"\"\"\n        label = self.add_constant(value)\n\n        if label is None:\n            # Small value - use immediate\n            return f\"MOV {reg}, #{value}\"\n        else:\n            # Large value - load from pool\n            return f\"LDR {reg}, ={label}\"",
    "testCases": [
      {
        "input": "gen = ConstantPoolGenerator(max_immediate=255)\ninstr = gen.generate_load('r0', 100)\nprint(instr)",
        "expectedOutput": "MOV r0, #100",
        "isHidden": false,
        "description": "Small constant uses immediate"
      },
      {
        "input": "gen = ConstantPoolGenerator(max_immediate=255)\ninstr = gen.generate_load('r0', 1000)\nprint(instr)",
        "expectedOutput": "LDR r0, =CONST_0",
        "isHidden": false,
        "description": "Large constant uses pool"
      },
      {
        "input": "gen = ConstantPoolGenerator(max_immediate=255)\ngen.generate_load('r0', 1000)\ngen.generate_load('r1', 1000)\nprint(len(gen.pool))",
        "isHidden": true,
        "description": "Same constant reuses pool entry"
      }
    ],
    "hints": [
      "Compare constant values against the maximum immediate value",
      "Create a unique label for each distinct large constant",
      "Reuse pool entries for the same constant value",
      "Use MOV for small values and LDR for pool references"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex15",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Condition Code Optimizer",
    "difficulty": 3,
    "description": "Optimize the use of condition codes by eliminating redundant comparisons and reusing previously set flags.",
    "starterCode": "class ConditionCodeOptimizer:\n    def __init__(self):\n        self.last_flags_set = None  # Track what last set the flags\n\n    def optimize(self, instructions):\n        \"\"\"\n        Optimize condition code usage.\n        - Remove redundant CMP instructions\n        - Track operations that set flags\n\n        Instruction format: strings like \"ADD r0, r1, r2\", \"CMP r0, #0\", \"BEQ L1\"\n        \"\"\"\n        # TODO: Implement optimization\n        pass",
    "solution": "class ConditionCodeOptimizer:\n    def __init__(self):\n        self.last_flags_set = None  # Track what last set the flags\n\n    def optimize(self, instructions):\n        \"\"\"\n        Optimize condition code usage.\n        - Remove redundant CMP instructions\n        - Track operations that set flags\n\n        Instruction format: strings like \"ADD r0, r1, r2\", \"CMP r0, #0\", \"BEQ L1\"\n        \"\"\"\n        optimized = []\n\n        for instr in instructions:\n            parts = instr.split()\n            op = parts[0]\n\n            # Check for redundant CMP\n            if op == 'CMP':\n                # CMP sets flags based on comparison\n                operands = ' '.join(parts[1:])\n\n                # If the same comparison was just done, skip it\n                if self.last_flags_set == ('CMP', operands):\n                    continue  # Redundant comparison\n\n                self.last_flags_set = ('CMP', operands)\n                optimized.append(instr)\n\n            # Arithmetic operations that set flags\n            elif op in ['ADD', 'SUB', 'AND', 'OR']:\n                # These operations set flags as a side effect\n                # Extract destination register\n                dest = parts[1].rstrip(',')\n                self.last_flags_set = (op, dest)\n                optimized.append(instr)\n\n            # Branch instructions use flags but don't modify them\n            elif op in ['BEQ', 'BNE', 'BLT', 'BGT']:\n                optimized.append(instr)\n                # Don't clear last_flags_set - flags are still valid\n\n            # Other instructions may clobber flags\n            else:\n                self.last_flags_set = None\n                optimized.append(instr)\n\n        return optimized",
    "testCases": [
      {
        "input": "opt = ConditionCodeOptimizer()\ninstrs = ['CMP r0, #0', 'BEQ L1', 'CMP r0, #0', 'BNE L2']\nresult = opt.optimize(instrs)\nprint(len(result))",
        "expectedOutput": "3",
        "isHidden": false,
        "description": "Remove redundant second CMP"
      },
      {
        "input": "opt = ConditionCodeOptimizer()\ninstrs = ['SUB r0, r1, r2', 'CMP r0, #0', 'BEQ L1']\nresult = opt.optimize(instrs)\nprint(len(result))",
        "expectedOutput": "3",
        "isHidden": false,
        "description": "SUB sets flags but CMP is different comparison"
      },
      {
        "input": "opt = ConditionCodeOptimizer()\ninstrs = ['CMP r0, #5', 'BEQ L1', 'ADD r1, r2, #1', 'CMP r0, #5']\nresult = opt.optimize(instrs)\nprint(len(result))",
        "isHidden": true,
        "description": "ADD clobbers flags, CMP needed again"
      }
    ],
    "hints": [
      "Track what operation last set the condition flags",
      "Arithmetic operations like ADD and SUB set flags as a side effect",
      "Branch instructions use flags but don't modify them",
      "Remove consecutive identical CMP instructions"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t5-ex16",
    "subjectId": "cs304",
    "topicId": "cs304-topic-5",
    "title": "Advanced Register Coalescing",
    "difficulty": 5,
    "description": "Implement register coalescing to reduce copy instructions by assigning the same register to variables connected by move operations.",
    "starterCode": "class RegisterCoalescer:\n    def __init__(self):\n        self.copies = []  # List of (dest, src) copy operations\n        self.interference = {}  # Interference graph\n        self.coalesced = {}  # Variable -> coalesced representative\n\n    def add_copy(self, dest, src):\n        \"\"\"Record a copy operation.\"\"\"\n        self.copies.append((dest, src))\n\n    def add_interference(self, var1, var2):\n        \"\"\"Record that two variables interfere.\"\"\"\n        if var1 not in self.interference:\n            self.interference[var1] = set()\n        if var2 not in self.interference:\n            self.interference[var2] = set()\n        self.interference[var1].add(var2)\n        self.interference[var2].add(var1)\n\n    def can_coalesce(self, dest, src):\n        \"\"\"Check if dest and src can be coalesced (don't interfere).\"\"\"\n        # TODO: Implement coalescing check\n        pass\n\n    def coalesce(self):\n        \"\"\"Perform register coalescing. Returns mapping of variables to coalesced names.\"\"\"\n        # TODO: Implement coalescing algorithm\n        pass",
    "solution": "class RegisterCoalescer:\n    def __init__(self):\n        self.copies = []  # List of (dest, src) copy operations\n        self.interference = {}  # Interference graph\n        self.coalesced = {}  # Variable -> coalesced representative\n\n    def add_copy(self, dest, src):\n        \"\"\"Record a copy operation.\"\"\"\n        self.copies.append((dest, src))\n\n    def add_interference(self, var1, var2):\n        \"\"\"Record that two variables interfere.\"\"\"\n        if var1 not in self.interference:\n            self.interference[var1] = set()\n        if var2 not in self.interference:\n            self.interference[var2] = set()\n        self.interference[var1].add(var2)\n        self.interference[var2].add(var1)\n\n    def find_representative(self, var):\n        \"\"\"Find the coalesced representative for a variable.\"\"\"\n        if var not in self.coalesced:\n            return var\n        # Path compression\n        if self.coalesced[var] != var:\n            self.coalesced[var] = self.find_representative(self.coalesced[var])\n        return self.coalesced[var]\n\n    def can_coalesce(self, dest, src):\n        \"\"\"Check if dest and src can be coalesced (don't interfere).\"\"\"\n        dest_rep = self.find_representative(dest)\n        src_rep = self.find_representative(src)\n\n        if dest_rep == src_rep:\n            return False  # Already coalesced\n\n        # Check if representatives interfere\n        dest_neighbors = self.interference.get(dest_rep, set())\n        src_neighbors = self.interference.get(src_rep, set())\n\n        # Can coalesce if they don't interfere with each other\n        if src_rep in dest_neighbors or dest_rep in src_neighbors:\n            return False\n\n        # Briggs' criterion: conservative coalescing\n        # Can coalesce if the combined node has fewer than K high-degree neighbors\n        # For simplicity, we'll just check direct interference\n        return True\n\n    def coalesce(self):\n        \"\"\"Perform register coalescing. Returns mapping of variables to coalesced names.\"\"\"\n        # Initialize coalesced mapping\n        all_vars = set()\n        for dest, src in self.copies:\n            all_vars.add(dest)\n            all_vars.add(src)\n        for var in all_vars:\n            self.coalesced[var] = var\n\n        # Try to coalesce each copy\n        for dest, src in self.copies:\n            if self.can_coalesce(dest, src):\n                dest_rep = self.find_representative(dest)\n                src_rep = self.find_representative(src)\n\n                # Union: make src point to dest\n                self.coalesced[src_rep] = dest_rep\n\n                # Merge interference edges\n                if src_rep in self.interference:\n                    if dest_rep not in self.interference:\n                        self.interference[dest_rep] = set()\n                    self.interference[dest_rep].update(self.interference[src_rep])\n\n        # Build final mapping\n        result = {}\n        for var in all_vars:\n            result[var] = self.find_representative(var)\n\n        return result",
    "testCases": [
      {
        "input": "coalescer = RegisterCoalescer()\ncoalescer.add_copy('a', 'b')\nresult = coalescer.coalesce()\nprint(result['a'] == result['b'])",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Non-interfering copy can be coalesced"
      },
      {
        "input": "coalescer = RegisterCoalescer()\ncoalescer.add_copy('a', 'b')\ncoalescer.add_interference('a', 'b')\nresult = coalescer.coalesce()\nprint(result['a'] == result['b'])",
        "expectedOutput": "False",
        "isHidden": false,
        "description": "Interfering variables cannot be coalesced"
      },
      {
        "input": "coalescer = RegisterCoalescer()\ncoalescer.add_copy('a', 'b')\ncoalescer.add_copy('b', 'c')\nresult = coalescer.coalesce()\nprint(result['a'] == result['c'])",
        "isHidden": true,
        "description": "Transitive coalescing"
      }
    ],
    "hints": [
      "Use union-find to track coalesced variables",
      "Check if variables interfere before coalescing",
      "When coalescing, merge the interference edges of both variables",
      "Use path compression in find_representative for efficiency"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex01",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Constant Folding",
    "difficulty": 1,
    "description": "Implement constant folding optimization that evaluates constant expressions at compile time.",
    "starterCode": "class ConstantFolder:\n    def fold(self, expr):\n        \"\"\"\n        Fold constant expressions.\n        expr: dict with 'op' and 'left'/'right', or 'value' for constants\n        Returns: simplified expression\n        \"\"\"\n        # TODO: Implement constant folding\n        pass\n\n# Example: {'op': '+', 'left': {'value': 5}, 'right': {'value': 3}} -> {'value': 8}",
    "solution": "class ConstantFolder:\n    def fold(self, expr):\n        \"\"\"\n        Fold constant expressions.\n        expr: dict with 'op' and 'left'/'right', or 'value' for constants\n        Returns: simplified expression\n        \"\"\"\n        # Base case: already a constant\n        if 'value' in expr:\n            return expr\n\n        # Recursively fold subexpressions\n        left = self.fold(expr['left'])\n        right = self.fold(expr['right'])\n\n        # If both operands are constants, evaluate\n        if 'value' in left and 'value' in right:\n            left_val = left['value']\n            right_val = right['value']\n\n            if expr['op'] == '+':\n                return {'value': left_val + right_val}\n            elif expr['op'] == '-':\n                return {'value': left_val - right_val}\n            elif expr['op'] == '*':\n                return {'value': left_val * right_val}\n            elif expr['op'] == '/':\n                if right_val != 0:\n                    return {'value': left_val // right_val}\n\n        # Cannot fold - return expression with folded subexpressions\n        return {'op': expr['op'], 'left': left, 'right': right}",
    "testCases": [
      {
        "input": "folder = ConstantFolder()\nresult = folder.fold({'op': '+', 'left': {'value': 5}, 'right': {'value': 3}})\nprint(result['value'])",
        "expectedOutput": "8",
        "isHidden": false,
        "description": "Simple addition folding"
      },
      {
        "input": "folder = ConstantFolder()\nresult = folder.fold({'op': '*', 'left': {'op': '+', 'left': {'value': 2}, 'right': {'value': 3}}, 'right': {'value': 4}})\nprint(result['value'])",
        "expectedOutput": "20",
        "isHidden": false,
        "description": "Nested expression (2 + 3) * 4"
      },
      {
        "input": "folder = ConstantFolder()\nresult = folder.fold({'op': '+', 'left': {'value': 10}, 'right': {'var': 'x'}})\nprint('op' in result)",
        "isHidden": true,
        "description": "Cannot fold with variable operand"
      }
    ],
    "hints": [
      "Recursively fold left and right subexpressions first",
      "Check if both operands are constants after folding",
      "If both are constants, evaluate the operation",
      "Return the folded subexpressions if they cannot be completely evaluated"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex02",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Constant Propagation",
    "difficulty": 2,
    "description": "Implement constant propagation that tracks constant values of variables and substitutes them in expressions.",
    "starterCode": "class ConstantPropagator:\n    def __init__(self):\n        self.constants = {}  # variable -> constant value\n\n    def propagate(self, statements):\n        \"\"\"\n        Propagate constants through statements.\n        statements: list of (var, expr) tuples\n        Returns: list of optimized statements\n        \"\"\"\n        # TODO: Implement constant propagation\n        pass",
    "solution": "class ConstantPropagator:\n    def __init__(self):\n        self.constants = {}  # variable -> constant value\n\n    def evaluate(self, expr):\n        \"\"\"Evaluate expression using known constants.\"\"\"\n        if isinstance(expr, int):\n            return expr\n\n        if isinstance(expr, str):\n            # Variable reference\n            if expr in self.constants:\n                return self.constants[expr]\n            return expr\n\n        if isinstance(expr, dict):\n            if 'value' in expr:\n                return expr['value']\n\n            if 'var' in expr:\n                var = expr['var']\n                if var in self.constants:\n                    return self.constants[var]\n                return expr\n\n            # Binary operation\n            if 'op' in expr:\n                left = self.evaluate(expr['left'])\n                right = self.evaluate(expr['right'])\n\n                # If both are constants, evaluate\n                if isinstance(left, int) and isinstance(right, int):\n                    if expr['op'] == '+':\n                        return left + right\n                    elif expr['op'] == '-':\n                        return left - right\n                    elif expr['op'] == '*':\n                        return left * right\n                    elif expr['op'] == '/':\n                        return left // right if right != 0 else expr\n\n                return {'op': expr['op'], 'left': left, 'right': right}\n\n        return expr\n\n    def propagate(self, statements):\n        \"\"\"\n        Propagate constants through statements.\n        statements: list of (var, expr) tuples\n        Returns: list of optimized statements\n        \"\"\"\n        optimized = []\n\n        for var, expr in statements:\n            # Evaluate expression with known constants\n            result = self.evaluate(expr)\n\n            # If result is a constant, record it\n            if isinstance(result, int):\n                self.constants[var] = result\n\n            optimized.append((var, result))\n\n        return optimized",
    "testCases": [
      {
        "input": "prop = ConstantPropagator()\nstmts = [('x', 5), ('y', {'op': '+', 'left': {'var': 'x'}, 'right': 3})]\nresult = prop.propagate(stmts)\nprint(result[1][1])",
        "expectedOutput": "8",
        "isHidden": false,
        "description": "Propagate x=5 into y=x+3"
      },
      {
        "input": "prop = ConstantPropagator()\nstmts = [('a', 10), ('b', 20), ('c', {'op': '*', 'left': {'var': 'a'}, 'right': {'var': 'b'}})]\nresult = prop.propagate(stmts)\nprint(result[2][1])",
        "expectedOutput": "200",
        "isHidden": false,
        "description": "Propagate both operands"
      },
      {
        "input": "prop = ConstantPropagator()\nstmts = [('x', 5), ('y', {'var': 'x'}), ('z', {'op': '+', 'left': {'var': 'y'}, 'right': 1})]\nresult = prop.propagate(stmts)\nprint(result[2][1])",
        "isHidden": true,
        "description": "Transitive propagation"
      }
    ],
    "hints": [
      "Maintain a map of variables to their constant values",
      "When evaluating expressions, substitute known constant values",
      "Update the constant map when a variable is assigned a constant",
      "Recursively evaluate nested expressions"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex03",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Dead Code Elimination",
    "difficulty": 2,
    "description": "Implement dead code elimination that removes assignments to variables that are never used.",
    "starterCode": "class DeadCodeEliminator:\n    def eliminate(self, statements):\n        \"\"\"\n        Remove dead code (assignments to unused variables).\n        statements: list of (var, expr) tuples\n        Returns: list of statements with dead code removed\n        \"\"\"\n        # TODO: Implement dead code elimination\n        # Hint: Work backwards to track which variables are used\n        pass",
    "solution": "class DeadCodeEliminator:\n    def get_used_vars(self, expr):\n        \"\"\"Extract variables used in an expression.\"\"\"\n        if isinstance(expr, str):\n            return {expr}\n\n        if isinstance(expr, int):\n            return set()\n\n        if isinstance(expr, dict):\n            if 'var' in expr:\n                return {expr['var']}\n\n            if 'value' in expr:\n                return set()\n\n            if 'op' in expr:\n                left_vars = self.get_used_vars(expr['left'])\n                right_vars = self.get_used_vars(expr['right'])\n                return left_vars | right_vars\n\n        return set()\n\n    def eliminate(self, statements):\n        \"\"\"\n        Remove dead code (assignments to unused variables).\n        statements: list of (var, expr) tuples\n        Returns: list of statements with dead code removed\n        \"\"\"\n        # First pass: collect all used variables (working backwards)\n        live = set()\n        used_in = {}  # var -> set of variables it uses\n\n        for var, expr in statements:\n            used_vars = self.get_used_vars(expr)\n            used_in[var] = used_vars\n\n        # Mark variables as live if they're used in live variables\n        # Start by assuming last statement is live\n        if statements:\n            live.add(statements[-1][0])\n\n        # Work backwards\n        changed = True\n        while changed:\n            changed = False\n            for var, expr in reversed(statements):\n                if var in live:\n                    # This variable is live, so variables it uses are live\n                    for used_var in used_in.get(var, []):\n                        if used_var not in live:\n                            live.add(used_var)\n                            changed = True\n\n        # Second pass: keep only live statements\n        result = []\n        for var, expr in statements:\n            if var in live or not isinstance(expr, (int, dict)):\n                result.append((var, expr))\n\n        return result",
    "testCases": [
      {
        "input": "elim = DeadCodeEliminator()\nstmts = [('x', 5), ('y', 10), ('z', {'op': '+', 'left': {'var': 'x'}, 'right': 3})]\nresult = elim.eliminate(stmts)\nprint(len(result))",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Remove unused y assignment"
      },
      {
        "input": "elim = DeadCodeEliminator()\nstmts = [('a', 1), ('b', 2), ('c', 3)]\nresult = elim.eliminate(stmts)\nprint(len(result))",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Keep only last assignment"
      },
      {
        "input": "elim = DeadCodeEliminator()\nstmts = [('x', 5), ('y', {'var': 'x'}), ('z', {'var': 'y'})]\nresult = elim.eliminate(stmts)\nprint(len(result))",
        "isHidden": true,
        "description": "Keep all in use chain"
      }
    ],
    "hints": [
      "Work backwards from the end of the statements",
      "Track which variables are live (will be used later)",
      "A variable is live if it appears in the expression of a live variable",
      "Remove assignments to variables that are never live"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex04",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Common Subexpression Elimination",
    "difficulty": 3,
    "description": "Implement CSE to identify and eliminate redundant computations by reusing previously computed values.",
    "starterCode": "class CSE:\n    def __init__(self):\n        self.expressions = {}  # expr_str -> variable holding result\n        self.temp_count = 0\n\n    def expr_to_string(self, expr):\n        \"\"\"Convert expression to canonical string form.\"\"\"\n        # TODO: Implement expression serialization\n        pass\n\n    def eliminate(self, statements):\n        \"\"\"\n        Eliminate common subexpressions.\n        statements: list of (var, expr) tuples\n        Returns: optimized statements\n        \"\"\"\n        # TODO: Implement CSE\n        pass",
    "solution": "class CSE:\n    def __init__(self):\n        self.expressions = {}  # expr_str -> variable holding result\n        self.temp_count = 0\n\n    def expr_to_string(self, expr):\n        \"\"\"Convert expression to canonical string form.\"\"\"\n        if isinstance(expr, int):\n            return str(expr)\n\n        if isinstance(expr, str):\n            return expr\n\n        if isinstance(expr, dict):\n            if 'value' in expr:\n                return str(expr['value'])\n\n            if 'var' in expr:\n                return expr['var']\n\n            if 'op' in expr:\n                left_str = self.expr_to_string(expr['left'])\n                right_str = self.expr_to_string(expr['right'])\n                # Canonical form for commutative operators\n                if expr['op'] in ['+', '*']:\n                    left_str, right_str = sorted([left_str, right_str])\n                return f\"({left_str} {expr['op']} {right_str})\"\n\n        return str(expr)\n\n    def eliminate(self, statements):\n        \"\"\"\n        Eliminate common subexpressions.\n        statements: list of (var, expr) tuples\n        Returns: optimized statements\n        \"\"\"\n        optimized = []\n\n        for var, expr in statements:\n            # Only eliminate non-trivial expressions\n            if isinstance(expr, dict) and 'op' in expr:\n                expr_str = self.expr_to_string(expr)\n\n                if expr_str in self.expressions:\n                    # Reuse previous computation\n                    prev_var = self.expressions[expr_str]\n                    optimized.append((var, {'var': prev_var}))\n                else:\n                    # New expression - compute and record it\n                    self.expressions[expr_str] = var\n                    optimized.append((var, expr))\n            else:\n                optimized.append((var, expr))\n\n                # If assigning a simple value, invalidate expressions using old value of var\n                # For simplicity, we'll just add the statement\n                # In practice, would need to track which expressions are invalidated\n\n        return optimized",
    "testCases": [
      {
        "input": "cse = CSE()\nstmts = [\n    ('t1', {'op': '+', 'left': {'var': 'a'}, 'right': {'var': 'b'}}),\n    ('t2', {'op': '+', 'left': {'var': 'a'}, 'right': {'var': 'b'}})\n]\nresult = cse.eliminate(stmts)\nprint(result[1][1])",
        "expectedOutput": "{'var': 't1'}",
        "isHidden": false,
        "description": "Eliminate duplicate a+b"
      },
      {
        "input": "cse = CSE()\nstmts = [\n    ('t1', {'op': '*', 'left': {'var': 'x'}, 'right': {'value': 2}}),\n    ('t2', {'op': '+', 'left': {'var': 't1'}, 'right': 1}),\n    ('t3', {'op': '*', 'left': {'var': 'x'}, 'right': {'value': 2}})\n]\nresult = cse.eliminate(stmts)\nprint(result[2][1])",
        "expectedOutput": "{'var': 't1'}",
        "isHidden": false,
        "description": "Reuse x*2 computation"
      },
      {
        "input": "cse = CSE()\nstmts = [\n    ('t1', {'op': '+', 'left': {'var': 'a'}, 'right': {'var': 'b'}}),\n    ('t2', {'op': '+', 'left': {'var': 'b'}, 'right': {'var': 'a'}})\n]\nresult = cse.eliminate(stmts)\nprint(result[1][1])",
        "isHidden": true,
        "description": "Commutative operation a+b = b+a"
      }
    ],
    "hints": [
      "Convert expressions to a canonical string representation",
      "For commutative operators (+, *), sort operands to ensure a+b and b+a match",
      "Maintain a map from expression strings to variables holding their results",
      "Replace duplicate expressions with references to the first computation"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex05",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Copy Propagation",
    "difficulty": 2,
    "description": "Implement copy propagation that replaces uses of a variable with its copied value.",
    "starterCode": "class CopyPropagator:\n    def __init__(self):\n        self.copies = {}  # variable -> variable it copies\n\n    def propagate(self, statements):\n        \"\"\"\n        Propagate copies through statements.\n        statements: list of (var, expr) tuples\n        Returns: optimized statements\n        \"\"\"\n        # TODO: Implement copy propagation\n        pass",
    "solution": "class CopyPropagator:\n    def __init__(self):\n        self.copies = {}  # variable -> variable it copies\n\n    def substitute(self, expr):\n        \"\"\"Substitute variables with their copied values.\"\"\"\n        if isinstance(expr, str):\n            # Variable reference\n            if expr in self.copies:\n                return self.substitute(self.copies[expr])\n            return expr\n\n        if isinstance(expr, int):\n            return expr\n\n        if isinstance(expr, dict):\n            if 'var' in expr:\n                var = expr['var']\n                if var in self.copies:\n                    return {'var': self.substitute(self.copies[var])}\n                return expr\n\n            if 'value' in expr:\n                return expr\n\n            if 'op' in expr:\n                left = self.substitute(expr['left'])\n                right = self.substitute(expr['right'])\n                return {'op': expr['op'], 'left': left, 'right': right}\n\n        return expr\n\n    def propagate(self, statements):\n        \"\"\"\n        Propagate copies through statements.\n        statements: list of (var, expr) tuples\n        Returns: optimized statements\n        \"\"\"\n        optimized = []\n\n        for var, expr in statements:\n            # Substitute in the expression\n            new_expr = self.substitute(expr)\n\n            # Check if this is a copy assignment\n            if isinstance(new_expr, dict) and 'var' in new_expr:\n                # Record the copy\n                self.copies[var] = new_expr['var']\n\n            # If variable is redefined, it's no longer a copy\n            if var in self.copies and not (isinstance(new_expr, dict) and 'var' in new_expr):\n                del self.copies[var]\n\n            optimized.append((var, new_expr))\n\n        return optimized",
    "testCases": [
      {
        "input": "prop = CopyPropagator()\nstmts = [('x', 5), ('y', {'var': 'x'}), ('z', {'op': '+', 'left': {'var': 'y'}, 'right': 1})]\nresult = prop.propagate(stmts)\nprint(result[2][1]['left']['var'])",
        "expectedOutput": "x",
        "isHidden": false,
        "description": "Propagate y=x, replace y with x"
      },
      {
        "input": "prop = CopyPropagator()\nstmts = [('a', {'var': 'b'}), ('c', {'var': 'a'}), ('d', {'var': 'c'})]\nresult = prop.propagate(stmts)\nprint(result[2][1]['var'])",
        "expectedOutput": "b",
        "isHidden": false,
        "description": "Transitive copy propagation"
      },
      {
        "input": "prop = CopyPropagator()\nstmts = [('x', {'var': 'y'}), ('x', 10), ('z', {'var': 'x'})]\nresult = prop.propagate(stmts)\nprint(result[2][1])",
        "isHidden": true,
        "description": "Copy invalidated by reassignment"
      }
    ],
    "hints": [
      "Track which variables are copies of other variables",
      "When substituting, follow the chain of copies transitively",
      "Replace uses of copy variables with the original variable",
      "Invalidate copy information when a variable is reassigned"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex06",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Reaching Definitions Analysis",
    "difficulty": 3,
    "description": "Implement reaching definitions data flow analysis to determine which definitions reach each program point.",
    "starterCode": "class ReachingDefinitions:\n    def __init__(self):\n        self.definitions = {}  # variable -> list of definition points\n\n    def analyze(self, statements):\n        \"\"\"\n        Compute reaching definitions for each statement.\n        statements: list of (var, expr) tuples\n        Returns: dict mapping line_number -> set of (var, def_line) reaching that point\n        \"\"\"\n        # TODO: Implement reaching definitions analysis\n        pass",
    "solution": "class ReachingDefinitions:\n    def __init__(self):\n        self.definitions = {}  # variable -> list of definition points\n\n    def analyze(self, statements):\n        \"\"\"\n        Compute reaching definitions for each statement.\n        statements: list of (var, expr) tuples\n        Returns: dict mapping line_number -> set of (var, def_line) reaching that point\n        \"\"\"\n        reaching = {}  # line -> set of (var, def_line)\n\n        # Initialize: no definitions reach the start\n        reaching[0] = set()\n\n        # Process each statement\n        for i, (var, expr) in enumerate(statements):\n            # Definitions reaching this point are those from previous point\n            if i == 0:\n                reaching[i] = set()\n            else:\n                reaching[i] = reaching[i - 1].copy()\n\n            # This statement kills previous definitions of var\n            reaching[i] = {(v, line) for v, line in reaching[i] if v != var}\n\n            # This statement generates a new definition of var\n            reaching[i].add((var, i))\n\n            # Propagate to next statement\n            if i + 1 not in reaching:\n                reaching[i + 1] = set()\n\n        return reaching",
    "testCases": [
      {
        "input": "rd = ReachingDefinitions()\nstmts = [('x', 1), ('y', 2), ('x', 3)]\nresult = rd.analyze(stmts)\ndefs = result[2]\nx_defs = [line for var, line in defs if var == 'x']\nprint(x_defs[0])",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Second definition of x kills first"
      },
      {
        "input": "rd = ReachingDefinitions()\nstmts = [('a', 1), ('b', 2)]\nresult = rd.analyze(stmts)\nprint(len(result[2]))",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Both definitions reach end"
      },
      {
        "input": "rd = ReachingDefinitions()\nstmts = [('x', 5), ('y', {'var': 'x'}), ('x', 10)]\nresult = rd.analyze(stmts)\nx_defs = [line for var, line in result[3] if var == 'x']\nprint(x_defs[0])",
        "isHidden": true,
        "description": "Most recent x definition reaches end"
      }
    ],
    "hints": [
      "At each program point, track which definitions are live",
      "A new definition of a variable kills previous definitions of that variable",
      "Propagate reaching definitions forward through the program",
      "Each definition is identified by (variable, line_number) pair"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex07",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Live Variable Analysis",
    "difficulty": 3,
    "description": "Implement live variable analysis to determine which variables are live (will be used in the future) at each program point.",
    "starterCode": "class LiveVariableAnalysis:\n    def get_uses(self, expr):\n        \"\"\"Get variables used in an expression.\"\"\"\n        # TODO: Extract variables from expression\n        pass\n\n    def analyze(self, statements):\n        \"\"\"\n        Compute live variables at each program point.\n        statements: list of (var, expr) tuples\n        Returns: dict mapping line_number -> set of live variables\n        \"\"\"\n        # TODO: Implement backward data flow analysis\n        pass",
    "solution": "class LiveVariableAnalysis:\n    def get_uses(self, expr):\n        \"\"\"Get variables used in an expression.\"\"\"\n        if isinstance(expr, str):\n            return {expr}\n\n        if isinstance(expr, int):\n            return set()\n\n        if isinstance(expr, dict):\n            if 'var' in expr:\n                return {expr['var']}\n\n            if 'value' in expr:\n                return set()\n\n            if 'op' in expr:\n                left_uses = self.get_uses(expr['left'])\n                right_uses = self.get_uses(expr['right'])\n                return left_uses | right_uses\n\n        return set()\n\n    def analyze(self, statements):\n        \"\"\"\n        Compute live variables at each program point.\n        statements: list of (var, expr) tuples\n        Returns: dict mapping line_number -> set of live variables\n        \"\"\"\n        n = len(statements)\n        live = {}\n\n        # Initialize: nothing is live after the last statement\n        for i in range(n + 1):\n            live[i] = set()\n\n        # Iterate backwards until fixed point\n        changed = True\n        while changed:\n            changed = False\n            for i in range(n - 1, -1, -1):\n                var, expr = statements[i]\n\n                # live_out[i] = live_in[i+1]\n                old_live = live[i].copy()\n\n                # live_in[i] = (live_out[i] - {var})  uses(expr)\n                live[i] = live[i + 1].copy()\n                live[i].discard(var)  # var is defined here\n                live[i].update(self.get_uses(expr))  # variables used here\n\n                if live[i] != old_live:\n                    changed = True\n\n        return live",
    "testCases": [
      {
        "input": "lva = LiveVariableAnalysis()\nstmts = [('x', 5), ('y', {'var': 'x'})]\nresult = lva.analyze(stmts)\nprint('x' in result[0])",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "x is live at start (used later)"
      },
      {
        "input": "lva = LiveVariableAnalysis()\nstmts = [('a', 1), ('b', 2), ('c', {'var': 'a'})]\nresult = lva.analyze(stmts)\nprint('b' in result[3])",
        "expectedOutput": "False",
        "isHidden": false,
        "description": "b is not live at end (not used after definition)"
      },
      {
        "input": "lva = LiveVariableAnalysis()\nstmts = [('x', 5), ('x', 10), ('y', {'var': 'x'})]\nresult = lva.analyze(stmts)\nprint('x' in result[0])",
        "isHidden": true,
        "description": "First x is not live (overwritten before use)"
      }
    ],
    "hints": [
      "Work backwards from the end of the program",
      "A variable is live if it will be used before being redefined",
      "At each point: live = (live_after - defined)  used",
      "Iterate until the live sets stop changing (fixed point)"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex08",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Strength Reduction",
    "difficulty": 3,
    "description": "Implement strength reduction to replace expensive operations (multiplication, division) with cheaper ones (addition, shifts).",
    "starterCode": "class StrengthReducer:\n    def reduce(self, expr):\n        \"\"\"\n        Apply strength reduction to expressions.\n        - Replace multiplication by power of 2 with left shift\n        - Replace division by power of 2 with right shift\n        - Replace x * 1 with x, x * 0 with 0\n        \"\"\"\n        # TODO: Implement strength reduction\n        pass",
    "solution": "class StrengthReducer:\n    def is_power_of_2(self, n):\n        \"\"\"Check if n is a power of 2.\"\"\"\n        return n > 0 and (n & (n - 1)) == 0\n\n    def log2(self, n):\n        \"\"\"Compute log base 2 of n (assumes n is power of 2).\"\"\"\n        count = 0\n        while n > 1:\n            n >>= 1\n            count += 1\n        return count\n\n    def reduce(self, expr):\n        \"\"\"\n        Apply strength reduction to expressions.\n        - Replace multiplication by power of 2 with left shift\n        - Replace division by power of 2 with right shift\n        - Replace x * 1 with x, x * 0 with 0\n        \"\"\"\n        if not isinstance(expr, dict) or 'op' not in expr:\n            return expr\n\n        # Recursively reduce subexpressions\n        left = self.reduce(expr['left'])\n        right = self.reduce(expr['right'])\n\n        op = expr['op']\n\n        # Get constant value if right operand is constant\n        right_val = None\n        if isinstance(right, dict) and 'value' in right:\n            right_val = right['value']\n        elif isinstance(right, int):\n            right_val = right\n\n        # Multiplication optimizations\n        if op == '*':\n            if right_val == 0:\n                return {'value': 0}\n            elif right_val == 1:\n                return left\n            elif right_val is not None and self.is_power_of_2(right_val):\n                # Replace with left shift\n                shift = self.log2(right_val)\n                return {'op': '<<', 'left': left, 'right': {'value': shift}}\n\n        # Division optimizations\n        elif op == '/':\n            if right_val == 1:\n                return left\n            elif right_val is not None and self.is_power_of_2(right_val):\n                # Replace with right shift\n                shift = self.log2(right_val)\n                return {'op': '>>', 'left': left, 'right': {'value': shift}}\n\n        return {'op': op, 'left': left, 'right': right}",
    "testCases": [
      {
        "input": "reducer = StrengthReducer()\nexpr = {'op': '*', 'left': {'var': 'x'}, 'right': {'value': 8}}\nresult = reducer.reduce(expr)\nprint(result['op'])",
        "expectedOutput": "<<",
        "isHidden": false,
        "description": "x * 8 becomes x << 3"
      },
      {
        "input": "reducer = StrengthReducer()\nexpr = {'op': '*', 'left': {'var': 'x'}, 'right': {'value': 1}}\nresult = reducer.reduce(expr)\nprint(result)",
        "expectedOutput": "{'var': 'x'}",
        "isHidden": false,
        "description": "x * 1 becomes x"
      },
      {
        "input": "reducer = StrengthReducer()\nexpr = {'op': '/', 'left': {'var': 'y'}, 'right': {'value': 16}}\nresult = reducer.reduce(expr)\nprint(result['right']['value'])",
        "isHidden": true,
        "description": "y / 16 becomes y >> 4"
      }
    ],
    "hints": [
      "Check if multiplier/divisor is a power of 2",
      "Multiplication by 2^n can be replaced with left shift by n",
      "Division by 2^n can be replaced with right shift by n",
      "Handle identity cases: x * 1 = x, x * 0 = 0"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex09",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Loop Invariant Code Motion",
    "difficulty": 4,
    "description": "Implement loop invariant code motion to move computations that don't change in a loop outside the loop.",
    "starterCode": "class LoopInvariantMotion:\n    def __init__(self):\n        self.loop_vars = set()  # Variables modified in loop\n\n    def is_invariant(self, expr, loop_vars):\n        \"\"\"Check if expression is loop invariant.\"\"\"\n        # TODO: Determine if expr depends only on non-loop variables\n        pass\n\n    def hoist(self, loop_body):\n        \"\"\"\n        Move loop-invariant code out of loop.\n        loop_body: list of (var, expr) tuples\n        Returns: (preheader, new_loop_body)\n        \"\"\"\n        # TODO: Implement hoisting\n        pass",
    "solution": "class LoopInvariantMotion:\n    def __init__(self):\n        self.loop_vars = set()  # Variables modified in loop\n\n    def get_vars(self, expr):\n        \"\"\"Get all variables used in an expression.\"\"\"\n        if isinstance(expr, str):\n            return {expr}\n\n        if isinstance(expr, int):\n            return set()\n\n        if isinstance(expr, dict):\n            if 'var' in expr:\n                return {expr['var']}\n\n            if 'value' in expr:\n                return set()\n\n            if 'op' in expr:\n                left_vars = self.get_vars(expr['left'])\n                right_vars = self.get_vars(expr['right'])\n                return left_vars | right_vars\n\n        return set()\n\n    def is_invariant(self, expr, loop_vars):\n        \"\"\"Check if expression is loop invariant.\"\"\"\n        # Get all variables used in expression\n        used_vars = self.get_vars(expr)\n\n        # Invariant if no loop-modified variables are used\n        return len(used_vars & loop_vars) == 0\n\n    def hoist(self, loop_body):\n        \"\"\"\n        Move loop-invariant code out of loop.\n        loop_body: list of (var, expr) tuples\n        Returns: (preheader, new_loop_body)\n        \"\"\"\n        # First pass: identify variables modified in loop\n        loop_vars = set()\n        for var, expr in loop_body:\n            loop_vars.add(var)\n\n        # Second pass: identify invariant statements\n        preheader = []\n        new_body = []\n\n        for var, expr in loop_body:\n            if self.is_invariant(expr, loop_vars) and isinstance(expr, dict):\n                # This is invariant - hoist it\n                preheader.append((var, expr))\n            else:\n                # Keep in loop\n                new_body.append((var, expr))\n\n        return preheader, new_body",
    "testCases": [
      {
        "input": "lim = LoopInvariantMotion()\nloop = [('x', {'op': '+', 'left': {'var': 'a'}, 'right': {'var': 'b'}}), ('i', {'op': '+', 'left': {'var': 'i'}, 'right': 1})]\npreheader, body = lim.hoist(loop)\nprint(len(preheader))",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Hoist a+b (invariant)"
      },
      {
        "input": "lim = LoopInvariantMotion()\nloop = [('x', {'op': '*', 'left': {'var': 'i'}, 'right': 2}), ('i', {'op': '+', 'left': {'var': 'i'}, 'right': 1})]\npreheader, body = lim.hoist(loop)\nprint(len(preheader))",
        "expectedOutput": "0",
        "isHidden": false,
        "description": "Cannot hoist i*2 (i is modified)"
      },
      {
        "input": "lim = LoopInvariantMotion()\nloop = [('y', {'op': '+', 'left': {'value': 5}, 'right': {'value': 3}}), ('z', {'var': 'y'})]\npreheader, body = lim.hoist(loop)\nprint(len(preheader))",
        "isHidden": true,
        "description": "Hoist constant expression"
      }
    ],
    "hints": [
      "First identify all variables that are modified in the loop",
      "An expression is invariant if it uses only non-loop variables",
      "Hoist invariant computations to a preheader before the loop",
      "Be careful with dependencies: hoisted code should not use loop variables"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex10",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Induction Variable Elimination",
    "difficulty": 4,
    "description": "Identify and optimize induction variables in loops by replacing derived induction variables with computations based on the basic induction variable.",
    "starterCode": "class InductionVariableOptimizer:\n    def find_basic_induction_vars(self, loop_body):\n        \"\"\"\n        Find basic induction variables (vars of form i = i + c).\n        Returns dict: var -> increment\n        \"\"\"\n        # TODO: Identify basic induction variables\n        pass\n\n    def optimize(self, loop_body):\n        \"\"\"\n        Optimize induction variables.\n        Replace j = c1 * i + c2 with incremental updates.\n        \"\"\"\n        # TODO: Implement induction variable optimization\n        pass",
    "solution": "class InductionVariableOptimizer:\n    def find_basic_induction_vars(self, loop_body):\n        \"\"\"\n        Find basic induction variables (vars of form i = i + c).\n        Returns dict: var -> increment\n        \"\"\"\n        basic_ivs = {}\n\n        for var, expr in loop_body:\n            if isinstance(expr, dict) and expr.get('op') == '+':\n                left = expr['left']\n                right = expr['right']\n\n                # Check for i = i + c\n                if isinstance(left, dict) and left.get('var') == var:\n                    if isinstance(right, dict) and 'value' in right:\n                        basic_ivs[var] = right['value']\n                    elif isinstance(right, int):\n                        basic_ivs[var] = right\n\n        return basic_ivs\n\n    def optimize(self, loop_body):\n        \"\"\"\n        Optimize induction variables.\n        Replace j = c1 * i + c2 with incremental updates.\n        \"\"\"\n        # Find basic induction variables\n        basic_ivs = self.find_basic_induction_vars(loop_body)\n\n        optimized = []\n\n        for var, expr in loop_body:\n            # Check if this is a derived induction variable: j = c * i + d\n            if isinstance(expr, dict) and expr.get('op') in ['+', '*']:\n                # Simplified check for j = c * i form\n                if expr['op'] == '*':\n                    left = expr['left']\n                    right = expr['right']\n\n                    # Check if multiplying by a basic IV\n                    basic_iv = None\n                    multiplier = None\n\n                    if isinstance(left, dict) and left.get('var') in basic_ivs:\n                        basic_iv = left['var']\n                        if isinstance(right, dict) and 'value' in right:\n                            multiplier = right['value']\n\n                    if basic_iv and multiplier:\n                        # This is a derived IV: j = c * i\n                        # Can optimize to: j = j + c * increment_of_i\n                        increment = basic_ivs[basic_iv] * multiplier\n                        new_expr = {\n                            'op': '+',\n                            'left': {'var': var},\n                            'right': {'value': increment}\n                        }\n                        optimized.append((var, new_expr))\n                        continue\n\n            # Keep statement as-is\n            optimized.append((var, expr))\n\n        return optimized",
    "testCases": [
      {
        "input": "ivo = InductionVariableOptimizer()\nloop = [('i', {'op': '+', 'left': {'var': 'i'}, 'right': {'value': 1}})]\nbasic = ivo.find_basic_induction_vars(loop)\nprint(basic['i'])",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Identify basic IV i = i + 1"
      },
      {
        "input": "ivo = InductionVariableOptimizer()\nloop = [\n    ('i', {'op': '+', 'left': {'var': 'i'}, 'right': {'value': 1}}),\n    ('j', {'op': '*', 'left': {'var': 'i'}, 'right': {'value': 4}})\n]\noptimized = ivo.optimize(loop)\nprint(optimized[1][1]['right']['value'])",
        "expectedOutput": "4",
        "isHidden": false,
        "description": "Transform j = i * 4 to j = j + 4"
      },
      {
        "input": "ivo = InductionVariableOptimizer()\nloop = [\n    ('i', {'op': '+', 'left': {'var': 'i'}, 'right': {'value': 2}}),\n    ('j', {'op': '*', 'left': {'var': 'i'}, 'right': {'value': 3}})\n]\noptimized = ivo.optimize(loop)\nprint(optimized[1][1]['right']['value'])",
        "isHidden": true,
        "description": "j = i * 3 becomes j = j + 6 (since i += 2)"
      }
    ],
    "hints": [
      "Basic induction variables have the form i = i + c",
      "Derived induction variables are linear functions of basic IVs",
      "Replace j = c * i with j = j + (c * increment_of_i)",
      "Track the increment value for each basic induction variable"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex11",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Algebraic Simplification",
    "difficulty": 2,
    "description": "Implement algebraic simplifications like x + 0 = x, x * 1 = x, x - x = 0, etc.",
    "starterCode": "class AlgebraicSimplifier:\n    def simplify(self, expr):\n        \"\"\"\n        Apply algebraic simplifications.\n        - x + 0 = x, 0 + x = x\n        - x * 1 = x, 1 * x = x\n        - x * 0 = 0, 0 * x = 0\n        - x - 0 = x\n        - x - x = 0\n        \"\"\"\n        # TODO: Implement simplifications\n        pass",
    "solution": "class AlgebraicSimplifier:\n    def expr_equal(self, e1, e2):\n        \"\"\"Check if two expressions are equal.\"\"\"\n        if isinstance(e1, int) and isinstance(e2, int):\n            return e1 == e2\n\n        if isinstance(e1, str) and isinstance(e2, str):\n            return e1 == e2\n\n        if isinstance(e1, dict) and isinstance(e2, dict):\n            if 'var' in e1 and 'var' in e2:\n                return e1['var'] == e2['var']\n            if 'value' in e1 and 'value' in e2:\n                return e1['value'] == e2['value']\n\n        return False\n\n    def get_value(self, expr):\n        \"\"\"Get constant value if expression is a constant.\"\"\"\n        if isinstance(expr, int):\n            return expr\n        if isinstance(expr, dict) and 'value' in expr:\n            return expr['value']\n        return None\n\n    def simplify(self, expr):\n        \"\"\"\n        Apply algebraic simplifications.\n        - x + 0 = x, 0 + x = x\n        - x * 1 = x, 1 * x = x\n        - x * 0 = 0, 0 * x = 0\n        - x - 0 = x\n        - x - x = 0\n        \"\"\"\n        if not isinstance(expr, dict) or 'op' not in expr:\n            return expr\n\n        # Recursively simplify subexpressions\n        left = self.simplify(expr['left'])\n        right = self.simplify(expr['right'])\n\n        op = expr['op']\n        left_val = self.get_value(left)\n        right_val = self.get_value(right)\n\n        # Addition simplifications\n        if op == '+':\n            if left_val == 0:\n                return right\n            if right_val == 0:\n                return left\n\n        # Subtraction simplifications\n        elif op == '-':\n            if right_val == 0:\n                return left\n            if self.expr_equal(left, right):\n                return {'value': 0}\n\n        # Multiplication simplifications\n        elif op == '*':\n            if left_val == 0 or right_val == 0:\n                return {'value': 0}\n            if left_val == 1:\n                return right\n            if right_val == 1:\n                return left\n\n        # Division simplifications\n        elif op == '/':\n            if right_val == 1:\n                return left\n\n        return {'op': op, 'left': left, 'right': right}",
    "testCases": [
      {
        "input": "simp = AlgebraicSimplifier()\nresult = simp.simplify({'op': '+', 'left': {'var': 'x'}, 'right': {'value': 0}})\nprint(result)",
        "expectedOutput": "{'var': 'x'}",
        "isHidden": false,
        "description": "x + 0 = x"
      },
      {
        "input": "simp = AlgebraicSimplifier()\nresult = simp.simplify({'op': '*', 'left': {'var': 'y'}, 'right': {'value': 1}})\nprint(result)",
        "expectedOutput": "{'var': 'y'}",
        "isHidden": false,
        "description": "y * 1 = y"
      },
      {
        "input": "simp = AlgebraicSimplifier()\nresult = simp.simplify({'op': '-', 'left': {'var': 'z'}, 'right': {'var': 'z'}})\nprint(result['value'])",
        "isHidden": true,
        "description": "z - z = 0"
      }
    ],
    "hints": [
      "Check for identity elements: 0 for addition, 1 for multiplication",
      "Handle both left and right operand positions",
      "For x - x, check if both operands are the same variable",
      "Recursively simplify subexpressions first"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex12",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Available Expressions Analysis",
    "difficulty": 3,
    "description": "Implement available expressions analysis to determine which expressions have been computed and are still valid at each program point.",
    "starterCode": "class AvailableExpressions:\n    def expr_to_str(self, expr):\n        \"\"\"Convert expression to string for comparison.\"\"\"\n        # TODO: Implement\n        pass\n\n    def analyze(self, statements):\n        \"\"\"\n        Compute available expressions at each program point.\n        Returns: dict mapping line_number -> set of available expression strings\n        \"\"\"\n        # TODO: Implement forward data flow analysis\n        pass",
    "solution": "class AvailableExpressions:\n    def expr_to_str(self, expr):\n        \"\"\"Convert expression to string for comparison.\"\"\"\n        if isinstance(expr, int):\n            return str(expr)\n\n        if isinstance(expr, str):\n            return expr\n\n        if isinstance(expr, dict):\n            if 'value' in expr:\n                return str(expr['value'])\n\n            if 'var' in expr:\n                return expr['var']\n\n            if 'op' in expr:\n                left = self.expr_to_str(expr['left'])\n                right = self.expr_to_str(expr['right'])\n                return f\"({left} {expr['op']} {right})\"\n\n        return \"\"\n\n    def get_exprs(self, expr):\n        \"\"\"Get all subexpressions.\"\"\"\n        exprs = set()\n\n        if isinstance(expr, dict) and 'op' in expr:\n            expr_str = self.expr_to_str(expr)\n            exprs.add(expr_str)\n\n            # Recursively get subexpressions\n            exprs.update(self.get_exprs(expr['left']))\n            exprs.update(self.get_exprs(expr['right']))\n\n        return exprs\n\n    def analyze(self, statements):\n        \"\"\"\n        Compute available expressions at each program point.\n        Returns: dict mapping line_number -> set of available expression strings\n        \"\"\"\n        n = len(statements)\n        available = {}\n\n        # Initialize: no expressions available at start\n        for i in range(n + 1):\n            available[i] = set()\n\n        # Iterate forward until fixed point\n        changed = True\n        while changed:\n            changed = False\n\n            for i, (var, expr) in enumerate(statements):\n                # available_in[i] = available_out[i-1]\n                old_available = available[i].copy()\n\n                if i > 0:\n                    available[i] = available[i - 1].copy()\n                else:\n                    available[i] = set()\n\n                # Kill expressions that use the variable being defined\n                available[i] = {e for e in available[i] if var not in e}\n\n                # Gen: add new expressions computed here\n                new_exprs = self.get_exprs(expr)\n                available[i].update(new_exprs)\n\n                # Propagate to next point\n                available[i + 1] = available[i].copy()\n\n                if available[i] != old_available:\n                    changed = True\n\n        return available",
    "testCases": [
      {
        "input": "ae = AvailableExpressions()\nstmts = [('t1', {'op': '+', 'left': {'var': 'a'}, 'right': {'var': 'b'}}), ('t2', {'var': 't1'})]\nresult = ae.analyze(stmts)\nprint('(a + b)' in result[1])",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "a+b is available after first statement"
      },
      {
        "input": "ae = AvailableExpressions()\nstmts = [('x', {'op': '+', 'left': {'var': 'a'}, 'right': {'var': 'b'}}), ('a', 10)]\nresult = ae.analyze(stmts)\nprint('(a + b)' in result[2])",
        "expectedOutput": "False",
        "isHidden": false,
        "description": "a+b is killed when a is redefined"
      },
      {
        "input": "ae = AvailableExpressions()\nstmts = [('t1', {'op': '*', 'left': {'var': 'x'}, 'right': {'value': 2}}), ('t2', {'op': '+', 'left': {'var': 't1'}, 'right': 1})]\nresult = ae.analyze(stmts)\nprint('(x * 2)' in result[2])",
        "isHidden": true,
        "description": "x*2 remains available"
      }
    ],
    "hints": [
      "Work forwards through the program",
      "An expression is available if it has been computed and not invalidated",
      "Kill expressions when any variable they use is redefined",
      "Generate new expressions when they are computed"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex13",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Partial Redundancy Elimination",
    "difficulty": 5,
    "description": "Implement partial redundancy elimination to optimize cases where an expression is redundant on some paths but not others.",
    "starterCode": "class PartialRedundancyElimination:\n    def __init__(self):\n        self.anticipated = {}  # Anticipated expressions\n        self.available = {}  # Available expressions\n\n    def compute_anticipated(self, cfg):\n        \"\"\"\n        Compute anticipated expressions (will be used on all paths).\n        cfg: list of basic blocks, each block is list of statements\n        \"\"\"\n        # TODO: Backward analysis\n        pass\n\n    def eliminate(self, cfg):\n        \"\"\"\n        Perform partial redundancy elimination.\n        Insert computations at optimal points.\n        \"\"\"\n        # TODO: Implement PRE\n        pass",
    "solution": "class PartialRedundancyElimination:\n    def __init__(self):\n        self.anticipated = {}  # Anticipated expressions\n        self.available = {}  # Available expressions\n\n    def expr_to_str(self, expr):\n        \"\"\"Convert expression to string.\"\"\"\n        if isinstance(expr, dict) and 'op' in expr:\n            left = self.expr_to_str(expr.get('left', ''))\n            right = self.expr_to_str(expr.get('right', ''))\n            return f\"({left} {expr['op']} {right})\"\n        if isinstance(expr, dict) and 'var' in expr:\n            return expr['var']\n        if isinstance(expr, dict) and 'value' in expr:\n            return str(expr['value'])\n        return str(expr)\n\n    def get_exprs(self, block):\n        \"\"\"Get all expressions in a block.\"\"\"\n        exprs = set()\n        for var, expr in block:\n            if isinstance(expr, dict) and 'op' in expr:\n                exprs.add(self.expr_to_str(expr))\n        return exprs\n\n    def compute_anticipated(self, cfg):\n        \"\"\"\n        Compute anticipated expressions (will be used on all paths).\n        cfg: list of basic blocks, each block is list of statements\n        Simplified: just check if expression appears in block\n        \"\"\"\n        for i, block in enumerate(cfg):\n            self.anticipated[i] = self.get_exprs(block)\n\n    def eliminate(self, cfg):\n        \"\"\"\n        Perform partial redundancy elimination.\n        Insert computations at optimal points.\n        Simplified implementation: identify common expressions across blocks\n        \"\"\"\n        # Compute anticipated expressions\n        self.compute_anticipated(cfg)\n\n        # Find expressions that appear in multiple blocks\n        all_exprs = set()\n        expr_blocks = {}\n\n        for i, block in enumerate(cfg):\n            exprs = self.get_exprs(block)\n            all_exprs.update(exprs)\n\n            for expr in exprs:\n                if expr not in expr_blocks:\n                    expr_blocks[expr] = []\n                expr_blocks[expr].append(i)\n\n        # Identify partially redundant expressions (appear in 2+ blocks)\n        partially_redundant = {expr: blocks for expr, blocks in expr_blocks.items() if len(blocks) > 1}\n\n        return partially_redundant",
    "testCases": [
      {
        "input": "pre = PartialRedundancyElimination()\ncfg = [\n    [('t1', {'op': '+', 'left': {'var': 'a'}, 'right': {'var': 'b'}})],\n    [('t2', {'op': '+', 'left': {'var': 'a'}, 'right': {'var': 'b'}})]\n]\nresult = pre.eliminate(cfg)\nprint(len(result))",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Find one partially redundant expression"
      },
      {
        "input": "pre = PartialRedundancyElimination()\ncfg = [\n    [('x', 1)],\n    [('y', 2)]\n]\nresult = pre.eliminate(cfg)\nprint(len(result))",
        "expectedOutput": "0",
        "isHidden": false,
        "description": "No redundant expressions"
      },
      {
        "input": "pre = PartialRedundancyElimination()\ncfg = [\n    [('t1', {'op': '*', 'left': {'var': 'x'}, 'right': {'value': 2}})],\n    [('t2', 5)],\n    [('t3', {'op': '*', 'left': {'var': 'x'}, 'right': {'value': 2}})]\n]\nresult = pre.eliminate(cfg)\nprint('(x * 2)' in result)",
        "isHidden": true,
        "description": "Expression in blocks 0 and 2"
      }
    ],
    "hints": [
      "PRE combines anticipation and availability analysis",
      "An expression is partially redundant if it's redundant on some paths",
      "Insert computations at optimal points to make expressions fully redundant",
      "This is a simplified version focusing on identifying redundancy"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex14",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Tail Call Optimization",
    "difficulty": 3,
    "description": "Implement tail call optimization to convert tail-recursive functions into iterative loops.",
    "starterCode": "class TailCallOptimizer:\n    def is_tail_call(self, function_body):\n        \"\"\"\n        Check if last statement is a recursive call.\n        function_body: list of statements, last should be return statement\n        \"\"\"\n        # TODO: Check for tail recursion pattern\n        pass\n\n    def optimize(self, function_name, function_body):\n        \"\"\"\n        Convert tail recursive function to loop.\n        Returns optimized function body.\n        \"\"\"\n        # TODO: Transform to iterative version\n        pass",
    "solution": "class TailCallOptimizer:\n    def is_tail_call(self, function_body, function_name):\n        \"\"\"\n        Check if last statement is a recursive call.\n        function_body: list of statements\n        \"\"\"\n        if not function_body:\n            return False\n\n        last_stmt = function_body[-1]\n\n        # Check if it's a return statement with a call\n        if isinstance(last_stmt, dict) and last_stmt.get('type') == 'return':\n            expr = last_stmt.get('value')\n            if isinstance(expr, dict) and expr.get('type') == 'call':\n                return expr.get('function') == function_name\n\n        return False\n\n    def optimize(self, function_name, params, function_body):\n        \"\"\"\n        Convert tail recursive function to loop.\n        params: list of parameter names\n        function_body: list of statement dicts\n        Returns optimized function body.\n        \"\"\"\n        if not self.is_tail_call(function_body, function_name):\n            return function_body\n\n        # Create loop structure\n        optimized = []\n\n        # Add loop start label\n        optimized.append({'type': 'label', 'name': 'loop_start'})\n\n        # Transform body: replace return with jump to start and parameter updates\n        for stmt in function_body[:-1]:\n            optimized.append(stmt)\n\n        # Last statement is the tail call - replace with parameter updates and loop\n        last_stmt = function_body[-1]\n        if isinstance(last_stmt, dict) and last_stmt.get('type') == 'return':\n            call_expr = last_stmt['value']\n            if isinstance(call_expr, dict) and call_expr.get('type') == 'call':\n                # Update parameters with new arguments\n                args = call_expr.get('args', [])\n                for i, arg in enumerate(args):\n                    if i < len(params):\n                        optimized.append({\n                            'type': 'assign',\n                            'var': params[i],\n                            'value': arg\n                        })\n\n                # Jump back to loop start\n                optimized.append({'type': 'goto', 'label': 'loop_start'})\n\n        return optimized",
    "testCases": [
      {
        "input": "tco = TailCallOptimizer()\nbody = [\n    {'type': 'if', 'condition': 'n == 0', 'then': [{'type': 'return', 'value': 1}]},\n    {'type': 'return', 'value': {'type': 'call', 'function': 'fact', 'args': ['n-1', 'acc*n']}}\n]\nis_tail = tco.is_tail_call(body, 'fact')\nprint(is_tail)",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Detect tail recursive call"
      },
      {
        "input": "tco = TailCallOptimizer()\nbody = [\n    {'type': 'assign', 'var': 'x', 'value': 1},\n    {'type': 'return', 'value': {'type': 'call', 'function': 'foo', 'args': ['x']}}\n]\noptimized = tco.optimize('foo', ['n'], body)\nprint(optimized[-1]['type'])",
        "expectedOutput": "goto",
        "isHidden": false,
        "description": "Transform to loop with goto"
      },
      {
        "input": "tco = TailCallOptimizer()\nbody = [{'type': 'return', 'value': 'n'}]\noptimized = tco.optimize('foo', ['n'], body)\nprint(len(optimized))",
        "isHidden": true,
        "description": "Non-tail-recursive function unchanged"
      }
    ],
    "hints": [
      "A tail call is when the last action is a recursive call",
      "Convert the tail call into a loop that updates parameters and restarts",
      "Replace the return statement with parameter updates and a jump to the start",
      "Add a loop label at the beginning of the function"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex15",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Unreachable Code Elimination",
    "difficulty": 2,
    "description": "Implement unreachable code elimination to remove code that can never be executed.",
    "starterCode": "class UnreachableCodeEliminator:\n    def find_reachable(self, cfg, entry_block=0):\n        \"\"\"\n        Find all reachable basic blocks.\n        cfg: dict mapping block_id -> {'code': [...], 'successors': [block_ids]}\n        Returns: set of reachable block IDs\n        \"\"\"\n        # TODO: Implement reachability analysis\n        pass\n\n    def eliminate(self, cfg, entry_block=0):\n        \"\"\"Remove unreachable blocks from CFG.\"\"\"\n        # TODO: Remove unreachable blocks\n        pass",
    "solution": "class UnreachableCodeEliminator:\n    def find_reachable(self, cfg, entry_block=0):\n        \"\"\"\n        Find all reachable basic blocks.\n        cfg: dict mapping block_id -> {'code': [...], 'successors': [block_ids]}\n        Returns: set of reachable block IDs\n        \"\"\"\n        reachable = set()\n        worklist = [entry_block]\n\n        while worklist:\n            current = worklist.pop(0)\n\n            if current in reachable:\n                continue\n\n            reachable.add(current)\n\n            # Add successors to worklist\n            if current in cfg:\n                successors = cfg[current].get('successors', [])\n                for succ in successors:\n                    if succ not in reachable:\n                        worklist.append(succ)\n\n        return reachable\n\n    def eliminate(self, cfg, entry_block=0):\n        \"\"\"Remove unreachable blocks from CFG.\"\"\"\n        reachable = self.find_reachable(cfg, entry_block)\n\n        # Create new CFG with only reachable blocks\n        new_cfg = {}\n        for block_id in reachable:\n            if block_id in cfg:\n                new_cfg[block_id] = cfg[block_id]\n\n        return new_cfg",
    "testCases": [
      {
        "input": "uce = UnreachableCodeEliminator()\ncfg = {\n    0: {'code': ['x = 1'], 'successors': [1]},\n    1: {'code': ['y = 2'], 'successors': []},\n    2: {'code': ['z = 3'], 'successors': []}\n}\nreachable = uce.find_reachable(cfg, 0)\nprint(2 in reachable)",
        "expectedOutput": "False",
        "isHidden": false,
        "description": "Block 2 is unreachable from entry"
      },
      {
        "input": "uce = UnreachableCodeEliminator()\ncfg = {\n    0: {'code': ['x = 1'], 'successors': [1, 2]},\n    1: {'code': ['y = 2'], 'successors': [3]},\n    2: {'code': ['z = 3'], 'successors': [3]},\n    3: {'code': ['return'], 'successors': []}\n}\nnew_cfg = uce.eliminate(cfg, 0)\nprint(len(new_cfg))",
        "expectedOutput": "4",
        "isHidden": false,
        "description": "All blocks reachable"
      },
      {
        "input": "uce = UnreachableCodeEliminator()\ncfg = {\n    0: {'code': ['x = 1'], 'successors': [1]},\n    1: {'code': ['return'], 'successors': []},\n    2: {'code': ['y = 2'], 'successors': [3]},\n    3: {'code': ['z = 3'], 'successors': []}\n}\nnew_cfg = uce.eliminate(cfg, 0)\nprint(len(new_cfg))",
        "isHidden": true,
        "description": "Blocks 2 and 3 unreachable"
      }
    ],
    "hints": [
      "Use a worklist algorithm starting from the entry block",
      "Mark blocks as reachable when visited",
      "Add successor blocks to the worklist",
      "Remove blocks that are never marked as reachable"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t6-ex16",
    "subjectId": "cs304",
    "topicId": "cs304-topic-6",
    "title": "Inline Expansion",
    "difficulty": 4,
    "description": "Implement function inlining to replace function calls with the function body for small functions.",
    "starterCode": "class FunctionInliner:\n    def __init__(self, inline_threshold=5):\n        self.inline_threshold = inline_threshold\n        self.functions = {}  # function_name -> body\n\n    def should_inline(self, function_name):\n        \"\"\"Decide if function should be inlined based on size.\"\"\"\n        # TODO: Check function size\n        pass\n\n    def inline_call(self, call_site, function_name, args):\n        \"\"\"\n        Inline a function call.\n        call_site: (var, call_expr)\n        Returns: list of statements replacing the call\n        \"\"\"\n        # TODO: Substitute parameters with arguments\n        # Rename local variables to avoid conflicts\n        pass",
    "solution": "class FunctionInliner:\n    def __init__(self, inline_threshold=5):\n        self.inline_threshold = inline_threshold\n        self.functions = {}  # function_name -> {'params': [...], 'body': [...]}\n        self.inline_counter = 0\n\n    def register_function(self, name, params, body):\n        \"\"\"Register a function for potential inlining.\"\"\"\n        self.functions[name] = {'params': params, 'body': body}\n\n    def should_inline(self, function_name):\n        \"\"\"Decide if function should be inlined based on size.\"\"\"\n        if function_name not in self.functions:\n            return False\n\n        body = self.functions[function_name]['body']\n        return len(body) <= self.inline_threshold\n\n    def rename_var(self, var, suffix):\n        \"\"\"Rename a variable to avoid conflicts.\"\"\"\n        if isinstance(var, str):\n            return f\"{var}_{suffix}\"\n        if isinstance(var, dict) and 'var' in var:\n            return {'var': f\"{var['var']}_{suffix}\"}\n        return var\n\n    def rename_expr(self, expr, suffix, param_map):\n        \"\"\"Rename variables in an expression.\"\"\"\n        if isinstance(expr, str):\n            if expr in param_map:\n                return param_map[expr]\n            return f\"{expr}_{suffix}\"\n\n        if isinstance(expr, int):\n            return expr\n\n        if isinstance(expr, dict):\n            if 'var' in expr:\n                var = expr['var']\n                if var in param_map:\n                    return param_map[var]\n                return {'var': f\"{var}_{suffix}\"}\n\n            if 'value' in expr:\n                return expr\n\n            if 'op' in expr:\n                left = self.rename_expr(expr['left'], suffix, param_map)\n                right = self.rename_expr(expr['right'], suffix, param_map)\n                return {'op': expr['op'], 'left': left, 'right': right}\n\n        return expr\n\n    def inline_call(self, result_var, function_name, args):\n        \"\"\"\n        Inline a function call.\n        Returns: list of statements replacing the call\n        \"\"\"\n        if not self.should_inline(function_name):\n            return None\n\n        func_info = self.functions[function_name]\n        params = func_info['params']\n        body = func_info['body']\n\n        # Create unique suffix for this inlining\n        suffix = f\"inline{self.inline_counter}\"\n        self.inline_counter += 1\n\n        # Create parameter substitution map\n        param_map = {}\n        for i, param in enumerate(params):\n            if i < len(args):\n                param_map[param] = args[i]\n\n        # Inline the body with renamed variables\n        inlined = []\n        for var, expr in body:\n            new_var = f\"{var}_{suffix}\"\n            new_expr = self.rename_expr(expr, suffix, param_map)\n            inlined.append((new_var, new_expr))\n\n        # Last statement's result should be assigned to result_var\n        if inlined:\n            last_var = inlined[-1][0]\n            inlined.append((result_var, {'var': last_var}))\n\n        return inlined",
    "testCases": [
      {
        "input": "inliner = FunctionInliner(inline_threshold=5)\ninliner.register_function('add', ['a', 'b'], [('result', {'op': '+', 'left': {'var': 'a'}, 'right': {'var': 'b'}})])\nshould = inliner.should_inline('add')\nprint(should)",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Small function should be inlined"
      },
      {
        "input": "inliner = FunctionInliner(inline_threshold=5)\ninliner.register_function('foo', ['x'], [('t1', 1), ('t2', 2)])\ninlined = inliner.inline_call('result', 'foo', [{'value': 10}])\nprint(len(inlined))",
        "expectedOutput": "3",
        "isHidden": false,
        "description": "Inlined body plus result assignment"
      },
      {
        "input": "inliner = FunctionInliner(inline_threshold=2)\ninliner.register_function('big', ['x'], [('t1', 1), ('t2', 2), ('t3', 3)])\nshould = inliner.should_inline('big')\nprint(should)",
        "isHidden": true,
        "description": "Large function should not be inlined"
      }
    ],
    "hints": [
      "Check function size against threshold to decide if it should be inlined",
      "Substitute formal parameters with actual arguments",
      "Rename local variables to avoid name conflicts with the caller",
      "Connect the inlined code result to the call site result variable"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex01",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Simple Memory Allocator",
    "difficulty": 2,
    "description": "Implement a basic memory allocator using a free list to manage heap memory allocation and deallocation.",
    "starterCode": "class MemoryAllocator:\n    def __init__(self, heap_size):\n        self.heap_size = heap_size\n        # Free list: list of (start, size) tuples\n        self.free_list = [(0, heap_size)]\n        self.allocated = {}  # address -> size\n\n    def allocate(self, size):\n        \"\"\"\n        Allocate a block of memory.\n        Returns: starting address or None if allocation fails\n        \"\"\"\n        # TODO: Implement first-fit allocation\n        pass\n\n    def free(self, address):\n        \"\"\"Free a previously allocated block.\"\"\"\n        # TODO: Return block to free list\n        pass",
    "solution": "class MemoryAllocator:\n    def __init__(self, heap_size):\n        self.heap_size = heap_size\n        # Free list: list of (start, size) tuples\n        self.free_list = [(0, heap_size)]\n        self.allocated = {}  # address -> size\n\n    def allocate(self, size):\n        \"\"\"\n        Allocate a block of memory.\n        Returns: starting address or None if allocation fails\n        \"\"\"\n        # First-fit: find first free block large enough\n        for i, (start, block_size) in enumerate(self.free_list):\n            if block_size >= size:\n                # Allocate from this block\n                self.allocated[start] = size\n\n                # Update free list\n                if block_size == size:\n                    # Exact fit - remove block\n                    self.free_list.pop(i)\n                else:\n                    # Split block\n                    self.free_list[i] = (start + size, block_size - size)\n\n                return start\n\n        # No suitable block found\n        return None\n\n    def free(self, address):\n        \"\"\"Free a previously allocated block.\"\"\"\n        if address not in self.allocated:\n            return False\n\n        size = self.allocated[address]\n        del self.allocated[address]\n\n        # Add to free list\n        self.free_list.append((address, size))\n\n        # Sort free list by address for coalescing\n        self.free_list.sort()\n\n        # Coalesce adjacent free blocks\n        i = 0\n        while i < len(self.free_list) - 1:\n            start1, size1 = self.free_list[i]\n            start2, size2 = self.free_list[i + 1]\n\n            # If blocks are adjacent, merge them\n            if start1 + size1 == start2:\n                self.free_list[i] = (start1, size1 + size2)\n                self.free_list.pop(i + 1)\n            else:\n                i += 1\n\n        return True",
    "testCases": [
      {
        "input": "allocator = MemoryAllocator(1000)\naddr1 = allocator.allocate(100)\nprint(addr1)",
        "expectedOutput": "0",
        "isHidden": false,
        "description": "First allocation at address 0"
      },
      {
        "input": "allocator = MemoryAllocator(1000)\naddr1 = allocator.allocate(100)\naddr2 = allocator.allocate(200)\nprint(addr2)",
        "expectedOutput": "100",
        "isHidden": false,
        "description": "Second allocation after first"
      },
      {
        "input": "allocator = MemoryAllocator(1000)\naddr1 = allocator.allocate(100)\nallocator.free(addr1)\naddr2 = allocator.allocate(50)\nprint(addr2)",
        "isHidden": true,
        "description": "Reuse freed memory"
      }
    ],
    "hints": [
      "Use first-fit strategy: allocate from the first free block that is large enough",
      "Split free blocks when they are larger than the requested size",
      "When freeing, add the block back to the free list",
      "Coalesce adjacent free blocks to reduce fragmentation"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex02",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Mark and Sweep Garbage Collector",
    "difficulty": 3,
    "description": "Implement a mark-and-sweep garbage collector that identifies and reclaims unreachable objects.",
    "starterCode": "class MarkSweepGC:\n    def __init__(self):\n        self.objects = {}  # address -> {'size': N, 'refs': [addresses]}\n        self.roots = set()  # Root set (global variables, stack)\n        self.next_addr = 0\n\n    def allocate(self, size, refs=None):\n        \"\"\"Allocate an object. Returns address.\"\"\"\n        addr = self.next_addr\n        self.next_addr += size\n        self.objects[addr] = {'size': size, 'refs': refs or [], 'marked': False}\n        return addr\n\n    def add_root(self, address):\n        \"\"\"Add an address to the root set.\"\"\"\n        self.roots.add(address)\n\n    def mark(self):\n        \"\"\"Mark all reachable objects starting from roots.\"\"\"\n        # TODO: Implement marking phase\n        pass\n\n    def sweep(self):\n        \"\"\"Reclaim unmarked objects.\"\"\"\n        # TODO: Implement sweep phase\n        pass\n\n    def collect(self):\n        \"\"\"Run garbage collection.\"\"\"\n        self.mark()\n        self.sweep()",
    "solution": "class MarkSweepGC:\n    def __init__(self):\n        self.objects = {}  # address -> {'size': N, 'refs': [addresses]}\n        self.roots = set()  # Root set (global variables, stack)\n        self.next_addr = 0\n\n    def allocate(self, size, refs=None):\n        \"\"\"Allocate an object. Returns address.\"\"\"\n        addr = self.next_addr\n        self.next_addr += size\n        self.objects[addr] = {'size': size, 'refs': refs or [], 'marked': False}\n        return addr\n\n    def add_root(self, address):\n        \"\"\"Add an address to the root set.\"\"\"\n        self.roots.add(address)\n\n    def mark(self):\n        \"\"\"Mark all reachable objects starting from roots.\"\"\"\n        # Clear all marks\n        for obj in self.objects.values():\n            obj['marked'] = False\n\n        # Mark from roots using DFS\n        worklist = list(self.roots)\n\n        while worklist:\n            addr = worklist.pop()\n\n            if addr not in self.objects:\n                continue\n\n            obj = self.objects[addr]\n\n            if obj['marked']:\n                continue\n\n            # Mark this object\n            obj['marked'] = True\n\n            # Add referenced objects to worklist\n            for ref_addr in obj['refs']:\n                if ref_addr in self.objects and not self.objects[ref_addr]['marked']:\n                    worklist.append(ref_addr)\n\n    def sweep(self):\n        \"\"\"Reclaim unmarked objects.\"\"\"\n        # Collect addresses of unmarked objects\n        to_delete = []\n        for addr, obj in self.objects.items():\n            if not obj['marked']:\n                to_delete.append(addr)\n\n        # Delete unmarked objects\n        for addr in to_delete:\n            del self.objects[addr]\n\n    def collect(self):\n        \"\"\"Run garbage collection.\"\"\"\n        self.mark()\n        self.sweep()",
    "testCases": [
      {
        "input": "gc = MarkSweepGC()\nobj1 = gc.allocate(10)\nobj2 = gc.allocate(20)\ngc.add_root(obj1)\ngc.collect()\nprint(obj1 in gc.objects)",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Root object is not collected"
      },
      {
        "input": "gc = MarkSweepGC()\nobj1 = gc.allocate(10)\nobj2 = gc.allocate(20)\ngc.add_root(obj1)\ngc.collect()\nprint(obj2 in gc.objects)",
        "expectedOutput": "False",
        "isHidden": false,
        "description": "Unreachable object is collected"
      },
      {
        "input": "gc = MarkSweepGC()\nobj1 = gc.allocate(10, refs=[])\nobj2 = gc.allocate(20, refs=[])\ngc.objects[obj1]['refs'] = [obj2]\ngc.add_root(obj1)\ngc.collect()\nprint(obj2 in gc.objects)",
        "isHidden": true,
        "description": "Referenced object is not collected"
      }
    ],
    "hints": [
      "Mark phase: traverse from roots and mark all reachable objects",
      "Use a worklist to perform depth-first or breadth-first traversal",
      "Sweep phase: delete all objects that are not marked",
      "Clear marks before each collection cycle"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex03",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Reference Counting Collector",
    "difficulty": 2,
    "description": "Implement reference counting garbage collection where objects are freed when their reference count reaches zero.",
    "starterCode": "class RefCountingGC:\n    def __init__(self):\n        self.objects = {}  # address -> {'size': N, 'refcount': M}\n        self.next_addr = 0\n\n    def allocate(self, size):\n        \"\"\"Allocate an object with refcount 1. Returns address.\"\"\"\n        addr = self.next_addr\n        self.next_addr += size\n        self.objects[addr] = {'size': size, 'refcount': 1}\n        return addr\n\n    def add_ref(self, address):\n        \"\"\"Increment reference count.\"\"\"\n        # TODO: Implement\n        pass\n\n    def remove_ref(self, address):\n        \"\"\"Decrement reference count and free if zero.\"\"\"\n        # TODO: Implement\n        pass",
    "solution": "class RefCountingGC:\n    def __init__(self):\n        self.objects = {}  # address -> {'size': N, 'refcount': M}\n        self.next_addr = 0\n\n    def allocate(self, size):\n        \"\"\"Allocate an object with refcount 1. Returns address.\"\"\"\n        addr = self.next_addr\n        self.next_addr += size\n        self.objects[addr] = {'size': size, 'refcount': 1}\n        return addr\n\n    def add_ref(self, address):\n        \"\"\"Increment reference count.\"\"\"\n        if address in self.objects:\n            self.objects[address]['refcount'] += 1\n\n    def remove_ref(self, address):\n        \"\"\"Decrement reference count and free if zero.\"\"\"\n        if address not in self.objects:\n            return\n\n        self.objects[address]['refcount'] -= 1\n\n        # Free if refcount reaches zero\n        if self.objects[address]['refcount'] == 0:\n            del self.objects[address]",
    "testCases": [
      {
        "input": "gc = RefCountingGC()\nobj = gc.allocate(100)\ngc.add_ref(obj)\nprint(gc.objects[obj]['refcount'])",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Reference count incremented"
      },
      {
        "input": "gc = RefCountingGC()\nobj = gc.allocate(100)\ngc.remove_ref(obj)\nprint(obj in gc.objects)",
        "expectedOutput": "False",
        "isHidden": false,
        "description": "Object freed when refcount reaches 0"
      },
      {
        "input": "gc = RefCountingGC()\nobj = gc.allocate(100)\ngc.add_ref(obj)\ngc.remove_ref(obj)\nprint(obj in gc.objects)",
        "isHidden": true,
        "description": "Object remains while refcount > 0"
      }
    ],
    "hints": [
      "Initialize objects with refcount 1 when allocated",
      "Increment refcount when a new reference is created",
      "Decrement refcount when a reference is removed",
      "Free the object when refcount reaches zero"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex04",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Copying Collector",
    "difficulty": 3,
    "description": "Implement a copying garbage collector that moves live objects to a new space and compacts memory.",
    "starterCode": "class CopyingGC:\n    def __init__(self, heap_size):\n        self.heap_size = heap_size\n        self.from_space = {'start': 0, 'end': heap_size // 2, 'next': 0}\n        self.to_space = {'start': heap_size // 2, 'end': heap_size, 'next': heap_size // 2}\n        self.objects = {}  # old_addr -> {'size': N, 'new_addr': M, 'refs': [...]}\n        self.roots = set()\n\n    def allocate(self, size, refs=None):\n        \"\"\"Allocate in from-space. Returns address.\"\"\"\n        # TODO: Allocate from from_space\n        pass\n\n    def collect(self):\n        \"\"\"Perform copying collection.\"\"\"\n        # TODO: Copy live objects to to-space and update references\n        # Then swap spaces\n        pass",
    "solution": "class CopyingGC:\n    def __init__(self, heap_size):\n        self.heap_size = heap_size\n        self.from_space = {'start': 0, 'end': heap_size // 2, 'next': 0}\n        self.to_space = {'start': heap_size // 2, 'end': heap_size, 'next': heap_size // 2}\n        self.objects = {}  # old_addr -> {'size': N, 'new_addr': M, 'refs': [...]}\n        self.roots = set()\n\n    def allocate(self, size, refs=None):\n        \"\"\"Allocate in from-space. Returns address.\"\"\"\n        addr = self.from_space['start'] + self.from_space['next']\n\n        if addr + size > self.from_space['end']:\n            return None  # Out of memory\n\n        self.objects[addr] = {'size': size, 'new_addr': None, 'refs': refs or []}\n        self.from_space['next'] += size\n\n        return addr\n\n    def add_root(self, address):\n        \"\"\"Add a root reference.\"\"\"\n        self.roots.add(address)\n\n    def copy_object(self, old_addr):\n        \"\"\"Copy an object to to-space. Returns new address.\"\"\"\n        if old_addr not in self.objects:\n            return old_addr\n\n        obj = self.objects[old_addr]\n\n        # If already copied, return new address\n        if obj['new_addr'] is not None:\n            return obj['new_addr']\n\n        # Allocate in to-space\n        new_addr = self.to_space['start'] + self.to_space['next']\n        self.to_space['next'] += obj['size']\n\n        # Record new address\n        obj['new_addr'] = new_addr\n\n        return new_addr\n\n    def collect(self):\n        \"\"\"Perform copying collection.\"\"\"\n        # Reset to-space\n        self.to_space['next'] = 0\n\n        # Copy roots and update root references\n        new_roots = set()\n        for old_addr in self.roots:\n            new_addr = self.copy_object(old_addr)\n            new_roots.add(new_addr)\n\n        # Process worklist: copy transitively reachable objects\n        worklist = list(new_roots)\n        visited = set()\n\n        while worklist:\n            addr = worklist.pop()\n\n            if addr in visited:\n                continue\n\n            visited.add(addr)\n\n            # Find corresponding old address\n            old_addr = None\n            for old, obj in self.objects.items():\n                if obj['new_addr'] == addr:\n                    old_addr = old\n                    break\n\n            if old_addr is None:\n                continue\n\n            obj = self.objects[old_addr]\n\n            # Copy referenced objects\n            new_refs = []\n            for ref in obj['refs']:\n                new_ref = self.copy_object(ref)\n                new_refs.append(new_ref)\n                if new_ref not in visited:\n                    worklist.append(new_ref)\n\n            obj['refs'] = new_refs\n\n        # Rebuild objects table with new addresses\n        new_objects = {}\n        for old_addr, obj in self.objects.items():\n            if obj['new_addr'] is not None:\n                new_objects[obj['new_addr']] = {'size': obj['size'], 'new_addr': None, 'refs': obj['refs']}\n\n        self.objects = new_objects\n        self.roots = new_roots\n\n        # Swap from-space and to-space\n        self.from_space, self.to_space = self.to_space, self.from_space\n        self.from_space['next'] = self.to_space['next']\n        self.to_space['next'] = 0",
    "testCases": [
      {
        "input": "gc = CopyingGC(1000)\nobj1 = gc.allocate(10)\ngc.add_root(obj1)\nbefore_count = len(gc.objects)\ngc.collect()\nafter_count = len(gc.objects)\nprint(before_count == after_count)",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Root object survives collection"
      },
      {
        "input": "gc = CopyingGC(1000)\nobj1 = gc.allocate(10)\nobj2 = gc.allocate(20)\ngc.add_root(obj1)\ngc.collect()\nprint(len(gc.objects))",
        "expectedOutput": "1",
        "isHidden": false,
        "description": "Unreachable object not copied"
      },
      {
        "input": "gc = CopyingGC(1000)\nobj1 = gc.allocate(10, [])\nobj2 = gc.allocate(20, [])\ngc.objects[obj1]['refs'] = [obj2]\ngc.add_root(obj1)\ngc.collect()\nprint(len(gc.objects))",
        "isHidden": true,
        "description": "Referenced object is copied"
      }
    ],
    "hints": [
      "Divide heap into two semispaces: from-space and to-space",
      "Copy live objects from from-space to to-space",
      "Update all references to point to new addresses",
      "Swap spaces after collection is complete"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex05",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Generational Garbage Collector",
    "difficulty": 4,
    "description": "Implement a simple generational garbage collector with young and old generations.",
    "starterCode": "class GenerationalGC:\n    def __init__(self):\n        self.young = {}  # Young generation objects\n        self.old = {}  # Old generation objects\n        self.roots = set()\n        self.next_addr = 0\n        self.survivor_threshold = 2  # Promote after 2 collections\n\n    def allocate(self, size):\n        \"\"\"Allocate in young generation.\"\"\"\n        addr = self.next_addr\n        self.next_addr += size\n        self.young[addr] = {'size': size, 'age': 0, 'marked': False}\n        return addr\n\n    def minor_collection(self):\n        \"\"\"Collect young generation only.\"\"\"\n        # TODO: Collect young generation, promote survivors\n        pass\n\n    def major_collection(self):\n        \"\"\"Collect both generations.\"\"\"\n        # TODO: Full collection\n        pass",
    "solution": "class GenerationalGC:\n    def __init__(self):\n        self.young = {}  # Young generation objects\n        self.old = {}  # Old generation objects\n        self.roots = set()\n        self.next_addr = 0\n        self.survivor_threshold = 2  # Promote after 2 collections\n\n    def allocate(self, size):\n        \"\"\"Allocate in young generation.\"\"\"\n        addr = self.next_addr\n        self.next_addr += size\n        self.young[addr] = {'size': size, 'age': 0, 'marked': False}\n        return addr\n\n    def add_root(self, address):\n        \"\"\"Add a root reference.\"\"\"\n        self.roots.add(address)\n\n    def mark_from_roots(self, generation):\n        \"\"\"Mark objects in a generation reachable from roots.\"\"\"\n        for addr in self.roots:\n            if addr in generation:\n                generation[addr]['marked'] = True\n\n    def minor_collection(self):\n        \"\"\"Collect young generation only.\"\"\"\n        # Mark young objects reachable from roots\n        self.mark_from_roots(self.young)\n\n        # Also mark young objects referenced from old generation\n        for old_obj in self.old.values():\n            # In a real implementation, would track old->young references\n            pass\n\n        # Collect unmarked young objects\n        to_delete = []\n        to_promote = []\n\n        for addr, obj in self.young.items():\n            if obj['marked']:\n                # Survivor - increment age\n                obj['age'] += 1\n                obj['marked'] = False\n\n                # Check if should be promoted\n                if obj['age'] >= self.survivor_threshold:\n                    to_promote.append(addr)\n            else:\n                # Not marked - collect it\n                to_delete.append(addr)\n\n        # Delete dead objects\n        for addr in to_delete:\n            del self.young[addr]\n\n        # Promote old survivors to old generation\n        for addr in to_promote:\n            self.old[addr] = self.young[addr]\n            del self.young[addr]\n\n    def major_collection(self):\n        \"\"\"Collect both generations.\"\"\"\n        # Mark all reachable objects\n        self.mark_from_roots(self.young)\n        self.mark_from_roots(self.old)\n\n        # Sweep young generation\n        to_delete_young = [addr for addr, obj in self.young.items() if not obj['marked']]\n        for addr in to_delete_young:\n            del self.young[addr]\n\n        # Sweep old generation\n        to_delete_old = [addr for addr, obj in self.old.items() if not obj['marked']]\n        for addr in to_delete_old:\n            del self.old[addr]\n\n        # Clear marks\n        for obj in self.young.values():\n            obj['marked'] = False\n        for obj in self.old.values():\n            obj['marked'] = False",
    "testCases": [
      {
        "input": "gc = GenerationalGC()\nobj = gc.allocate(10)\ngc.add_root(obj)\ngc.minor_collection()\nprint(obj in gc.young)",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Young survivor stays in young generation initially"
      },
      {
        "input": "gc = GenerationalGC()\nobj = gc.allocate(10)\ngc.add_root(obj)\ngc.minor_collection()\ngc.minor_collection()\nprint(obj in gc.old)",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Object promoted after threshold"
      },
      {
        "input": "gc = GenerationalGC()\nobj1 = gc.allocate(10)\nobj2 = gc.allocate(20)\ngc.add_root(obj1)\ngc.minor_collection()\nprint(obj2 in gc.young)",
        "isHidden": true,
        "description": "Unreachable object collected"
      }
    ],
    "hints": [
      "Allocate new objects in the young generation",
      "Minor collection only collects the young generation",
      "Promote objects that survive multiple collections to old generation",
      "Major collection collects both generations"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex06",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Stack Frame Manager",
    "difficulty": 2,
    "description": "Implement a stack frame manager for function calls that manages activation records.",
    "starterCode": "class StackFrameManager:\n    def __init__(self, stack_size=1000):\n        self.stack = [None] * stack_size\n        self.sp = 0  # Stack pointer\n        self.fp = 0  # Frame pointer\n\n    def push_frame(self, num_locals, return_address):\n        \"\"\"\n        Create a new stack frame.\n        Returns the new frame pointer.\n        \"\"\"\n        # TODO: Save old FP, create new frame\n        pass\n\n    def pop_frame(self):\n        \"\"\"\n        Remove the current stack frame.\n        Returns the return address.\n        \"\"\"\n        # TODO: Restore old FP and SP\n        pass\n\n    def set_local(self, offset, value):\n        \"\"\"Set a local variable in current frame.\"\"\"\n        # TODO: Store at FP + offset\n        pass\n\n    def get_local(self, offset):\n        \"\"\"Get a local variable from current frame.\"\"\"\n        # TODO: Load from FP + offset\n        pass",
    "solution": "class StackFrameManager:\n    def __init__(self, stack_size=1000):\n        self.stack = [None] * stack_size\n        self.sp = 0  # Stack pointer\n        self.fp = 0  # Frame pointer\n        self.frames = []  # Track frame information\n\n    def push_frame(self, num_locals, return_address):\n        \"\"\"\n        Create a new stack frame.\n        Frame layout: [old_fp, return_addr, local0, local1, ...]\n        Returns the new frame pointer.\n        \"\"\"\n        # Save current frame info\n        self.frames.append({'fp': self.fp, 'sp': self.sp})\n\n        # Push old frame pointer\n        self.stack[self.sp] = self.fp\n        self.sp += 1\n\n        # Push return address\n        self.stack[self.sp] = return_address\n        self.sp += 1\n\n        # Set new frame pointer\n        self.fp = self.sp\n\n        # Allocate space for locals\n        self.sp += num_locals\n\n        return self.fp\n\n    def pop_frame(self):\n        \"\"\"\n        Remove the current stack frame.\n        Returns the return address.\n        \"\"\"\n        # Reset SP to FP\n        self.sp = self.fp\n\n        # Get return address (just below FP)\n        return_address = self.stack[self.fp - 1]\n\n        # Restore old FP\n        self.fp = self.stack[self.fp - 2]\n\n        # Pop saved FP and return address\n        self.sp -= 2\n\n        # Restore previous frame info\n        if self.frames:\n            self.frames.pop()\n\n        return return_address\n\n    def set_local(self, offset, value):\n        \"\"\"Set a local variable in current frame.\"\"\"\n        self.stack[self.fp + offset] = value\n\n    def get_local(self, offset):\n        \"\"\"Get a local variable from current frame.\"\"\"\n        return self.stack[self.fp + offset]",
    "testCases": [
      {
        "input": "sm = StackFrameManager()\nfp = sm.push_frame(3, 'return_here')\nsm.set_local(0, 42)\nprint(sm.get_local(0))",
        "expectedOutput": "42",
        "isHidden": false,
        "description": "Set and get local variable"
      },
      {
        "input": "sm = StackFrameManager()\nfp1 = sm.push_frame(2, 'ret1')\nfp2 = sm.push_frame(3, 'ret2')\nret = sm.pop_frame()\nprint(ret)",
        "expectedOutput": "ret2",
        "isHidden": false,
        "description": "Return address from pop"
      },
      {
        "input": "sm = StackFrameManager()\nfp1 = sm.push_frame(2, 'ret1')\nsm.set_local(0, 100)\nfp2 = sm.push_frame(1, 'ret2')\nsm.pop_frame()\nprint(sm.get_local(0))",
        "isHidden": true,
        "description": "Locals preserved across nested calls"
      }
    ],
    "hints": [
      "Each frame contains: saved frame pointer, return address, and local variables",
      "Frame pointer points to the base of the current frame",
      "Stack pointer points to the top of the stack",
      "When pushing a frame, save the old FP and set FP to current SP"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex07",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Exception Handler",
    "difficulty": 3,
    "description": "Implement exception handling runtime support with try-catch blocks and exception propagation.",
    "starterCode": "class ExceptionHandler:\n    def __init__(self):\n        self.handler_stack = []  # Stack of exception handlers\n        self.current_exception = None\n\n    def enter_try(self, handler_address):\n        \"\"\"Enter a try block - register exception handler.\"\"\"\n        # TODO: Push handler onto stack\n        pass\n\n    def exit_try(self):\n        \"\"\"Exit a try block - remove handler.\"\"\"\n        # TODO: Pop handler from stack\n        pass\n\n    def throw(self, exception):\n        \"\"\"Throw an exception.\"\"\"\n        # TODO: Find and invoke appropriate handler\n        pass",
    "solution": "class ExceptionHandler:\n    def __init__(self):\n        self.handler_stack = []  # Stack of exception handlers\n        self.current_exception = None\n\n    def enter_try(self, handler_address, exception_type=None):\n        \"\"\"Enter a try block - register exception handler.\"\"\"\n        self.handler_stack.append({\n            'handler': handler_address,\n            'exception_type': exception_type\n        })\n\n    def exit_try(self):\n        \"\"\"Exit a try block - remove handler.\"\"\"\n        if self.handler_stack:\n            self.handler_stack.pop()\n\n    def throw(self, exception):\n        \"\"\"\n        Throw an exception.\n        Returns the handler address to jump to, or None if unhandled.\n        \"\"\"\n        self.current_exception = exception\n\n        # Search for matching handler (most recent first)\n        while self.handler_stack:\n            handler_info = self.handler_stack.pop()\n\n            # Check if handler matches exception type\n            exception_type = handler_info['exception_type']\n\n            if exception_type is None or exception_type == exception.get('type'):\n                # Found matching handler\n                return handler_info['handler']\n\n        # No handler found\n        return None\n\n    def get_exception(self):\n        \"\"\"Get the current exception.\"\"\"\n        return self.current_exception",
    "testCases": [
      {
        "input": "eh = ExceptionHandler()\neh.enter_try('handler1')\nhandler = eh.throw({'type': 'ValueError', 'msg': 'bad value'})\nprint(handler)",
        "expectedOutput": "handler1",
        "isHidden": false,
        "description": "Find exception handler"
      },
      {
        "input": "eh = ExceptionHandler()\neh.enter_try('handler1', 'TypeError')\neh.enter_try('handler2', 'ValueError')\nhandler = eh.throw({'type': 'ValueError', 'msg': 'bad value'})\nprint(handler)",
        "expectedOutput": "handler2",
        "isHidden": false,
        "description": "Match most recent handler"
      },
      {
        "input": "eh = ExceptionHandler()\nhandler = eh.throw({'type': 'Error', 'msg': 'oops'})\nprint(handler is None)",
        "isHidden": true,
        "description": "Unhandled exception returns None"
      }
    ],
    "hints": [
      "Maintain a stack of active exception handlers",
      "When entering a try block, push the handler address",
      "When throwing, search the handler stack from most recent to oldest",
      "Pop handlers until a matching one is found or stack is empty"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex08",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Symbol Linker",
    "difficulty": 3,
    "description": "Implement a simple linker that resolves symbols across object files and produces an executable.",
    "starterCode": "class Linker:\n    def __init__(self):\n        self.symbol_table = {}  # symbol_name -> address\n        self.relocations = []  # (location, symbol_name)\n        self.code = []  # Final executable code\n\n    def add_object_file(self, symbols, code, relocs):\n        \"\"\"\n        Add an object file.\n        symbols: dict of symbol_name -> offset in code\n        code: list of instructions/data\n        relocs: list of (offset, symbol_name) needing relocation\n        \"\"\"\n        # TODO: Merge symbols and track relocations\n        pass\n\n    def link(self):\n        \"\"\"Resolve all relocations and produce executable.\"\"\"\n        # TODO: Resolve symbols and patch addresses\n        pass",
    "solution": "class Linker:\n    def __init__(self):\n        self.symbol_table = {}  # symbol_name -> address\n        self.relocations = []  # (location, symbol_name)\n        self.code = []  # Final executable code\n        self.next_address = 0\n\n    def add_object_file(self, symbols, code, relocs):\n        \"\"\"\n        Add an object file.\n        symbols: dict of symbol_name -> offset in code\n        code: list of instructions/data\n        relocs: list of (offset, symbol_name) needing relocation\n        \"\"\"\n        base_address = self.next_address\n\n        # Add code to executable\n        self.code.extend(code)\n\n        # Add symbols with relocated addresses\n        for symbol, offset in symbols.items():\n            absolute_address = base_address + offset\n\n            if symbol in self.symbol_table:\n                raise ValueError(f\"Duplicate symbol: {symbol}\")\n\n            self.symbol_table[symbol] = absolute_address\n\n        # Add relocations with relocated positions\n        for offset, symbol in relocs:\n            absolute_location = base_address + offset\n            self.relocations.append((absolute_location, symbol))\n\n        # Update next available address\n        self.next_address += len(code)\n\n    def link(self):\n        \"\"\"Resolve all relocations and produce executable.\"\"\"\n        # Resolve all relocations\n        for location, symbol in self.relocations:\n            if symbol not in self.symbol_table:\n                raise ValueError(f\"Undefined symbol: {symbol}\")\n\n            # Get symbol address\n            symbol_address = self.symbol_table[symbol]\n\n            # Patch the code at location\n            # Assuming instruction format allows direct address patching\n            if location < len(self.code):\n                # Replace placeholder with actual address\n                instr = self.code[location]\n                if isinstance(instr, str):\n                    # Replace symbol reference with address\n                    self.code[location] = instr.replace(\"$\" + symbol, str(symbol_address))\n\n        return self.code",
    "testCases": [
      {
        "input": "linker = Linker()\nlinker.add_object_file({'main': 0}, ['CALL $func', 'RET'], [(0, 'func')])\nlinker.add_object_file({'func': 0}, ['PUSH', 'POP', 'RET'], [])\nlinker.link()\nprint(linker.symbol_table['func'])",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Symbol in second object file"
      },
      {
        "input": "linker = Linker()\nlinker.add_object_file({'foo': 0, 'bar': 1}, ['NOP', 'NOP'], [])\nprint(len(linker.symbol_table))",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Multiple symbols in one file"
      },
      {
        "input": "linker = Linker()\nlinker.add_object_file({'start': 0}, ['CALL $helper'], [(0, 'helper')])\nlinker.add_object_file({'helper': 1}, ['NOP', 'RET'], [])\ncode = linker.link()\nprint('2' in code[0])",
        "isHidden": true,
        "description": "Relocation resolved correctly"
      }
    ],
    "hints": [
      "Combine code from all object files sequentially",
      "Track base address for each object file",
      "Adjust symbol addresses by adding base address",
      "Patch relocations by replacing symbol references with actual addresses"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex09",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Dynamic Loader",
    "difficulty": 3,
    "description": "Implement a dynamic loader that loads shared libraries at runtime and resolves symbols.",
    "starterCode": "class DynamicLoader:\n    def __init__(self):\n        self.loaded_libs = {}  # lib_name -> {'base': addr, 'symbols': {...}}\n        self.next_address = 1000\n\n    def load_library(self, lib_name, symbols, size):\n        \"\"\"\n        Load a shared library.\n        symbols: dict of symbol_name -> offset\n        size: library size in bytes\n        \"\"\"\n        # TODO: Allocate memory and record symbols\n        pass\n\n    def resolve_symbol(self, symbol_name):\n        \"\"\"Look up a symbol in loaded libraries. Returns address.\"\"\"\n        # TODO: Search all loaded libraries\n        pass",
    "solution": "class DynamicLoader:\n    def __init__(self):\n        self.loaded_libs = {}  # lib_name -> {'base': addr, 'symbols': {...}}\n        self.next_address = 1000\n\n    def load_library(self, lib_name, symbols, size):\n        \"\"\"\n        Load a shared library.\n        symbols: dict of symbol_name -> offset\n        size: library size in bytes\n        Returns: base address where library was loaded\n        \"\"\"\n        if lib_name in self.loaded_libs:\n            # Already loaded - return existing base\n            return self.loaded_libs[lib_name]['base']\n\n        # Allocate memory for library\n        base_address = self.next_address\n        self.next_address += size\n\n        # Record library information\n        self.loaded_libs[lib_name] = {\n            'base': base_address,\n            'symbols': symbols,\n            'size': size\n        }\n\n        return base_address\n\n    def resolve_symbol(self, symbol_name):\n        \"\"\"Look up a symbol in loaded libraries. Returns address.\"\"\"\n        # Search all loaded libraries\n        for lib_name, lib_info in self.loaded_libs.items():\n            symbols = lib_info['symbols']\n\n            if symbol_name in symbols:\n                # Found symbol - compute absolute address\n                offset = symbols[symbol_name]\n                base = lib_info['base']\n                return base + offset\n\n        # Symbol not found\n        return None\n\n    def unload_library(self, lib_name):\n        \"\"\"Unload a library.\"\"\"\n        if lib_name in self.loaded_libs:\n            del self.loaded_libs[lib_name]\n            return True\n        return False",
    "testCases": [
      {
        "input": "loader = DynamicLoader()\nbase = loader.load_library('libc', {'printf': 10, 'malloc': 50}, 200)\naddr = loader.resolve_symbol('printf')\nprint(addr)",
        "expectedOutput": "1010",
        "isHidden": false,
        "description": "Resolve symbol to absolute address"
      },
      {
        "input": "loader = DynamicLoader()\nloader.load_library('lib1', {'foo': 0}, 100)\nloader.load_library('lib2', {'bar': 20}, 100)\naddr = loader.resolve_symbol('bar')\nprint(addr)",
        "expectedOutput": "1120",
        "isHidden": false,
        "description": "Symbol in second library"
      },
      {
        "input": "loader = DynamicLoader()\nloader.load_library('mylib', {'func': 5}, 50)\naddr = loader.resolve_symbol('unknown')\nprint(addr is None)",
        "isHidden": true,
        "description": "Unknown symbol returns None"
      }
    ],
    "hints": [
      "Assign each library a base address in memory",
      "Store library symbols with their offsets from the base",
      "To resolve a symbol, search all loaded libraries",
      "Compute absolute address as base + offset"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex10",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Virtual Method Table",
    "difficulty": 3,
    "description": "Implement virtual method tables (vtables) for dynamic dispatch in object-oriented languages.",
    "starterCode": "class VTableManager:\n    def __init__(self):\n        self.vtables = {}  # class_name -> [method_addresses]\n        self.objects = {}  # object_id -> class_name\n\n    def create_vtable(self, class_name, methods):\n        \"\"\"\n        Create a vtable for a class.\n        methods: list of (method_name, address) tuples in order\n        \"\"\"\n        # TODO: Store vtable\n        pass\n\n    def create_object(self, object_id, class_name):\n        \"\"\"Create an object instance of a class.\"\"\"\n        # TODO: Associate object with its vtable\n        pass\n\n    def call_method(self, object_id, method_index):\n        \"\"\"\n        Perform virtual method call.\n        Returns the method address to call.\n        \"\"\"\n        # TODO: Look up method in object's vtable\n        pass",
    "solution": "class VTableManager:\n    def __init__(self):\n        self.vtables = {}  # class_name -> {'methods': [...], 'parent': class_name}\n        self.objects = {}  # object_id -> class_name\n\n    def create_vtable(self, class_name, methods, parent=None):\n        \"\"\"\n        Create a vtable for a class.\n        methods: list of (method_name, address) tuples in order\n        parent: parent class name for inheritance\n        \"\"\"\n        vtable = []\n\n        # If there's a parent, start with parent's methods\n        if parent and parent in self.vtables:\n            vtable = self.vtables[parent]['methods'].copy()\n\n        # Override or add methods\n        method_dict = {name: addr for name, addr in methods}\n\n        # Update vtable with new/overridden methods\n        for i, (name, addr) in enumerate(vtable):\n            if name in method_dict:\n                # Override parent method\n                vtable[i] = (name, method_dict[name])\n                del method_dict[name]\n\n        # Add new methods\n        for name, addr in methods:\n            if name in method_dict:\n                vtable.append((name, addr))\n\n        self.vtables[class_name] = {\n            'methods': vtable,\n            'parent': parent\n        }\n\n    def create_object(self, object_id, class_name):\n        \"\"\"Create an object instance of a class.\"\"\"\n        if class_name not in self.vtables:\n            raise ValueError(f\"Unknown class: {class_name}\")\n\n        self.objects[object_id] = class_name\n\n    def call_method(self, object_id, method_index):\n        \"\"\"\n        Perform virtual method call.\n        Returns the method address to call.\n        \"\"\"\n        if object_id not in self.objects:\n            raise ValueError(f\"Unknown object: {object_id}\")\n\n        class_name = self.objects[object_id]\n        vtable = self.vtables[class_name]['methods']\n\n        if method_index >= len(vtable):\n            raise ValueError(f\"Method index out of bounds: {method_index}\")\n\n        method_name, method_address = vtable[method_index]\n        return method_address",
    "testCases": [
      {
        "input": "vtm = VTableManager()\nvtm.create_vtable('Animal', [('speak', 100), ('move', 200)])\nvtm.create_object('obj1', 'Animal')\naddr = vtm.call_method('obj1', 0)\nprint(addr)",
        "expectedOutput": "100",
        "isHidden": false,
        "description": "Call first method"
      },
      {
        "input": "vtm = VTableManager()\nvtm.create_vtable('Base', [('foo', 100)])\nvtm.create_vtable('Derived', [('foo', 300)], parent='Base')\nvtm.create_object('obj', 'Derived')\naddr = vtm.call_method('obj', 0)\nprint(addr)",
        "expectedOutput": "300",
        "isHidden": false,
        "description": "Overridden method in derived class"
      },
      {
        "input": "vtm = VTableManager()\nvtm.create_vtable('Class1', [('method1', 100), ('method2', 200)])\nvtm.create_object('obj', 'Class1')\naddr = vtm.call_method('obj', 1)\nprint(addr)",
        "isHidden": true,
        "description": "Call second method"
      }
    ],
    "hints": [
      "Store a vtable (array of method addresses) for each class",
      "Each object has a pointer to its class's vtable",
      "Method calls use the method index to look up the address in the vtable",
      "For inheritance, derived class vtables can override parent methods"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex11",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Garbage Collection Write Barrier",
    "difficulty": 4,
    "description": "Implement a write barrier for incremental garbage collection that tracks pointer updates.",
    "starterCode": "class WriteBarrierGC:\n    def __init__(self):\n        self.objects = {}  # address -> {'refs': [...], 'color': 'white/gray/black'}\n        self.gray_set = set()  # Objects to scan\n\n    def allocate(self, address, refs=None):\n        \"\"\"Allocate an object.\"\"\"\n        self.objects[address] = {'refs': refs or [], 'color': 'white'}\n\n    def write_barrier(self, obj_addr, field, new_ref):\n        \"\"\"\n        Write barrier for pointer update.\n        obj_addr: object being modified\n        field: field index\n        new_ref: new reference value\n        \"\"\"\n        # TODO: Update reference and maintain GC invariants\n        pass\n\n    def mark_step(self):\n        \"\"\"Perform one step of incremental marking.\"\"\"\n        # TODO: Mark one gray object\n        pass",
    "solution": "class WriteBarrierGC:\n    def __init__(self):\n        self.objects = {}  # address -> {'refs': [...], 'color': 'white/gray/black'}\n        self.gray_set = set()  # Objects to scan\n        self.roots = set()\n\n    def allocate(self, address, refs=None):\n        \"\"\"Allocate an object.\"\"\"\n        self.objects[address] = {'refs': refs or [], 'color': 'white'}\n\n    def add_root(self, address):\n        \"\"\"Add a root reference.\"\"\"\n        self.roots.add(address)\n        if address in self.objects:\n            self.objects[address]['color'] = 'gray'\n            self.gray_set.add(address)\n\n    def write_barrier(self, obj_addr, field, new_ref):\n        \"\"\"\n        Write barrier for pointer update.\n        Maintains tri-color invariant: no black object points to white object.\n        \"\"\"\n        if obj_addr not in self.objects:\n            return\n\n        obj = self.objects[obj_addr]\n\n        # Update the reference\n        while len(obj['refs']) <= field:\n            obj['refs'].append(None)\n        obj['refs'][field] = new_ref\n\n        # Apply write barrier\n        # If object is black and new reference is white, shade the reference gray\n        if obj['color'] == 'black' and new_ref in self.objects:\n            target = self.objects[new_ref]\n            if target['color'] == 'white':\n                target['color'] = 'gray'\n                self.gray_set.add(new_ref)\n\n    def mark_step(self):\n        \"\"\"Perform one step of incremental marking.\"\"\"\n        if not self.gray_set:\n            return False  # Marking complete\n\n        # Pick a gray object\n        obj_addr = self.gray_set.pop()\n        obj = self.objects[obj_addr]\n\n        # Mark it black\n        obj['color'] = 'black'\n\n        # Shade all white children gray\n        for ref in obj['refs']:\n            if ref in self.objects:\n                target = self.objects[ref]\n                if target['color'] == 'white':\n                    target['color'] = 'gray'\n                    self.gray_set.add(ref)\n\n        return True  # More work to do\n\n    def start_collection(self):\n        \"\"\"Start a new GC cycle.\"\"\"\n        # Reset colors\n        for obj in self.objects.values():\n            obj['color'] = 'white'\n\n        self.gray_set.clear()\n\n        # Mark roots gray\n        for root in self.roots:\n            if root in self.objects:\n                self.objects[root]['color'] = 'gray'\n                self.gray_set.add(root)",
    "testCases": [
      {
        "input": "gc = WriteBarrierGC()\ngc.allocate(100, [])\ngc.allocate(200, [])\ngc.add_root(100)\ngc.objects[100]['color'] = 'black'\ngc.write_barrier(100, 0, 200)\nprint(gc.objects[200]['color'])",
        "expectedOutput": "gray",
        "isHidden": false,
        "description": "Write barrier shades white object gray"
      },
      {
        "input": "gc = WriteBarrierGC()\ngc.allocate(100, [])\ngc.add_root(100)\ngc.mark_step()\nprint(gc.objects[100]['color'])",
        "expectedOutput": "black",
        "isHidden": false,
        "description": "Mark step colors gray object black"
      },
      {
        "input": "gc = WriteBarrierGC()\ngc.allocate(100, [200])\ngc.allocate(200, [])\ngc.add_root(100)\ngc.mark_step()\nprint(200 in gc.gray_set)",
        "isHidden": true,
        "description": "Referenced white objects become gray"
      }
    ],
    "hints": [
      "Use tri-color marking: white (unvisited), gray (to scan), black (scanned)",
      "Write barrier maintains invariant: no black->white pointers",
      "When a black object gets a white reference, shade the reference gray",
      "Incremental marking processes gray objects one at a time"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex12",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Memory Defragmentation",
    "difficulty": 3,
    "description": "Implement memory defragmentation (compaction) to eliminate fragmentation in a heap.",
    "starterCode": "class MemoryCompactor:\n    def __init__(self, heap_size):\n        self.heap_size = heap_size\n        self.allocations = {}  # start_addr -> {'size': N, 'id': obj_id}\n        self.object_refs = {}  # obj_id -> start_addr\n\n    def compact(self):\n        \"\"\"\n        Compact memory by moving allocations to eliminate gaps.\n        Returns: dict mapping old_address -> new_address\n        \"\"\"\n        # TODO: Move allocations to eliminate fragmentation\n        pass",
    "solution": "class MemoryCompactor:\n    def __init__(self, heap_size):\n        self.heap_size = heap_size\n        self.allocations = {}  # start_addr -> {'size': N, 'id': obj_id}\n        self.object_refs = {}  # obj_id -> start_addr\n\n    def allocate(self, obj_id, size):\n        \"\"\"Allocate memory for an object.\"\"\"\n        # Find free space (simplified: linear search)\n        occupied = set()\n        for addr, alloc in self.allocations.items():\n            for i in range(addr, addr + alloc['size']):\n                occupied.add(i)\n\n        # Find first fit\n        for start in range(self.heap_size - size + 1):\n            if all(i not in occupied for i in range(start, start + size)):\n                self.allocations[start] = {'size': size, 'id': obj_id}\n                self.object_refs[obj_id] = start\n                return start\n\n        return None\n\n    def free(self, obj_id):\n        \"\"\"Free an object's memory.\"\"\"\n        if obj_id in self.object_refs:\n            addr = self.object_refs[obj_id]\n            del self.allocations[addr]\n            del self.object_refs[obj_id]\n\n    def compact(self):\n        \"\"\"\n        Compact memory by moving allocations to eliminate gaps.\n        Returns: dict mapping old_address -> new_address\n        \"\"\"\n        # Sort allocations by address\n        sorted_allocs = sorted(self.allocations.items(), key=lambda x: x[0])\n\n        relocation_map = {}\n        new_allocations = {}\n        new_object_refs = {}\n\n        next_addr = 0\n\n        for old_addr, alloc in sorted_allocs:\n            obj_id = alloc['id']\n            size = alloc['size']\n\n            # Move to next available address\n            new_addr = next_addr\n            relocation_map[old_addr] = new_addr\n\n            # Update allocations\n            new_allocations[new_addr] = {'size': size, 'id': obj_id}\n            new_object_refs[obj_id] = new_addr\n\n            next_addr += size\n\n        # Update internal state\n        self.allocations = new_allocations\n        self.object_refs = new_object_refs\n\n        return relocation_map\n\n    def fragmentation(self):\n        \"\"\"Calculate fragmentation: (largest_gap / total_free) if free > 0, else 0.\"\"\"\n        if not self.allocations:\n            return 0.0\n\n        # Find all gaps\n        occupied = []\n        for addr, alloc in self.allocations.items():\n            occupied.append((addr, addr + alloc['size']))\n\n        occupied.sort()\n\n        gaps = []\n        last_end = 0\n\n        for start, end in occupied:\n            if start > last_end:\n                gaps.append(start - last_end)\n            last_end = end\n\n        # Gap at end\n        if last_end < self.heap_size:\n            gaps.append(self.heap_size - last_end)\n\n        if not gaps:\n            return 0.0\n\n        total_free = sum(gaps)\n        largest_gap = max(gaps)\n\n        return largest_gap / total_free if total_free > 0 else 0.0",
    "testCases": [
      {
        "input": "mc = MemoryCompactor(1000)\nmc.allocate('obj1', 100)\nmc.allocate('obj2', 200)\nmc.free('obj1')\nmc.allocate('obj3', 50)\nreloc = mc.compact()\nprint(mc.object_refs['obj3'])",
        "expectedOutput": "200",
        "isHidden": false,
        "description": "Objects compacted to eliminate gaps"
      },
      {
        "input": "mc = MemoryCompactor(1000)\nmc.allocate('a', 100)\nmc.allocate('b', 100)\nreloc = mc.compact()\nprint(len(reloc))",
        "expectedOutput": "2",
        "isHidden": false,
        "description": "Relocation map for all objects"
      },
      {
        "input": "mc = MemoryCompactor(1000)\nmc.allocate('x', 100)\nmc.allocate('y', 100)\nmc.free('x')\nmc.allocate('z', 50)\nbefore_frag = mc.fragmentation()\nmc.compact()\nafter_frag = mc.fragmentation()\nprint(after_frag < before_frag)",
        "isHidden": true,
        "description": "Compaction reduces fragmentation"
      }
    ],
    "hints": [
      "Sort allocations by address",
      "Move each allocation to the next available address sequentially",
      "Maintain a mapping of old addresses to new addresses",
      "After compaction, all allocations should be contiguous"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex13",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "JIT Code Cache",
    "difficulty": 3,
    "description": "Implement a code cache for a JIT compiler that manages compiled code and handles cache eviction.",
    "starterCode": "class JITCodeCache:\n    def __init__(self, max_size):\n        self.max_size = max_size\n        self.cache = {}  # bytecode_id -> {'code': ..., 'size': N, 'hits': M}\n        self.current_size = 0\n\n    def compile_and_cache(self, bytecode_id, compiled_code, code_size):\n        \"\"\"\n        Add compiled code to cache.\n        If cache is full, evict least-used entries.\n        \"\"\"\n        # TODO: Implement caching with LRU eviction\n        pass\n\n    def lookup(self, bytecode_id):\n        \"\"\"Look up compiled code. Returns code or None.\"\"\"\n        # TODO: Return cached code and update stats\n        pass",
    "solution": "class JITCodeCache:\n    def __init__(self, max_size):\n        self.max_size = max_size\n        self.cache = {}  # bytecode_id -> {'code': ..., 'size': N, 'hits': M, 'last_used': T}\n        self.current_size = 0\n        self.time = 0\n\n    def compile_and_cache(self, bytecode_id, compiled_code, code_size):\n        \"\"\"\n        Add compiled code to cache.\n        If cache is full, evict least-used entries.\n        \"\"\"\n        # Check if already cached\n        if bytecode_id in self.cache:\n            return\n\n        # Make room if necessary\n        while self.current_size + code_size > self.max_size and self.cache:\n            self.evict_lru()\n\n        # Add to cache\n        if self.current_size + code_size <= self.max_size:\n            self.cache[bytecode_id] = {\n                'code': compiled_code,\n                'size': code_size,\n                'hits': 0,\n                'last_used': self.time\n            }\n            self.current_size += code_size\n            self.time += 1\n\n    def lookup(self, bytecode_id):\n        \"\"\"Look up compiled code. Returns code or None.\"\"\"\n        if bytecode_id in self.cache:\n            entry = self.cache[bytecode_id]\n            entry['hits'] += 1\n            entry['last_used'] = self.time\n            self.time += 1\n            return entry['code']\n\n        return None\n\n    def evict_lru(self):\n        \"\"\"Evict least recently used entry.\"\"\"\n        if not self.cache:\n            return\n\n        # Find LRU entry\n        lru_id = None\n        lru_time = float('inf')\n\n        for bytecode_id, entry in self.cache.items():\n            if entry['last_used'] < lru_time:\n                lru_time = entry['last_used']\n                lru_id = bytecode_id\n\n        # Evict it\n        if lru_id:\n            entry = self.cache[lru_id]\n            self.current_size -= entry['size']\n            del self.cache[lru_id]",
    "testCases": [
      {
        "input": "cache = JITCodeCache(max_size=100)\ncache.compile_and_cache('func1', 'compiled_code_1', 50)\ncode = cache.lookup('func1')\nprint(code)",
        "expectedOutput": "compiled_code_1",
        "isHidden": false,
        "description": "Lookup cached code"
      },
      {
        "input": "cache = JITCodeCache(max_size=100)\ncache.compile_and_cache('func1', 'code1', 60)\ncache.compile_and_cache('func2', 'code2', 60)\nprint('func1' in cache.cache)",
        "expectedOutput": "False",
        "isHidden": false,
        "description": "LRU eviction when cache is full"
      },
      {
        "input": "cache = JITCodeCache(max_size=100)\ncache.compile_and_cache('a', 'code_a', 40)\ncache.compile_and_cache('b', 'code_b', 40)\ncache.lookup('a')\ncache.compile_and_cache('c', 'code_c', 40)\nprint('b' in cache.cache)",
        "isHidden": true,
        "description": "Recent lookup prevents eviction"
      }
    ],
    "hints": [
      "Track the size of cached code to enforce size limit",
      "Use LRU (Least Recently Used) eviction policy",
      "Update last-used time on each lookup",
      "When adding code, evict entries until there is enough space"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex14",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Position-Independent Code Generator",
    "difficulty": 4,
    "description": "Generate position-independent code (PIC) that can be loaded at any memory address.",
    "starterCode": "class PICGenerator:\n    def __init__(self):\n        self.got = {}  # Global Offset Table: symbol -> GOT offset\n        self.got_size = 0\n\n    def add_global_symbol(self, symbol):\n        \"\"\"Add a global symbol to GOT.\"\"\"\n        # TODO: Add symbol to GOT if not present\n        pass\n\n    def generate_call(self, function_name):\n        \"\"\"\n        Generate PIC code to call a function.\n        Uses GOT for indirection.\n        \"\"\"\n        # TODO: Generate code using GOT\n        pass",
    "solution": "class PICGenerator:\n    def __init__(self):\n        self.got = {}  # Global Offset Table: symbol -> GOT offset\n        self.got_size = 0\n        self.instructions = []\n\n    def add_global_symbol(self, symbol):\n        \"\"\"Add a global symbol to GOT.\"\"\"\n        if symbol not in self.got:\n            self.got[symbol] = self.got_size\n            self.got_size += 4  # Assume 4-byte pointers\n\n    def generate_call(self, function_name):\n        \"\"\"\n        Generate PIC code to call a function.\n        Uses GOT for indirection.\n        \"\"\"\n        # Ensure function is in GOT\n        self.add_global_symbol(function_name)\n\n        got_offset = self.got[function_name]\n\n        # Generate PIC code:\n        # 1. Get PC (program counter)\n        # 2. Calculate GOT address relative to PC\n        # 3. Load function address from GOT\n        # 4. Call the function\n\n        self.instructions.extend([\n            f\"# Call {function_name} via GOT\",\n            f\"CALL get_pc\",  # Get PC into a register\n            f\"ADD r_pc, GOT_BASE\",  # Calculate GOT base\n            f\"LOAD r_func, [r_pc + {got_offset}]\",  # Load function address\n            f\"CALL r_func\"  # Indirect call\n        ])\n\n        return self.instructions\n\n    def generate_global_access(self, var_name):\n        \"\"\"Generate PIC code to access a global variable.\"\"\"\n        self.add_global_symbol(var_name)\n\n        got_offset = self.got[var_name]\n\n        self.instructions.extend([\n            f\"# Access global {var_name} via GOT\",\n            f\"CALL get_pc\",\n            f\"ADD r_pc, GOT_BASE\",\n            f\"LOAD r_addr, [r_pc + {got_offset}]\",  # Load variable address\n            f\"LOAD r_val, [r_addr]\"  # Load variable value\n        ])\n\n        return self.instructions",
    "testCases": [
      {
        "input": "pic = PICGenerator()\npic.generate_call('printf')\nprint('GOT' in pic.instructions[2])",
        "expectedOutput": "True",
        "isHidden": false,
        "description": "Generated code uses GOT"
      },
      {
        "input": "pic = PICGenerator()\npic.add_global_symbol('foo')\npic.add_global_symbol('bar')\nprint(pic.got_size)",
        "expectedOutput": "8",
        "isHidden": false,
        "description": "GOT size for 2 symbols"
      },
      {
        "input": "pic = PICGenerator()\npic.generate_call('func1')\npic.generate_call('func1')\nprint(len(pic.got))",
        "isHidden": true,
        "description": "Same symbol not duplicated in GOT"
      }
    ],
    "hints": [
      "Use a Global Offset Table (GOT) to store addresses of global symbols",
      "Generate code that calculates addresses relative to PC (program counter)",
      "Load addresses from GOT using PC-relative addressing",
      "All global accesses go through the GOT for position independence"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex15",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Thread-Local Storage Manager",
    "difficulty": 3,
    "description": "Implement thread-local storage (TLS) that provides each thread with its own copy of variables.",
    "starterCode": "class TLSManager:\n    def __init__(self):\n        self.tls_data = {}  # thread_id -> {var_name: value}\n        self.current_thread = None\n\n    def set_current_thread(self, thread_id):\n        \"\"\"Switch to a different thread context.\"\"\"\n        # TODO: Set current thread\n        pass\n\n    def set_tls_var(self, var_name, value):\n        \"\"\"Set a thread-local variable for current thread.\"\"\"\n        # TODO: Store in current thread's TLS\n        pass\n\n    def get_tls_var(self, var_name):\n        \"\"\"Get a thread-local variable for current thread.\"\"\"\n        # TODO: Retrieve from current thread's TLS\n        pass",
    "solution": "class TLSManager:\n    def __init__(self):\n        self.tls_data = {}  # thread_id -> {var_name: value}\n        self.current_thread = None\n\n    def set_current_thread(self, thread_id):\n        \"\"\"Switch to a different thread context.\"\"\"\n        self.current_thread = thread_id\n\n        # Initialize TLS for this thread if needed\n        if thread_id not in self.tls_data:\n            self.tls_data[thread_id] = {}\n\n    def set_tls_var(self, var_name, value):\n        \"\"\"Set a thread-local variable for current thread.\"\"\"\n        if self.current_thread is None:\n            raise RuntimeError(\"No current thread set\")\n\n        if self.current_thread not in self.tls_data:\n            self.tls_data[self.current_thread] = {}\n\n        self.tls_data[self.current_thread][var_name] = value\n\n    def get_tls_var(self, var_name):\n        \"\"\"Get a thread-local variable for current thread.\"\"\"\n        if self.current_thread is None:\n            raise RuntimeError(\"No current thread set\")\n\n        if self.current_thread not in self.tls_data:\n            return None\n\n        return self.tls_data[self.current_thread].get(var_name)\n\n    def clear_thread_data(self, thread_id):\n        \"\"\"Clear all TLS data for a thread (when thread exits).\"\"\"\n        if thread_id in self.tls_data:\n            del self.tls_data[thread_id]",
    "testCases": [
      {
        "input": "tls = TLSManager()\ntls.set_current_thread('thread1')\ntls.set_tls_var('x', 100)\nprint(tls.get_tls_var('x'))",
        "expectedOutput": "100",
        "isHidden": false,
        "description": "Set and get TLS variable"
      },
      {
        "input": "tls = TLSManager()\ntls.set_current_thread('thread1')\ntls.set_tls_var('x', 100)\ntls.set_current_thread('thread2')\ntls.set_tls_var('x', 200)\ntls.set_current_thread('thread1')\nprint(tls.get_tls_var('x'))",
        "expectedOutput": "100",
        "isHidden": false,
        "description": "Each thread has its own TLS"
      },
      {
        "input": "tls = TLSManager()\ntls.set_current_thread('thread1')\ntls.set_tls_var('y', 42)\ntls.clear_thread_data('thread1')\ntls.set_current_thread('thread1')\nprint(tls.get_tls_var('y') is None)",
        "isHidden": true,
        "description": "Clearing thread data works"
      }
    ],
    "hints": [
      "Maintain separate storage for each thread",
      "Track which thread is currently executing",
      "Store thread-local variables in a nested dictionary structure",
      "Each thread accesses only its own TLS data"
    ],
    "language": "python"
  },
  {
    "id": "cs304-t7-ex16",
    "subjectId": "cs304",
    "topicId": "cs304-topic-7",
    "title": "Lazy Symbol Resolution",
    "difficulty": 4,
    "description": "Implement lazy symbol resolution where symbols are only resolved when first used, improving startup time.",
    "starterCode": "class LazyResolver:\n    def __init__(self):\n        self.symbol_table = {}  # symbol -> actual_address\n        self.plt = {}  # symbol -> PLT stub address\n        self.resolved = {}  # symbol -> resolved address\n\n    def register_symbol(self, symbol, address):\n        \"\"\"Register a symbol with its actual address.\"\"\"\n        self.symbol_table[symbol] = address\n\n    def create_plt_stub(self, symbol):\n        \"\"\"\n        Create a PLT (Procedure Linkage Table) stub for lazy resolution.\n        Returns PLT stub address.\n        \"\"\"\n        # TODO: Create stub that will resolve on first call\n        pass\n\n    def resolve_symbol(self, symbol):\n        \"\"\"\n        Resolve a symbol (called by PLT stub).\n        Returns actual address.\n        \"\"\"\n        # TODO: Look up symbol and cache resolution\n        pass",
    "solution": "class LazyResolver:\n    def __init__(self):\n        self.symbol_table = {}  # symbol -> actual_address\n        self.plt = {}  # symbol -> PLT stub address\n        self.resolved = {}  # symbol -> resolved address\n        self.next_plt_addr = 10000  # PLT starts at 10000\n        self.resolve_count = 0  # Track resolution calls\n\n    def register_symbol(self, symbol, address):\n        \"\"\"Register a symbol with its actual address.\"\"\"\n        self.symbol_table[symbol] = address\n\n    def create_plt_stub(self, symbol):\n        \"\"\"\n        Create a PLT (Procedure Linkage Table) stub for lazy resolution.\n        Returns PLT stub address.\n        \"\"\"\n        if symbol in self.plt:\n            return self.plt[symbol]\n\n        # Allocate PLT stub address\n        plt_addr = self.next_plt_addr\n        self.next_plt_addr += 16  # Each stub is 16 bytes\n\n        self.plt[symbol] = {\n            'address': plt_addr,\n            'symbol': symbol,\n            'resolved': False\n        }\n\n        return plt_addr\n\n    def resolve_symbol(self, symbol):\n        \"\"\"\n        Resolve a symbol (called by PLT stub).\n        Returns actual address.\n        \"\"\"\n        self.resolve_count += 1\n\n        # Check if already resolved\n        if symbol in self.resolved:\n            return self.resolved[symbol]\n\n        # Look up symbol\n        if symbol not in self.symbol_table:\n            raise ValueError(f\"Undefined symbol: {symbol}\")\n\n        actual_address = self.symbol_table[symbol]\n\n        # Cache resolution\n        self.resolved[symbol] = actual_address\n\n        # Mark PLT stub as resolved\n        if symbol in self.plt:\n            self.plt[symbol]['resolved'] = True\n\n        return actual_address\n\n    def call_symbol(self, symbol):\n        \"\"\"\n        Simulate calling a symbol (goes through PLT).\n        Returns actual address to call.\n        \"\"\"\n        # Get or create PLT stub\n        if symbol not in self.plt:\n            self.create_plt_stub(symbol)\n\n        # Check if already resolved\n        if symbol in self.resolved:\n            return self.resolved[symbol]\n\n        # Not resolved - trigger lazy resolution\n        return self.resolve_symbol(symbol)",
    "testCases": [
      {
        "input": "resolver = LazyResolver()\nresolver.register_symbol('printf', 5000)\nplt_addr = resolver.create_plt_stub('printf')\nprint(plt_addr)",
        "expectedOutput": "10000",
        "isHidden": false,
        "description": "PLT stub created at fixed address"
      },
      {
        "input": "resolver = LazyResolver()\nresolver.register_symbol('malloc', 6000)\naddr = resolver.call_symbol('malloc')\nprint(addr)",
        "expectedOutput": "6000",
        "isHidden": false,
        "description": "Lazy resolution returns actual address"
      },
      {
        "input": "resolver = LazyResolver()\nresolver.register_symbol('foo', 7000)\nresolver.call_symbol('foo')\nresolver.call_symbol('foo')\nprint(resolver.resolve_count)",
        "isHidden": true,
        "description": "Symbol resolved only once"
      }
    ],
    "hints": [
      "Create PLT stubs that defer symbol resolution until first call",
      "Cache resolved addresses to avoid repeated lookups",
      "Track which symbols have been resolved",
      "First call triggers resolution, subsequent calls use cached address"
    ],
    "language": "python"
  }
]