[
  {
    "id": "cs407-midterm",
    "subjectId": "cs407",
    "title": "CS407 Midterm Exam",
    "durationMinutes": 90,
    "instructions": [
      "This exam covers data collection, data cleaning, and exploratory data analysis.",
      "Answer all questions to the best of your ability.",
      "For written questions, provide detailed explanations with examples.",
      "Passing score is 70%."
    ],
    "questions": [
      {
        "id": "q1",
        "type": "written",
        "prompt": "Explain the difference between MCAR (Missing Completely At Random), MAR (Missing At Random), and MNAR (Missing Not At Random). Provide an example of each type of missingness.",
        "correctAnswer": "mcar mar mnar random missing pattern mechanism",
        "explanation": "Understanding missingness mechanisms is crucial for choosing appropriate imputation strategies.",
        "modelAnswer": "MCAR (Missing Completely At Random): The probability of missingness is the same for all observations. Example: A survey respondent randomly skips questions by accident. MAR (Missing At Random): The probability of missingness depends on observed data but not the missing values themselves. Example: Younger people are less likely to report income, but missingness depends only on age (which is observed). MNAR (Missing Not At Random): The probability of missingness depends on the unobserved values. Example: People with very high incomes deliberately skip income questions. Understanding these mechanisms helps choose appropriate imputation methods and assess potential bias."
      },
      {
        "id": "q2",
        "type": "written",
        "prompt": "You have a dataset with 40% missing values in a critical column. Describe three different strategies you could use to handle this missing data, including the pros and cons of each approach.",
        "correctAnswer": "deletion imputation mean median knn model strategy",
        "explanation": "Different missing data strategies have different trade-offs in terms of bias, variance, and computational cost.",
        "modelAnswer": "Strategy 1 - Deletion: Remove rows with missing values. Pros: Simple, no assumptions needed. Cons: Loses 40% of data, may introduce bias if not MCAR. Strategy 2 - Simple Imputation (mean/median): Fill with column mean or median. Pros: Retains all rows, fast computation. Cons: Reduces variance, ignores relationships with other features, inappropriate for MNAR. Strategy 3 - Advanced Imputation (KNN/MICE): Use similar observations or multiple imputation. Pros: Preserves relationships, handles complex patterns. Cons: Computationally expensive, requires careful validation, assumptions about data distribution."
      },
      {
        "id": "q3",
        "type": "multiple_choice",
        "prompt": "What is the primary purpose of feature scaling in machine learning?",
        "options": [
          "To remove missing values from the dataset",
          "To ensure features contribute equally to distance-based algorithms",
          "To increase the number of features in the dataset",
          "To convert categorical variables to numeric"
        ],
        "correctAnswer": 1,
        "explanation": "Feature scaling ensures that features with different ranges contribute equally to distance calculations in algorithms like k-NN, SVM, and gradient descent."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "Which of the following algorithms does NOT typically require feature scaling?",
        "options": [
          "K-Nearest Neighbors (k-NN)",
          "Support Vector Machines (SVM)",
          "Decision Trees",
          "Gradient Descent-based algorithms"
        ],
        "correctAnswer": 2,
        "explanation": "Decision trees and tree-based algorithms (Random Forests, XGBoost) do not require feature scaling because they make decisions based on splitting thresholds, not distances."
      },
      {
        "id": "q5",
        "type": "written",
        "prompt": "Compare and contrast data lakes and data warehouses. Discuss their architecture, typical use cases, and the types of users who would use each system.",
        "correctAnswer": "data lake warehouse structured unstructured schema analytics storage",
        "explanation": "Understanding the differences between data lakes and warehouses is essential for designing modern data architectures.",
        "modelAnswer": "Data Lakes: Architecture - Store raw, unstructured/semi-structured data in native format (schema-on-read). Use technologies like Hadoop, S3, Azure Data Lake. Use Cases - Big data analytics, machine learning, exploratory analysis, storing diverse data types. Users - Data scientists, ML engineers, analysts exploring new data sources. Data Warehouses: Architecture - Store structured, processed data with defined schema (schema-on-write). Use relational databases, dimensional modeling (star/snowflake schemas). Use Cases - Business intelligence, reporting, OLAP, historical analysis. Users - Business analysts, executives, BI developers. Key Differences: Lakes are flexible but require more data engineering; warehouses are optimized for queries but less flexible."
      },
      {
        "id": "q6",
        "type": "multiple_choice",
        "prompt": "In exploratory data analysis, which visualization is most appropriate for examining the distribution of a continuous variable?",
        "options": [
          "Bar chart",
          "Pie chart",
          "Histogram",
          "Scatter plot"
        ],
        "correctAnswer": 2,
        "explanation": "Histograms display the frequency distribution of continuous data by dividing it into bins, making it easy to see the shape, spread, and central tendency."
      },
      {
        "id": "q7",
        "type": "true_false",
        "prompt": "A correlation coefficient of 0 indicates that there is absolutely no relationship between two variables.",
        "correctAnswer": false,
        "explanation": "A correlation coefficient of 0 indicates no LINEAR relationship, but there could still be a non-linear relationship between the variables."
      }
    ]
  },
  {
    "id": "cs407-final",
    "subjectId": "cs407",
    "title": "CS407 Final Exam",
    "durationMinutes": 120,
    "instructions": [
      "This comprehensive exam covers all CS407 topics including data pipelines, statistical inference, machine learning basics, and ethics.",
      "Answer all questions thoroughly.",
      "For design questions, consider scalability, reliability, and best practices.",
      "Passing score is 70%."
    ],
    "questions": [
      {
        "id": "q1",
        "type": "written",
        "prompt": "Design a complete data pipeline for a real-time analytics system that processes streaming user events (clicks, page views, etc.). Include data collection, processing, storage, and visualization components. Address scalability and error handling.",
        "correctAnswer": "pipeline streaming kafka spark storage processing analytics real-time",
        "explanation": "Real-time data pipelines require careful consideration of throughput, latency, fault tolerance, and scalability.",
        "modelAnswer": "Data Collection: Use Apache Kafka or AWS Kinesis to ingest streaming events from web/mobile apps. Implement client-side buffering and retry logic for reliability. Processing: Use Apache Spark Streaming or Flink for stream processing. Implement windowing (tumbling/sliding) for aggregations, stateful processing for sessionization. Storage: Hot path - Redis/Memcached for real-time dashboards. Warm path - Cassandra/DynamoDB for recent data queries. Cold path - S3/Parquet for historical analysis and ML training. Visualization: Grafana or custom dashboard consuming real-time aggregates from Redis. Scalability: Horizontal scaling of Kafka partitions, Spark executors. Auto-scaling based on queue depth. Error Handling: Dead letter queues for failed messages, circuit breakers, monitoring/alerting with Prometheus/Grafana, data quality checks at ingestion."
      },
      {
        "id": "q2",
        "type": "written",
        "prompt": "Discuss three major ethical considerations in data science (such as privacy, bias, transparency, consent, etc.) and explain concrete practices that data scientists should implement to address each one.",
        "correctAnswer": "ethics privacy bias fairness transparency consent responsible data",
        "explanation": "Ethical considerations are fundamental to responsible data science practice.",
        "modelAnswer": "1. Privacy and Consent: Users should have control over their data. Practices: Implement privacy-by-design, use differential privacy for aggregates, anonymize/pseudonymize data, obtain informed consent, follow GDPR/CCPA, minimize data collection, provide opt-out mechanisms. 2. Algorithmic Bias and Fairness: Models can perpetuate historical biases. Practices: Audit training data for representation, use fairness metrics (demographic parity, equalized odds), test across demographic groups, diverse team review, document limitations, regular bias audits. 3. Transparency and Explainability: Users deserve to understand decisions affecting them. Practices: Use interpretable models when possible, implement SHAP/LIME for complex models, document model cards, provide clear explanations for automated decisions, allow human appeal/override, regular audits and reporting."
      },
      {
        "id": "q3",
        "type": "multiple_choice",
        "prompt": "In hypothesis testing, what does a p-value represent?",
        "options": [
          "The probability that the null hypothesis is true",
          "The probability of observing the data (or more extreme) if the null hypothesis is true",
          "The probability that the alternative hypothesis is true",
          "The significance level of the test"
        ],
        "correctAnswer": 1,
        "explanation": "The p-value is the probability of obtaining test results at least as extreme as the observed results, assuming the null hypothesis is true."
      },
      {
        "id": "q4",
        "type": "multiple_choice",
        "prompt": "Which of the following is NOT a characteristic of a good machine learning feature?",
        "options": [
          "Strong correlation with the target variable",
          "Low correlation with other features (low multicollinearity)",
          "High cardinality with unique values for each observation",
          "Available at prediction time"
        ],
        "correctAnswer": 2,
        "explanation": "Features with unique values for each observation (like IDs) do not generalize well. Good features balance predictive power with generalizability."
      },
      {
        "id": "q5",
        "type": "true_false",
        "prompt": "Cross-validation helps prevent overfitting by testing the model on data it has not seen during training.",
        "correctAnswer": true,
        "explanation": "Cross-validation splits data into training and validation sets, allowing us to assess how well the model generalizes to unseen data, which helps detect and prevent overfitting."
      },
      {
        "id": "q6",
        "type": "fill_blank",
        "prompt": "The process of creating new features from existing ones to improve model performance is called feature ______.",
        "correctAnswer": "engineering",
        "explanation": "Feature engineering involves creating, transforming, and selecting features to improve machine learning model performance."
      },
      {
        "id": "q7",
        "type": "multiple_choice",
        "prompt": "What is the main purpose of a confusion matrix in classification problems?",
        "options": [
          "To visualize feature correlations",
          "To show the distribution of predicted vs actual classes",
          "To normalize feature values",
          "To perform dimensionality reduction"
        ],
        "correctAnswer": 1,
        "explanation": "A confusion matrix displays the counts of true positives, true negatives, false positives, and false negatives, helping evaluate classification model performance."
      },
      {
        "id": "q8",
        "type": "multiple_choice",
        "prompt": "Which metric would be most appropriate for evaluating a highly imbalanced classification problem where positive class is rare?",
        "options": [
          "Accuracy",
          "F1-score or AUC-ROC",
          "Mean Squared Error",
          "R-squared"
        ],
        "correctAnswer": 1,
        "explanation": "For imbalanced datasets, F1-score (harmonic mean of precision and recall) or AUC-ROC are better than accuracy, which can be misleadingly high by predicting the majority class."
      }
    ]
  }
]